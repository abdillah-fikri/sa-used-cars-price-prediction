{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IN1jfOnfZIqT"
   },
   "source": [
    "# Data Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00035-adb3a37b-199a-4d0e-ba89-ea8c10843673",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2020-10-13T13:29:52.833962Z",
     "iopub.status.busy": "2020-10-13T13:29:52.833962Z",
     "iopub.status.idle": "2020-10-13T13:29:52.864878Z",
     "shell.execute_reply": "2020-10-13T13:29:52.863881Z",
     "shell.execute_reply.started": "2020-10-13T13:29:52.833962Z"
    },
    "id": "bKob_zWgIakl",
    "outputId": "abad69f7-6d95-47a7-f39d-aa2c323d8c2a",
    "output_cleared": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "import miceforest as mf\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "from utils import *\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, KFold\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn import metrics\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "uOHFykGLHlTs",
    "outputId": "e29d793b-087b-4151-8549-6804e76f5f13"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Year</th>\n",
       "      <th>Kilometers_Driven</th>\n",
       "      <th>Fuel_Type</th>\n",
       "      <th>Transmission</th>\n",
       "      <th>Owner_Type</th>\n",
       "      <th>Seats</th>\n",
       "      <th>Price</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Series</th>\n",
       "      <th>Type</th>\n",
       "      <th>Mileage (kmpl)</th>\n",
       "      <th>Engine (CC)</th>\n",
       "      <th>Power (bhp)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>2010</td>\n",
       "      <td>72000</td>\n",
       "      <td>CNG</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>Maruti</td>\n",
       "      <td>Wagon</td>\n",
       "      <td>R</td>\n",
       "      <td>26.60</td>\n",
       "      <td>998.0</td>\n",
       "      <td>58.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pune</td>\n",
       "      <td>2015</td>\n",
       "      <td>41000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.50</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>Creta</td>\n",
       "      <td>1.6</td>\n",
       "      <td>19.67</td>\n",
       "      <td>1582.0</td>\n",
       "      <td>126.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chennai</td>\n",
       "      <td>2011</td>\n",
       "      <td>46000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.50</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Jazz</td>\n",
       "      <td>V</td>\n",
       "      <td>18.20</td>\n",
       "      <td>1199.0</td>\n",
       "      <td>88.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chennai</td>\n",
       "      <td>2012</td>\n",
       "      <td>87000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>Maruti</td>\n",
       "      <td>Ertiga</td>\n",
       "      <td>VDI</td>\n",
       "      <td>20.77</td>\n",
       "      <td>1248.0</td>\n",
       "      <td>88.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coimbatore</td>\n",
       "      <td>2013</td>\n",
       "      <td>40670</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Second</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.74</td>\n",
       "      <td>Audi</td>\n",
       "      <td>A4</td>\n",
       "      <td>New</td>\n",
       "      <td>15.20</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>140.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Location  Year  Kilometers_Driven Fuel_Type Transmission Owner_Type  \\\n",
       "0      Mumbai  2010              72000       CNG       Manual      First   \n",
       "1        Pune  2015              41000    Diesel       Manual      First   \n",
       "2     Chennai  2011              46000    Petrol       Manual      First   \n",
       "3     Chennai  2012              87000    Diesel       Manual      First   \n",
       "4  Coimbatore  2013              40670    Diesel    Automatic     Second   \n",
       "\n",
       "   Seats  Price    Brand  Series Type  Mileage (kmpl)  Engine (CC)  \\\n",
       "0    5.0   1.75   Maruti   Wagon    R           26.60        998.0   \n",
       "1    5.0  12.50  Hyundai   Creta  1.6           19.67       1582.0   \n",
       "2    5.0   4.50    Honda    Jazz    V           18.20       1199.0   \n",
       "3    7.0   6.00   Maruti  Ertiga  VDI           20.77       1248.0   \n",
       "4    5.0  17.74     Audi      A4  New           15.20       1968.0   \n",
       "\n",
       "   Power (bhp)  \n",
       "0        58.16  \n",
       "1       126.20  \n",
       "2        88.70  \n",
       "3        88.76  \n",
       "4       140.80  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/processed/after_prep.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q7_R-5ZmHlTx",
    "outputId": "f21a5ba3-a2d8-4b27-a719-8652785c2256"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6019 entries, 0 to 6018\n",
      "Data columns (total 14 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Location           6019 non-null   object \n",
      " 1   Year               6019 non-null   int64  \n",
      " 2   Kilometers_Driven  6019 non-null   int64  \n",
      " 3   Fuel_Type          6019 non-null   object \n",
      " 4   Transmission       6019 non-null   object \n",
      " 5   Owner_Type         6019 non-null   object \n",
      " 6   Seats              5976 non-null   float64\n",
      " 7   Price              6019 non-null   float64\n",
      " 8   Brand              6019 non-null   object \n",
      " 9   Series             6019 non-null   object \n",
      " 10  Type               6019 non-null   object \n",
      " 11  Mileage (kmpl)     5951 non-null   float64\n",
      " 12  Engine (CC)        5983 non-null   float64\n",
      " 13  Power (bhp)        5876 non-null   float64\n",
      "dtypes: float64(5), int64(2), object(7)\n",
      "memory usage: 658.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1GS1AAUZIt9"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2020-10-13T13:29:52.867870Z",
     "iopub.status.busy": "2020-10-13T13:29:52.866875Z",
     "iopub.status.idle": "2020-10-13T13:29:52.879124Z",
     "shell.execute_reply": "2020-10-13T13:29:52.879124Z",
     "shell.execute_reply.started": "2020-10-13T13:29:52.867870Z"
    },
    "id": "INV8VvOYZItN",
    "outputId": "d23b96f5-b584-4bdf-fef6-0c4fe60ffacf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6018, 14)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete outlier\n",
    "df = df[~(df.Kilometers_Driven > 1e6)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "execution": {
     "iopub.execute_input": "2020-10-13T13:29:52.879124Z",
     "iopub.status.busy": "2020-10-13T13:29:52.879124Z",
     "iopub.status.idle": "2020-10-13T13:29:52.910917Z",
     "shell.execute_reply": "2020-10-13T13:29:52.909951Z",
     "shell.execute_reply.started": "2020-10-13T13:29:52.879124Z"
    },
    "id": "TYqvFHW1HqFX",
    "outputId": "73c8156d-d213-41d0-f2ca-5d8e6c64c1cf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>null (sum)</th>\n",
       "      <th>null (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kilometers_Driven</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fuel_Type</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transmission</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Owner_Type</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seats</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brand</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Series</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mileage (kmpl)</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Engine (CC)</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Power (bhp)</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   null (sum)  null (%)\n",
       "Location                    0       0.0\n",
       "Year                        0       0.0\n",
       "Kilometers_Driven           0       0.0\n",
       "Fuel_Type                   0       0.0\n",
       "Transmission                0       0.0\n",
       "Owner_Type                  0       0.0\n",
       "Seats                       0       0.0\n",
       "Price                       0       0.0\n",
       "Brand                       0       0.0\n",
       "Series                      0       0.0\n",
       "Type                        0       0.0\n",
       "Mileage (kmpl)              0       0.0\n",
       "Engine (CC)                 0       0.0\n",
       "Power (bhp)                 0       0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop missing values\n",
    "df = df.dropna()\n",
    "null_checker(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fvvwh2uSWvUU"
   },
   "source": [
    "## Feature enginering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "bUXLzqVHZOI9"
   },
   "outputs": [],
   "source": [
    "# Grouping category less than 10 to \"Other\"\n",
    "for col in [\"Brand\", \"Series\", \"Type\"]:\n",
    "    counts = df[col].value_counts()\n",
    "    other = counts[counts < 10].index\n",
    "    df[col] = df[col].replace(other, \"Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "2HEc8zicU0uy",
    "outputId": "eeeba314-bd64-46d3-b9c8-a492605a3937"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Year</th>\n",
       "      <th>Kilometers_Driven</th>\n",
       "      <th>Fuel_Type</th>\n",
       "      <th>Transmission</th>\n",
       "      <th>Owner_Type</th>\n",
       "      <th>Seats</th>\n",
       "      <th>Price</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Series</th>\n",
       "      <th>...</th>\n",
       "      <th>Location_Fuel_Type</th>\n",
       "      <th>Location_Transmission</th>\n",
       "      <th>Location_Owner_Type</th>\n",
       "      <th>Location_Brand</th>\n",
       "      <th>Fuel_Type_Transmission</th>\n",
       "      <th>Fuel_Type_Owner_Type</th>\n",
       "      <th>Fuel_Type_Brand</th>\n",
       "      <th>Transmission_Owner_Type</th>\n",
       "      <th>Transmission_Brand</th>\n",
       "      <th>Owner_Type_Brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>2010</td>\n",
       "      <td>72000</td>\n",
       "      <td>CNG</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>Maruti</td>\n",
       "      <td>Wagon</td>\n",
       "      <td>...</td>\n",
       "      <td>Mumbai_CNG</td>\n",
       "      <td>Mumbai_Manual</td>\n",
       "      <td>Mumbai_First</td>\n",
       "      <td>Mumbai_Maruti</td>\n",
       "      <td>CNG_Manual</td>\n",
       "      <td>CNG_First</td>\n",
       "      <td>CNG_Maruti</td>\n",
       "      <td>Manual_First</td>\n",
       "      <td>Manual_Maruti</td>\n",
       "      <td>First_Maruti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pune</td>\n",
       "      <td>2015</td>\n",
       "      <td>41000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.50</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>Creta</td>\n",
       "      <td>...</td>\n",
       "      <td>Pune_Diesel</td>\n",
       "      <td>Pune_Manual</td>\n",
       "      <td>Pune_First</td>\n",
       "      <td>Pune_Hyundai</td>\n",
       "      <td>Diesel_Manual</td>\n",
       "      <td>Diesel_First</td>\n",
       "      <td>Diesel_Hyundai</td>\n",
       "      <td>Manual_First</td>\n",
       "      <td>Manual_Hyundai</td>\n",
       "      <td>First_Hyundai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chennai</td>\n",
       "      <td>2011</td>\n",
       "      <td>46000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.50</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Jazz</td>\n",
       "      <td>...</td>\n",
       "      <td>Chennai_Petrol</td>\n",
       "      <td>Chennai_Manual</td>\n",
       "      <td>Chennai_First</td>\n",
       "      <td>Chennai_Honda</td>\n",
       "      <td>Petrol_Manual</td>\n",
       "      <td>Petrol_First</td>\n",
       "      <td>Petrol_Honda</td>\n",
       "      <td>Manual_First</td>\n",
       "      <td>Manual_Honda</td>\n",
       "      <td>First_Honda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chennai</td>\n",
       "      <td>2012</td>\n",
       "      <td>87000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>Maruti</td>\n",
       "      <td>Ertiga</td>\n",
       "      <td>...</td>\n",
       "      <td>Chennai_Diesel</td>\n",
       "      <td>Chennai_Manual</td>\n",
       "      <td>Chennai_First</td>\n",
       "      <td>Chennai_Maruti</td>\n",
       "      <td>Diesel_Manual</td>\n",
       "      <td>Diesel_First</td>\n",
       "      <td>Diesel_Maruti</td>\n",
       "      <td>Manual_First</td>\n",
       "      <td>Manual_Maruti</td>\n",
       "      <td>First_Maruti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coimbatore</td>\n",
       "      <td>2013</td>\n",
       "      <td>40670</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Second</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.74</td>\n",
       "      <td>Audi</td>\n",
       "      <td>A4</td>\n",
       "      <td>...</td>\n",
       "      <td>Coimbatore_Diesel</td>\n",
       "      <td>Coimbatore_Automatic</td>\n",
       "      <td>Coimbatore_Second</td>\n",
       "      <td>Coimbatore_Audi</td>\n",
       "      <td>Diesel_Automatic</td>\n",
       "      <td>Diesel_Second</td>\n",
       "      <td>Diesel_Audi</td>\n",
       "      <td>Automatic_Second</td>\n",
       "      <td>Automatic_Audi</td>\n",
       "      <td>Second_Audi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Location  Year  Kilometers_Driven Fuel_Type Transmission Owner_Type  \\\n",
       "0      Mumbai  2010              72000       CNG       Manual      First   \n",
       "1        Pune  2015              41000    Diesel       Manual      First   \n",
       "2     Chennai  2011              46000    Petrol       Manual      First   \n",
       "3     Chennai  2012              87000    Diesel       Manual      First   \n",
       "4  Coimbatore  2013              40670    Diesel    Automatic     Second   \n",
       "\n",
       "   Seats  Price    Brand  Series  ... Location_Fuel_Type  \\\n",
       "0    5.0   1.75   Maruti   Wagon  ...         Mumbai_CNG   \n",
       "1    5.0  12.50  Hyundai   Creta  ...        Pune_Diesel   \n",
       "2    5.0   4.50    Honda    Jazz  ...     Chennai_Petrol   \n",
       "3    7.0   6.00   Maruti  Ertiga  ...     Chennai_Diesel   \n",
       "4    5.0  17.74     Audi      A4  ...  Coimbatore_Diesel   \n",
       "\n",
       "   Location_Transmission  Location_Owner_Type   Location_Brand  \\\n",
       "0          Mumbai_Manual         Mumbai_First    Mumbai_Maruti   \n",
       "1            Pune_Manual           Pune_First     Pune_Hyundai   \n",
       "2         Chennai_Manual        Chennai_First    Chennai_Honda   \n",
       "3         Chennai_Manual        Chennai_First   Chennai_Maruti   \n",
       "4   Coimbatore_Automatic    Coimbatore_Second  Coimbatore_Audi   \n",
       "\n",
       "  Fuel_Type_Transmission Fuel_Type_Owner_Type Fuel_Type_Brand  \\\n",
       "0             CNG_Manual            CNG_First      CNG_Maruti   \n",
       "1          Diesel_Manual         Diesel_First  Diesel_Hyundai   \n",
       "2          Petrol_Manual         Petrol_First    Petrol_Honda   \n",
       "3          Diesel_Manual         Diesel_First   Diesel_Maruti   \n",
       "4       Diesel_Automatic        Diesel_Second     Diesel_Audi   \n",
       "\n",
       "  Transmission_Owner_Type Transmission_Brand Owner_Type_Brand  \n",
       "0            Manual_First      Manual_Maruti     First_Maruti  \n",
       "1            Manual_First     Manual_Hyundai    First_Hyundai  \n",
       "2            Manual_First       Manual_Honda      First_Honda  \n",
       "3            Manual_First      Manual_Maruti     First_Maruti  \n",
       "4        Automatic_Second     Automatic_Audi      Second_Audi  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make categorical feature interactions\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "cat_cols = ['Location', 'Fuel_Type', 'Transmission', 'Owner_Type', 'Brand']\n",
    "\n",
    "for col in combinations(cat_cols, 2):\n",
    "    new_col = col[0]+'_'+col[1]\n",
    "    df[new_col] = df[col[0]] + \"_\" + df[col[1]]\n",
    "    \n",
    "    counts = df[new_col].value_counts()\n",
    "    other = counts[counts < 10].index\n",
    "    df[new_col] = df[new_col].replace(other, \"Other\")\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yEgVyyNSZIt9"
   },
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-13T13:29:52.911913Z",
     "iopub.status.busy": "2020-10-13T13:29:52.911913Z",
     "iopub.status.idle": "2020-10-13T13:29:52.926873Z",
     "shell.execute_reply": "2020-10-13T13:29:52.925908Z",
     "shell.execute_reply.started": "2020-10-13T13:29:52.911913Z"
    },
    "id": "nPxFt6bSZIt-"
   },
   "outputs": [],
   "source": [
    "# melakukan train test split di awal untuk mencegah data bocor ke test set saat dilakukan encoding/imputation\n",
    "train_data, test_data = train_test_split(df, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxqsMHrKZIuA"
   },
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "00036-c7e04c20-9ab9-48dc-a699-9e7a06582a8c",
    "execution": {
     "iopub.execute_input": "2020-10-13T13:29:52.928873Z",
     "iopub.status.busy": "2020-10-13T13:29:52.927872Z",
     "iopub.status.idle": "2020-10-13T13:29:53.107446Z",
     "shell.execute_reply": "2020-10-13T13:29:53.106483Z",
     "shell.execute_reply.started": "2020-10-13T13:29:52.928873Z"
    },
    "id": "_0criLnZIakn",
    "output_cleared": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define category mapping for label encoding\n",
    "mapping_owner = {\n",
    "    'First': 1, \n",
    "    'Second': 2, \n",
    "    'Third': 3, \n",
    "    'Fourth & Above': 4\n",
    "}\n",
    "mapping_trans = {\n",
    "    'Manual': 0, \n",
    "    'Automatic': 1, \n",
    "}\n",
    "\n",
    "# Encoding train set\n",
    "train_data[\"Owner_Type\"] = train_data[\"Owner_Type\"].map(mapping_owner)\n",
    "train_data[\"Transmission\"] = train_data[\"Transmission\"].map(mapping_trans)\n",
    "# Encoding test set\n",
    "test_data[\"Owner_Type\"] = test_data[\"Owner_Type\"].map(mapping_owner)\n",
    "test_data[\"Transmission\"] = test_data[\"Transmission\"].map(mapping_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w_QmQ1-COIRX",
    "outputId": "75000f20-1597-48fd-b81b-e41310aec223"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between the new feature, Location_Enc and, Price is 0.22953890285650633.\n",
      "Correlation between the new feature, Fuel_Type_Enc and, Price is 0.31902625145603397.\n",
      "Correlation between the new feature, Brand_Enc and, Price is 0.7558118852201624.\n",
      "Correlation between the new feature, Series_Enc and, Price is 0.7679810838662673.\n",
      "Correlation between the new feature, Type_Enc and, Price is 0.6936821252171319.\n",
      "Correlation between the new feature, Location_Fuel_Type_Enc and, Price is 0.4040042711000571.\n",
      "Correlation between the new feature, Location_Transmission_Enc and, Price is 0.6047463551016796.\n",
      "Correlation between the new feature, Location_Owner_Type_Enc and, Price is 0.23746243798549335.\n",
      "Correlation between the new feature, Location_Brand_Enc and, Price is 0.6984005568634631.\n",
      "Correlation between the new feature, Fuel_Type_Transmission_Enc and, Price is 0.6637391383193235.\n",
      "Correlation between the new feature, Fuel_Type_Owner_Type_Enc and, Price is 0.3302114220837294.\n",
      "Correlation between the new feature, Fuel_Type_Brand_Enc and, Price is 0.7565765558024673.\n",
      "Correlation between the new feature, Transmission_Owner_Type_Enc and, Price is 0.5862583788662555.\n",
      "Correlation between the new feature, Transmission_Brand_Enc and, Price is 0.767842506625322.\n",
      "Correlation between the new feature, Owner_Type_Brand_Enc and, Price is 0.7588994667586403.\n"
     ]
    }
   ],
   "source": [
    "import kfold_target_encoder as enc\n",
    "col_to_encode = train_data.select_dtypes(\"object\").columns.tolist()\n",
    "col_to_encode\n",
    "\n",
    "# Encoding train set\n",
    "for col in col_to_encode:\n",
    "    targetc = enc.KFoldTargetEncoderTrain(col, \"Price\", n_fold=5)\n",
    "    train_data = targetc.fit_transform(train_data)\n",
    "\n",
    "# Encoding test set\n",
    "for col in col_to_encode:\n",
    "    test_targetc = enc.KFoldTargetEncoderTest(train_data, col, col+\"_Enc\")\n",
    "    test_data = test_targetc.fit_transform(test_data)\n",
    "\n",
    "# Delete old features\n",
    "train_data.drop(columns=col_to_encode, inplace=True)\n",
    "test_data.drop(columns=col_to_encode, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1462 entries, 4872 to 2309\n",
      "Data columns (total 24 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   Year                         1462 non-null   int64  \n",
      " 1   Kilometers_Driven            1462 non-null   int64  \n",
      " 2   Transmission                 1462 non-null   int64  \n",
      " 3   Owner_Type                   1462 non-null   int64  \n",
      " 4   Seats                        1462 non-null   float64\n",
      " 5   Price                        1462 non-null   float64\n",
      " 6   Mileage (kmpl)               1462 non-null   float64\n",
      " 7   Engine (CC)                  1462 non-null   float64\n",
      " 8   Power (bhp)                  1462 non-null   float64\n",
      " 9   Location_Enc                 1462 non-null   float64\n",
      " 10  Fuel_Type_Enc                1462 non-null   float64\n",
      " 11  Brand_Enc                    1462 non-null   float64\n",
      " 12  Series_Enc                   1462 non-null   float64\n",
      " 13  Type_Enc                     1462 non-null   float64\n",
      " 14  Location_Fuel_Type_Enc       1462 non-null   float64\n",
      " 15  Location_Transmission_Enc    1462 non-null   float64\n",
      " 16  Location_Owner_Type_Enc      1462 non-null   float64\n",
      " 17  Location_Brand_Enc           1462 non-null   float64\n",
      " 18  Fuel_Type_Transmission_Enc   1462 non-null   float64\n",
      " 19  Fuel_Type_Owner_Type_Enc     1462 non-null   float64\n",
      " 20  Fuel_Type_Brand_Enc          1462 non-null   float64\n",
      " 21  Transmission_Owner_Type_Enc  1462 non-null   float64\n",
      " 22  Transmission_Brand_Enc       1462 non-null   float64\n",
      " 23  Owner_Type_Brand_Enc         1462 non-null   float64\n",
      "dtypes: float64(20), int64(4)\n",
      "memory usage: 285.5 KB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wV2sjkqEZIup"
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4g_nWqotKl6_"
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-13T13:29:53.181043Z",
     "iopub.status.busy": "2020-10-13T13:29:53.181043Z",
     "iopub.status.idle": "2020-10-13T13:29:53.195221Z",
     "shell.execute_reply": "2020-10-13T13:29:53.194224Z",
     "shell.execute_reply.started": "2020-10-13T13:29:53.181043Z"
    },
    "id": "Qp4QHIuFZIuq"
   },
   "outputs": [],
   "source": [
    "def get_cv_score(models, X_train, y_train):\n",
    "    \n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    summary = []\n",
    "    for label, model in models.items():\n",
    "        cv_results = cross_validate(model, X_train, y_train, cv=cv, \n",
    "                                    scoring=['r2',\n",
    "                                             'neg_root_mean_squared_error',\n",
    "                                             'neg_mean_absolute_error'])\n",
    "        \n",
    "        temp = pd.DataFrame(cv_results).copy()\n",
    "        temp['Model'] = label\n",
    "        summary.append(temp)\n",
    "    \n",
    "    summary = pd.concat(summary)\n",
    "    summary = summary.groupby('Model').mean()\n",
    "    \n",
    "    summary.drop(columns=['fit_time', 'score_time'], inplace=True)\n",
    "    summary.columns = ['CV R2', 'CV RMSE', 'CV MAE']\n",
    "    summary[['CV RMSE', 'CV MAE']] = summary[['CV RMSE', 'CV MAE']] * -1\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-13T13:29:53.198250Z",
     "iopub.status.busy": "2020-10-13T13:29:53.197220Z",
     "iopub.status.idle": "2020-10-13T13:29:53.212177Z",
     "shell.execute_reply": "2020-10-13T13:29:53.210182Z",
     "shell.execute_reply.started": "2020-10-13T13:29:53.198250Z"
    },
    "id": "BXEr8F5VZIu0"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(models, X_train, X_test, y_train, y_test):\n",
    "\n",
    "    summary = {'Model':[], 'Train R2':[], 'Train RMSE':[], 'Train MAE':[],\n",
    "               'Test R2':[], 'Test RMSE':[], 'Test MAE':[]}\n",
    "\n",
    "    for label, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        summary['Model'].append(label)\n",
    "\n",
    "        summary['Train R2'].append(\n",
    "            metrics.r2_score(y_train, y_train_pred))\n",
    "        summary['Train RMSE'].append(\n",
    "            np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "        summary['Train MAE'].append(\n",
    "            metrics.mean_absolute_error(y_train, y_train_pred))\n",
    "\n",
    "        summary['Test R2'].append(\n",
    "            metrics.r2_score(y_test, y_test_pred))\n",
    "        summary['Test RMSE'].append(\n",
    "            np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))\n",
    "        summary['Test MAE'].append(\n",
    "            metrics.mean_absolute_error(y_test, y_test_pred))\n",
    "    \n",
    "    summary = pd.DataFrame(summary)\n",
    "    summary.set_index('Model', inplace=True)\n",
    "\n",
    "    cv_scores = get_cv_score(models, X_train, y_train)\n",
    "    summary = summary.join(cv_scores)\n",
    "    summary.reset_index(inplace=True)\n",
    "    summary = summary[['Train R2', 'CV R2', 'Test R2',\n",
    "                       'Train RMSE', 'CV RMSE', 'Test RMSE',\n",
    "                       'Train MAE', 'CV MAE', 'Test MAE', 'Model']]\n",
    "    \n",
    "    return round(summary.sort_values(by='CV RMSE'), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop(columns=\"Price\")\n",
    "y_train = train_data[\"Price\"]\n",
    "X_test = test_data.drop(columns=\"Price\")\n",
    "y_test = test_data[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4383, 23), (4383,), (1462, 23), (1462,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UR-TUfLrHlUy"
   },
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGwkRRZ8W43D"
   },
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PzcpvsXbjHs3"
   },
   "source": [
    "#### Study 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qwWoTc--ImFJ",
    "outputId": "906e5e9c-0da6-4023-8c34-cb82002d6584"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-10-30 12:51:06,413]\u001b[0m A new study created in memory with name: no-name-5f01eb69-b3d4-48f1-9367-26b78782afc5\u001b[0m\n",
      "\u001b[32m[I 2020-10-30 12:51:15,077]\u001b[0m Trial 0 finished with value: 4.6973112 and parameters: {'max_depth': 1, 'min_child_weight': 1, 'gamma': 0.13741488645576821, 'subsample': 0.4269568096317711, 'colsample_bytree': 0.836250440384237, 'lambda': 1.201350549061885e-05, 'alpha': 0.005055729577608604, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 4.6973112.\u001b[0m\n",
      "\u001b[32m[I 2020-10-30 12:52:19,401]\u001b[0m Trial 1 finished with value: 3.7865275999999994 and parameters: {'max_depth': 6, 'min_child_weight': 3, 'gamma': 0.12769774023948166, 'subsample': 0.7605083478923543, 'colsample_bytree': 0.10177924609534657, 'lambda': 4.582839066555021e-05, 'alpha': 3.275501370610254e-07, 'grow_policy': 'lossguide'}. Best is trial 1 with value: 3.7865275999999994.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-83e196e600ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mpruner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpruners\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMedianPruner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_warmup_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpruner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpruner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'minimize'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Number of finished trials: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ds_env\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    336\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m                 self._optimize_sequential(\n\u001b[0m\u001b[0;32m    339\u001b[0m                     \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m                 )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ds_env\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(self, func, n_trials, timeout, catch, callbacks, gc_after_trial, time_start)\u001b[0m\n\u001b[0;32m    745\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 747\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_trial_and_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    748\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_progress_bar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ds_env\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_run_trial_and_callbacks\u001b[1;34m(self, func, catch, callbacks, gc_after_trial)\u001b[0m\n\u001b[0;32m    774\u001b[0m     ) -> None:\n\u001b[0;32m    775\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 776\u001b[1;33m         \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    777\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mfrozen_trial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ds_env\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(self, func, catch, gc_after_trial)\u001b[0m\n\u001b[0;32m    797\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    798\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 799\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    800\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    801\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Trial {} pruned. {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial_number\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-83e196e600ca>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     history = xgb.cv(param, dtrain, num_boost_round=2000, \n\u001b[0m\u001b[0;32m     23\u001b[0m                      \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                      \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpruning_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ds_env\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mcv\u001b[1;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks, shuffle)\u001b[0m\n\u001b[0;32m    496\u001b[0m                            evaluation_result_list=None))\n\u001b[0;32m    497\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m             \u001b[0mfold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    499\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maggcv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ds_env\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, iteration, fobj)\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;34m\"\"\"\"Update the boosters for one iteration\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ds_env\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1158\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1159\u001b[1;33m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[0;32m   1160\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1161\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "    param = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'tree_method': 'gpu_hist',\n",
    "        'learning_rate': 0.1,\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 10),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 6),\n",
    "        'gamma': trial.suggest_loguniform(\"gamma\", 1e-8, 1.0),\n",
    "        'subsample':trial.suggest_uniform('subsample', 0.1, 1),\n",
    "        'colsample_bytree':trial.suggest_uniform('colsample_bytree', 0.1, 1),\n",
    "        \"lambda\": trial.suggest_loguniform(\"lambda\", 1e-8, 1.0),\n",
    "        \"alpha\": trial.suggest_loguniform(\"alpha\", 1e-8, 1.0),\n",
    "        \"grow_policy\": trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
    "    }\n",
    "\n",
    "    pruning_callback = optuna.integration.XGBoostPruningCallback(trial, \"test-rmse\")\n",
    "\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    history = xgb.cv(param, dtrain, num_boost_round=2000, \n",
    "                     early_stopping_rounds=100,\n",
    "                     callbacks=[pruning_callback],\n",
    "                     metrics='rmse', \n",
    "                     folds=cv)\n",
    "\n",
    "    mean_score = history[\"test-rmse-mean\"].values[-1]\n",
    "    return mean_score\n",
    "\n",
    "pruner = optuna.pruners.MedianPruner(n_warmup_steps=10)\n",
    "study = optuna.create_study(pruner=pruner, direction='minimize')\n",
    "study.optimize(objective, n_trials=1000)\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NsHKTHFSIm49",
    "outputId": "49057bf4-8362-4344-b6a3-389aa5c49421"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.7590127908977213,\n",
       " 'colsample_bytree': 0.9607197516247233,\n",
       " 'gamma': 2.3958951034113745e-07,\n",
       " 'grow_policy': 'depthwise',\n",
       " 'lambda': 0.00013762368579039482,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 10,\n",
       " 'min_child_weight': 4,\n",
       " 'objective': 'reg:squarederror',\n",
       " 'subsample': 0.6186395456914845,\n",
       " 'tree_method': 'hist'}"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get best params then add to param_1\n",
    "study_1_params = study.best_params\n",
    "param_1 = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'tree_method': 'hist',\n",
    "    'learning_rate': 0.1,\n",
    "}\n",
    "param_1.update(study_1_params)\n",
    "param_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yWR-ZmE3WxaI",
    "outputId": "a4d4dae9-188e-4b13-92fc-e9b2709bade5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "cv = KFold(\n",
    "    n_splits=5, \n",
    "    shuffle=True, \n",
    "    random_state=0\n",
    ")\n",
    "history = xgb.cv(\n",
    "    param_1, dtrain, \n",
    "    num_boost_round=2000, \n",
    "    early_stopping_rounds=100,\n",
    "    metrics='rmse',\n",
    "    folds=cv\n",
    ")\n",
    "n_estimators_1 = history.shape[0]\n",
    "n_estimators_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQ-p-_ykjMF0"
   },
   "source": [
    "#### Study 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MzSy2WLUNqhN",
    "outputId": "6fffc654-90d5-48ad-a432-13b63a4aee74"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-10-29 17:27:34,387]\u001b[0m A new study created in memory with name: no-name-9de25694-6aae-460e-bd6e-c9a1e6053a48\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:27:53,580]\u001b[0m Trial 0 finished with value: 3.169108 and parameters: {'max_depth': 3, 'min_child_weight': 4, 'gamma': 2.8175426413045556e-05, 'subsample': 0.347474169111479, 'colsample_bytree': 0.9837370310385078, 'lambda': 0.0007521936991226943, 'alpha': 0.07774597566476385, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 3.169108.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:28:24,362]\u001b[0m Trial 1 finished with value: 4.2587564 and parameters: {'max_depth': 1, 'min_child_weight': 2, 'gamma': 0.00012409400570614071, 'subsample': 0.5307739269217518, 'colsample_bytree': 0.8489245015220577, 'lambda': 0.1347898363403124, 'alpha': 1.25707339853515e-07, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 3.169108.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:28:48,100]\u001b[0m Trial 2 finished with value: 2.9726986 and parameters: {'max_depth': 5, 'min_child_weight': 4, 'gamma': 6.74640573232549e-08, 'subsample': 0.41804219456104286, 'colsample_bytree': 0.9210874847791644, 'lambda': 0.00013279420778995486, 'alpha': 0.0018597983186874147, 'grow_policy': 'depthwise'}. Best is trial 2 with value: 2.9726986.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:29:50,916]\u001b[0m Trial 3 finished with value: 2.8974316 and parameters: {'max_depth': 7, 'min_child_weight': 1, 'gamma': 1.2225476946800587e-08, 'subsample': 0.36983021033971963, 'colsample_bytree': 0.6186821934217552, 'lambda': 0.00024227054672764828, 'alpha': 1.083745225543085e-08, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 2.8974316.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:30:48,135]\u001b[0m Trial 4 finished with value: 3.3181526 and parameters: {'max_depth': 10, 'min_child_weight': 5, 'gamma': 3.071109724339959e-08, 'subsample': 0.6004496070794609, 'colsample_bytree': 0.13164332585602553, 'lambda': 1.5901172037671071e-07, 'alpha': 5.148190416269084e-08, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 2.8974316.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:31:18,306]\u001b[0m Trial 5 finished with value: 2.9674541999999997 and parameters: {'max_depth': 5, 'min_child_weight': 5, 'gamma': 0.0009342846136415374, 'subsample': 0.809874072970768, 'colsample_bytree': 0.69780309369967, 'lambda': 0.006896397284763977, 'alpha': 2.5479869140376478e-05, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 2.8974316.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:31:18,624]\u001b[0m Trial 6 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:31:18,942]\u001b[0m Trial 7 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:31:42,268]\u001b[0m Trial 8 finished with value: 2.9386262000000003 and parameters: {'max_depth': 6, 'min_child_weight': 5, 'gamma': 5.492696829733424e-06, 'subsample': 0.6020902342016663, 'colsample_bytree': 0.8473784397150925, 'lambda': 3.99951713550768e-07, 'alpha': 0.0002629883589487802, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 2.8974316.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:31:42,573]\u001b[0m Trial 9 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:31:43,291]\u001b[0m Trial 10 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:32:16,782]\u001b[0m Trial 11 finished with value: 2.9495478000000004 and parameters: {'max_depth': 8, 'min_child_weight': 3, 'gamma': 7.1283494970898925e-06, 'subsample': 0.7218116376537814, 'colsample_bytree': 0.7260264057482503, 'lambda': 1.1298316248346139e-08, 'alpha': 0.005423732967089844, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 2.8974316.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:32:17,421]\u001b[0m Trial 12 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:32:49,859]\u001b[0m Trial 13 finished with value: 2.9395246 and parameters: {'max_depth': 7, 'min_child_weight': 5, 'gamma': 0.0017189738278086911, 'subsample': 0.7460392170534869, 'colsample_bytree': 0.5955928841609346, 'lambda': 1.0740772501018961e-08, 'alpha': 0.3732725348250401, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 2.8974316.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:33:12,914]\u001b[0m Trial 14 finished with value: 2.9518596 and parameters: {'max_depth': 6, 'min_child_weight': 3, 'gamma': 1.480642325509886e-06, 'subsample': 0.44890124049056135, 'colsample_bytree': 0.8196936648354273, 'lambda': 1.797373244632211e-07, 'alpha': 2.258596285363987e-06, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 2.8974316.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:33:13,284]\u001b[0m Trial 15 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:33:13,947]\u001b[0m Trial 16 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:34:10,404]\u001b[0m Trial 17 finished with value: 2.9526164 and parameters: {'max_depth': 10, 'min_child_weight': 2, 'gamma': 1.0476836259964545e-05, 'subsample': 0.6664883167991147, 'colsample_bytree': 0.6422532231635207, 'lambda': 0.003162906621823278, 'alpha': 0.0004936711932972547, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 2.8974316.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:34:38,495]\u001b[0m Trial 18 finished with value: 2.9193038 and parameters: {'max_depth': 8, 'min_child_weight': 5, 'gamma': 2.634544398438517e-07, 'subsample': 0.48408225523117454, 'colsample_bytree': 0.8398745176624574, 'lambda': 2.8582867268214233e-05, 'alpha': 1.7472420741224543e-05, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 2.8974316.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:34:39,259]\u001b[0m Trial 19 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:34:39,886]\u001b[0m Trial 20 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:34:53,496]\u001b[0m Trial 21 pruned. Trial was pruned at iteration 437.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:35:21,602]\u001b[0m Trial 22 finished with value: 2.9281086000000003 and parameters: {'max_depth': 8, 'min_child_weight': 5, 'gamma': 1.1017378185177468e-08, 'subsample': 0.49524244994001326, 'colsample_bytree': 0.9081879720537395, 'lambda': 5.172046944517586e-05, 'alpha': 0.00040748210115556485, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 2.8974316.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:35:47,817]\u001b[0m Trial 23 pruned. Trial was pruned at iteration 753.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:36:10,407]\u001b[0m Trial 24 pruned. Trial was pruned at iteration 496.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:36:11,011]\u001b[0m Trial 25 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:36:12,024]\u001b[0m Trial 26 pruned. Trial was pruned at iteration 21.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:36:41,875]\u001b[0m Trial 27 finished with value: 2.9255374000000005 and parameters: {'max_depth': 9, 'min_child_weight': 6, 'gamma': 4.957942404651903e-07, 'subsample': 0.5222783352450787, 'colsample_bytree': 0.7801919478791957, 'lambda': 0.00208114546374228, 'alpha': 0.49891827174235087, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 2.8974316.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:36:42,456]\u001b[0m Trial 28 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:36:43,128]\u001b[0m Trial 29 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:36:43,615]\u001b[0m Trial 30 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:37:14,099]\u001b[0m Trial 31 finished with value: 2.9277230000000003 and parameters: {'max_depth': 8, 'min_child_weight': 5, 'gamma': 7.190585125014047e-08, 'subsample': 0.5188860570627423, 'colsample_bytree': 0.925783062923867, 'lambda': 0.00018227720203255795, 'alpha': 0.23209953064433522, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 2.8974316.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:37:38,804]\u001b[0m Trial 32 finished with value: 2.9409676 and parameters: {'max_depth': 7, 'min_child_weight': 6, 'gamma': 7.782605690998723e-08, 'subsample': 0.5387635142101933, 'colsample_bytree': 0.9953437695764926, 'lambda': 0.0007816540892637513, 'alpha': 0.4139521152531768, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 2.8974316.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:38:12,483]\u001b[0m Trial 33 finished with value: 2.9351542 and parameters: {'max_depth': 8, 'min_child_weight': 5, 'gamma': 2.512076072788679e-07, 'subsample': 0.672256380776256, 'colsample_bytree': 0.8948963572164991, 'lambda': 0.00024274000925353264, 'alpha': 0.9919953186537591, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 2.8974316.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:38:16,659]\u001b[0m Trial 34 pruned. Trial was pruned at iteration 55.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:38:17,159]\u001b[0m Trial 35 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:38:17,617]\u001b[0m Trial 36 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:38:59,067]\u001b[0m Trial 37 pruned. Trial was pruned at iteration 724.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:38:59,655]\u001b[0m Trial 38 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:39:02,739]\u001b[0m Trial 39 pruned. Trial was pruned at iteration 53.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:39:03,611]\u001b[0m Trial 40 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:39:32,404]\u001b[0m Trial 41 finished with value: 2.9242049999999997 and parameters: {'max_depth': 8, 'min_child_weight': 5, 'gamma': 1.1632903398092217e-08, 'subsample': 0.506772572229594, 'colsample_bytree': 0.8949449754149986, 'lambda': 6.588249821022702e-05, 'alpha': 1.051772468721552e-05, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 2.8974316.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:40:07,197]\u001b[0m Trial 42 finished with value: 2.9086410000000003 and parameters: {'max_depth': 9, 'min_child_weight': 4, 'gamma': 0.99908156117986, 'subsample': 0.5211225932069624, 'colsample_bytree': 0.9490337016491238, 'lambda': 7.480494543559946e-05, 'alpha': 8.115844553911635e-05, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 2.8974316.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:40:28,481]\u001b[0m Trial 43 pruned. Trial was pruned at iteration 376.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:41:07,891]\u001b[0m Trial 44 finished with value: 2.9147382 and parameters: {'max_depth': 9, 'min_child_weight': 4, 'gamma': 0.008073077921560423, 'subsample': 0.5791273580223322, 'colsample_bytree': 0.8744846923822347, 'lambda': 1.7973524555747914e-06, 'alpha': 1.3680233425351627e-05, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 2.8974316.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:41:40,170]\u001b[0m Trial 45 finished with value: 2.9155583999999997 and parameters: {'max_depth': 7, 'min_child_weight': 4, 'gamma': 0.02437415776040908, 'subsample': 0.578825114146708, 'colsample_bytree': 0.8770012550999351, 'lambda': 5.0346217096079244e-08, 'alpha': 8.120827059053005e-06, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 2.8974316.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:41:42,937]\u001b[0m Trial 46 pruned. Trial was pruned at iteration 66.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:41:43,678]\u001b[0m Trial 47 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:41:44,091]\u001b[0m Trial 48 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:41:45,358]\u001b[0m Trial 49 pruned. Trial was pruned at iteration 22.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:42:27,778]\u001b[0m Trial 50 finished with value: 2.9168800000000004 and parameters: {'max_depth': 10, 'min_child_weight': 4, 'gamma': 0.0004021581442803269, 'subsample': 0.5984253337614097, 'colsample_bytree': 0.7511780647355571, 'lambda': 1.3972840297253394e-06, 'alpha': 3.7200588634007916e-06, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 2.8974316.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:43:11,506]\u001b[0m Trial 51 finished with value: 2.915701 and parameters: {'max_depth': 10, 'min_child_weight': 4, 'gamma': 0.000566017627105797, 'subsample': 0.5882861576275563, 'colsample_bytree': 0.8648511267789483, 'lambda': 4.929960108809486e-07, 'alpha': 3.7380122121922437e-06, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 2.8974316.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:43:59,274]\u001b[0m Trial 52 finished with value: 2.9172988 and parameters: {'max_depth': 10, 'min_child_weight': 4, 'gamma': 0.00018532536127460254, 'subsample': 0.5999524518011315, 'colsample_bytree': 0.7426112430102378, 'lambda': 5.72976197708362e-07, 'alpha': 4.736106850158622e-06, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 2.8974316.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:44:43,994]\u001b[0m Trial 53 finished with value: 2.9284464 and parameters: {'max_depth': 10, 'min_child_weight': 4, 'gamma': 0.0004441434731074019, 'subsample': 0.6994172721676954, 'colsample_bytree': 0.7033966984187876, 'lambda': 3.604088752425439e-08, 'alpha': 1.190928579539631e-06, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 2.8974316.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:45:29,496]\u001b[0m Trial 54 finished with value: 2.9067592 and parameters: {'max_depth': 10, 'min_child_weight': 4, 'gamma': 0.006073212604927158, 'subsample': 0.6068218118313743, 'colsample_bytree': 0.870903715490191, 'lambda': 1.7132319345333711e-06, 'alpha': 6.600117655291453e-05, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 2.8974316.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:45:30,375]\u001b[0m Trial 55 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:46:00,824]\u001b[0m Trial 56 pruned. Trial was pruned at iteration 301.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:46:01,296]\u001b[0m Trial 57 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:46:40,827]\u001b[0m Trial 58 finished with value: 2.924335 and parameters: {'max_depth': 9, 'min_child_weight': 4, 'gamma': 0.01249287066083561, 'subsample': 0.6734219174497411, 'colsample_bytree': 0.8728559296881274, 'lambda': 1.784191479330032e-08, 'alpha': 2.7667036947788427e-05, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 2.8974316.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:46:41,145]\u001b[0m Trial 59 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:46:41,574]\u001b[0m Trial 60 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:47:02,287]\u001b[0m Trial 61 pruned. Trial was pruned at iteration 262.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:47:41,049]\u001b[0m Trial 62 finished with value: 2.9216046 and parameters: {'max_depth': 10, 'min_child_weight': 4, 'gamma': 0.0007440570952869664, 'subsample': 0.6043594654240599, 'colsample_bytree': 0.9352955822175553, 'lambda': 9.56293943339088e-07, 'alpha': 1.5828558059772905e-06, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 2.8974316.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:48:22,451]\u001b[0m Trial 63 finished with value: 2.9066798 and parameters: {'max_depth': 9, 'min_child_weight': 4, 'gamma': 0.006556840662552185, 'subsample': 0.6443868759289452, 'colsample_bytree': 0.8671118832795324, 'lambda': 6.037963988185184e-07, 'alpha': 6.893850476670722e-07, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 2.8974316.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:49:01,954]\u001b[0m Trial 64 finished with value: 2.9168487999999995 and parameters: {'max_depth': 9, 'min_child_weight': 4, 'gamma': 0.005189056314273901, 'subsample': 0.6326022019152383, 'colsample_bytree': 0.8347965672608941, 'lambda': 5.251714461802745e-07, 'alpha': 4.72350134373743e-07, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 2.8974316.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:49:40,851]\u001b[0m Trial 65 finished with value: 2.9145194 and parameters: {'max_depth': 9, 'min_child_weight': 4, 'gamma': 0.06734581954402545, 'subsample': 0.5654749463893545, 'colsample_bytree': 0.9140912461691855, 'lambda': 2.108320672593478e-08, 'alpha': 2.358479930284582e-07, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 2.8974316.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:50:04,506]\u001b[0m Trial 66 pruned. Trial was pruned at iteration 215.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:50:21,436]\u001b[0m Trial 67 pruned. Trial was pruned at iteration 265.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:50:22,168]\u001b[0m Trial 68 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:50:22,759]\u001b[0m Trial 69 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:50:23,215]\u001b[0m Trial 70 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:50:58,661]\u001b[0m Trial 71 pruned. Trial was pruned at iteration 494.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:51:41,240]\u001b[0m Trial 72 finished with value: 2.8976496 and parameters: {'max_depth': 9, 'min_child_weight': 4, 'gamma': 0.006919021523912965, 'subsample': 0.5761283360702373, 'colsample_bytree': 0.9355141219188441, 'lambda': 2.1781884617720787e-07, 'alpha': 7.382028734754105e-07, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 2.8974316.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:52:17,368]\u001b[0m Trial 73 finished with value: 2.9099688 and parameters: {'max_depth': 9, 'min_child_weight': 4, 'gamma': 0.007406904544872637, 'subsample': 0.5329966807002596, 'colsample_bytree': 0.9304762448814654, 'lambda': 5.0975948024803443e-08, 'alpha': 7.770220769734756e-07, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 2.8974316.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:52:47,145]\u001b[0m Trial 74 pruned. Trial was pruned at iteration 614.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:53:19,792]\u001b[0m Trial 75 pruned. Trial was pruned at iteration 604.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:54:00,371]\u001b[0m Trial 76 finished with value: 2.9102482 and parameters: {'max_depth': 9, 'min_child_weight': 3, 'gamma': 0.06013140771530339, 'subsample': 0.56281231814629, 'colsample_bytree': 0.9386028621462638, 'lambda': 1.215987845486409e-07, 'alpha': 7.97741890403625e-08, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 2.8974316.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:55:35,066]\u001b[0m Trial 77 finished with value: 2.8791281999999994 and parameters: {'max_depth': 8, 'min_child_weight': 1, 'gamma': 0.08264996105972894, 'subsample': 0.47791865485060586, 'colsample_bytree': 0.9420049690307035, 'lambda': 1.0674934630594815e-07, 'alpha': 9.499277900945256e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:57:11,851]\u001b[0m Trial 78 finished with value: 2.8936634 and parameters: {'max_depth': 8, 'min_child_weight': 1, 'gamma': 0.19964854940213114, 'subsample': 0.4895808845542274, 'colsample_bytree': 0.9438429906661696, 'lambda': 2.773233808728354e-07, 'alpha': 2.040374678204322e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:57:12,583]\u001b[0m Trial 79 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:57:13,372]\u001b[0m Trial 80 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:57:35,149]\u001b[0m Trial 81 pruned. Trial was pruned at iteration 300.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:57:59,947]\u001b[0m Trial 82 pruned. Trial was pruned at iteration 326.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:58:17,078]\u001b[0m Trial 83 pruned. Trial was pruned at iteration 229.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:58:39,169]\u001b[0m Trial 84 pruned. Trial was pruned at iteration 204.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:58:53,354]\u001b[0m Trial 85 pruned. Trial was pruned at iteration 173.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:58:54,072]\u001b[0m Trial 86 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:59:16,185]\u001b[0m Trial 87 pruned. Trial was pruned at iteration 214.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:59:16,955]\u001b[0m Trial 88 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:59:43,763]\u001b[0m Trial 89 pruned. Trial was pruned at iteration 258.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 17:59:54,055]\u001b[0m Trial 90 pruned. Trial was pruned at iteration 214.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:00:32,220]\u001b[0m Trial 91 finished with value: 2.9129984 and parameters: {'max_depth': 9, 'min_child_weight': 4, 'gamma': 0.06597216746829405, 'subsample': 0.5502636309312031, 'colsample_bytree': 0.9248894376641555, 'lambda': 2.3398957871265504e-08, 'alpha': 0.0010720356633471646, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:01:08,270]\u001b[0m Trial 92 finished with value: 2.9229278 and parameters: {'max_depth': 9, 'min_child_weight': 4, 'gamma': 0.04697665029051533, 'subsample': 0.5518947156648168, 'colsample_bytree': 0.9741348541793242, 'lambda': 3.3989232818403266e-07, 'alpha': 0.0012430037027472006, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:01:54,534]\u001b[0m Trial 93 pruned. Trial was pruned at iteration 914.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:02:34,997]\u001b[0m Trial 94 pruned. Trial was pruned at iteration 914.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:02:35,838]\u001b[0m Trial 95 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:02:37,021]\u001b[0m Trial 96 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:02:37,992]\u001b[0m Trial 97 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:02:58,882]\u001b[0m Trial 98 pruned. Trial was pruned at iteration 426.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:02:59,585]\u001b[0m Trial 99 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:03:40,776]\u001b[0m Trial 100 pruned. Trial was pruned at iteration 677.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:03:42,632]\u001b[0m Trial 101 pruned. Trial was pruned at iteration 20.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:04:21,437]\u001b[0m Trial 102 finished with value: 2.9127959999999997 and parameters: {'max_depth': 9, 'min_child_weight': 4, 'gamma': 0.06508738214015433, 'subsample': 0.616419048820156, 'colsample_bytree': 0.9165883461924788, 'lambda': 0.0002474210567750223, 'alpha': 6.185956467568924e-05, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:04:56,280]\u001b[0m Trial 103 pruned. Trial was pruned at iteration 700.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:04:57,285]\u001b[0m Trial 104 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:05:31,964]\u001b[0m Trial 105 pruned. Trial was pruned at iteration 696.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:06:12,368]\u001b[0m Trial 106 finished with value: 2.9203564 and parameters: {'max_depth': 10, 'min_child_weight': 4, 'gamma': 0.05122667068562929, 'subsample': 0.5848360699904679, 'colsample_bytree': 0.9471281635434341, 'lambda': 0.0006943879504444535, 'alpha': 1.9448894667997792e-05, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:06:13,380]\u001b[0m Trial 107 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:06:14,852]\u001b[0m Trial 108 pruned. Trial was pruned at iteration 20.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:06:15,747]\u001b[0m Trial 109 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:06:16,589]\u001b[0m Trial 110 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:06:18,449]\u001b[0m Trial 111 pruned. Trial was pruned at iteration 20.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:06:50,827]\u001b[0m Trial 112 pruned. Trial was pruned at iteration 638.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:07:16,682]\u001b[0m Trial 113 pruned. Trial was pruned at iteration 469.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:07:55,630]\u001b[0m Trial 114 finished with value: 2.9194154 and parameters: {'max_depth': 10, 'min_child_weight': 4, 'gamma': 0.006524683993112237, 'subsample': 0.5963404413425492, 'colsample_bytree': 0.9616073838652156, 'lambda': 6.553431374955111e-08, 'alpha': 1.5652523230301394e-06, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:07:56,493]\u001b[0m Trial 115 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:07:57,536]\u001b[0m Trial 116 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:08:30,661]\u001b[0m Trial 117 finished with value: 2.9244163999999997 and parameters: {'max_depth': 9, 'min_child_weight': 3, 'gamma': 0.07447820461196289, 'subsample': 0.4647281610219321, 'colsample_bytree': 0.9251113627043424, 'lambda': 0.0001259298194243364, 'alpha': 6.173065826997615e-06, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:08:31,484]\u001b[0m Trial 118 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:09:09,460]\u001b[0m Trial 119 finished with value: 2.8950196000000004 and parameters: {'max_depth': 9, 'min_child_weight': 3, 'gamma': 0.16804513573298135, 'subsample': 0.5458182650363438, 'colsample_bytree': 0.8632067347233736, 'lambda': 5.684924888277777e-08, 'alpha': 7.229164399277014e-07, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:09:12,072]\u001b[0m Trial 120 pruned. Trial was pruned at iteration 24.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:09:32,525]\u001b[0m Trial 121 pruned. Trial was pruned at iteration 263.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:10:17,997]\u001b[0m Trial 122 finished with value: 2.9005123999999998 and parameters: {'max_depth': 9, 'min_child_weight': 3, 'gamma': 0.09933925504375507, 'subsample': 0.5698341176506091, 'colsample_bytree': 0.908699280710635, 'lambda': 4.5991413389306726e-08, 'alpha': 1.5979549427475172e-06, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:10:48,175]\u001b[0m Trial 123 pruned. Trial was pruned at iteration 513.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:10:48,834]\u001b[0m Trial 124 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:11:11,750]\u001b[0m Trial 125 pruned. Trial was pruned at iteration 321.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:11:12,887]\u001b[0m Trial 126 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:11:53,320]\u001b[0m Trial 127 pruned. Trial was pruned at iteration 560.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:12:07,514]\u001b[0m Trial 128 pruned. Trial was pruned at iteration 181.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:12:34,459]\u001b[0m Trial 129 pruned. Trial was pruned at iteration 340.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:12:35,454]\u001b[0m Trial 130 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:12:36,388]\u001b[0m Trial 131 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:12:38,075]\u001b[0m Trial 132 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:13:10,583]\u001b[0m Trial 133 finished with value: 2.9226149999999995 and parameters: {'max_depth': 9, 'min_child_weight': 4, 'gamma': 0.0711613511137284, 'subsample': 0.5979928858495585, 'colsample_bytree': 0.9008435984439266, 'lambda': 1.0076821808451424e-08, 'alpha': 4.4629869452358547e-07, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:13:11,574]\u001b[0m Trial 134 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:13:49,553]\u001b[0m Trial 135 finished with value: 2.9253038 and parameters: {'max_depth': 10, 'min_child_weight': 4, 'gamma': 0.018423093233826713, 'subsample': 0.5718956396499152, 'colsample_bytree': 0.9545528357086068, 'lambda': 3.295298618834222e-08, 'alpha': 1.8775260070760098e-06, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:13:52,883]\u001b[0m Trial 136 pruned. Trial was pruned at iteration 36.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:13:53,813]\u001b[0m Trial 137 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:14:30,448]\u001b[0m Trial 138 finished with value: 2.9199669999999998 and parameters: {'max_depth': 9, 'min_child_weight': 3, 'gamma': 0.30978263911364107, 'subsample': 0.6144187973795215, 'colsample_bytree': 0.9268691171133174, 'lambda': 2.8115892081085443e-07, 'alpha': 1.0120679271474556e-06, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:14:31,177]\u001b[0m Trial 139 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:14:57,830]\u001b[0m Trial 140 pruned. Trial was pruned at iteration 186.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:14:58,889]\u001b[0m Trial 141 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:15:00,660]\u001b[0m Trial 142 pruned. Trial was pruned at iteration 20.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:15:02,299]\u001b[0m Trial 143 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:15:03,708]\u001b[0m Trial 144 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:15:10,790]\u001b[0m Trial 145 pruned. Trial was pruned at iteration 107.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:15:11,805]\u001b[0m Trial 146 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:15:12,653]\u001b[0m Trial 147 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:15:34,216]\u001b[0m Trial 148 pruned. Trial was pruned at iteration 313.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:15:56,063]\u001b[0m Trial 149 pruned. Trial was pruned at iteration 136.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:16:25,148]\u001b[0m Trial 150 pruned. Trial was pruned at iteration 514.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:16:25,728]\u001b[0m Trial 151 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:16:26,443]\u001b[0m Trial 152 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:16:27,017]\u001b[0m Trial 153 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:16:27,641]\u001b[0m Trial 154 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:16:28,152]\u001b[0m Trial 155 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:16:29,065]\u001b[0m Trial 156 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:17:11,115]\u001b[0m Trial 157 finished with value: 2.9103594 and parameters: {'max_depth': 9, 'min_child_weight': 4, 'gamma': 0.004335574173278243, 'subsample': 0.5567282304597764, 'colsample_bytree': 0.9594176281125157, 'lambda': 2.2895964852281362e-07, 'alpha': 3.4728953810844505e-05, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:17:33,078]\u001b[0m Trial 158 pruned. Trial was pruned at iteration 365.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:17:35,033]\u001b[0m Trial 159 pruned. Trial was pruned at iteration 21.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:18:08,701]\u001b[0m Trial 160 pruned. Trial was pruned at iteration 513.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:18:27,032]\u001b[0m Trial 161 pruned. Trial was pruned at iteration 261.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:18:53,988]\u001b[0m Trial 162 pruned. Trial was pruned at iteration 494.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:19:26,753]\u001b[0m Trial 163 finished with value: 2.9198551999999998 and parameters: {'max_depth': 9, 'min_child_weight': 4, 'gamma': 0.11936059151492551, 'subsample': 0.5924461855068677, 'colsample_bytree': 0.9357816559060961, 'lambda': 3.086358414824529e-07, 'alpha': 0.00011737071123805225, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:19:42,021]\u001b[0m Trial 164 pruned. Trial was pruned at iteration 248.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:19:43,374]\u001b[0m Trial 165 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:19:44,567]\u001b[0m Trial 166 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:20:20,823]\u001b[0m Trial 167 finished with value: 2.9177723999999996 and parameters: {'max_depth': 9, 'min_child_weight': 4, 'gamma': 0.19803114404310862, 'subsample': 0.6122723234613546, 'colsample_bytree': 0.9999101767165726, 'lambda': 9.903942263564718e-05, 'alpha': 1.629956753435604e-07, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:20:21,566]\u001b[0m Trial 168 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:20:23,079]\u001b[0m Trial 169 pruned. Trial was pruned at iteration 20.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:20:23,720]\u001b[0m Trial 170 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:20:24,893]\u001b[0m Trial 171 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:20:26,093]\u001b[0m Trial 172 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:21:11,661]\u001b[0m Trial 173 finished with value: 2.9159016 and parameters: {'max_depth': 10, 'min_child_weight': 4, 'gamma': 3.510695845854494e-05, 'subsample': 0.6060512097746542, 'colsample_bytree': 0.8738215787809025, 'lambda': 3.8218784484727035e-07, 'alpha': 7.875154194357373e-06, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:21:31,491]\u001b[0m Trial 174 pruned. Trial was pruned at iteration 264.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:21:32,783]\u001b[0m Trial 175 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:21:34,462]\u001b[0m Trial 176 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:21:35,472]\u001b[0m Trial 177 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:21:36,513]\u001b[0m Trial 178 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:21:37,958]\u001b[0m Trial 179 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:22:02,361]\u001b[0m Trial 180 pruned. Trial was pruned at iteration 374.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:22:48,058]\u001b[0m Trial 181 finished with value: 2.9099218000000002 and parameters: {'max_depth': 10, 'min_child_weight': 4, 'gamma': 0.0824157122066203, 'subsample': 0.6048629695533388, 'colsample_bytree': 0.8747648749983225, 'lambda': 3.597096987657075e-07, 'alpha': 4.683195153744041e-06, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:23:13,668]\u001b[0m Trial 182 pruned. Trial was pruned at iteration 294.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:23:14,642]\u001b[0m Trial 183 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:23:59,802]\u001b[0m Trial 184 finished with value: 2.9102764 and parameters: {'max_depth': 10, 'min_child_weight': 4, 'gamma': 6.713030837965026e-05, 'subsample': 0.5875717666688239, 'colsample_bytree': 0.9163770436668088, 'lambda': 1.878034453999976e-07, 'alpha': 1.5722547369715077e-06, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:24:00,859]\u001b[0m Trial 185 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:24:39,582]\u001b[0m Trial 186 finished with value: 2.9137356 and parameters: {'max_depth': 10, 'min_child_weight': 4, 'gamma': 0.17970878179268074, 'subsample': 0.588505578436665, 'colsample_bytree': 0.9655216775365556, 'lambda': 1.3978406689345425e-07, 'alpha': 1.6399030746423753e-06, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:25:18,554]\u001b[0m Trial 187 finished with value: 2.9148736 and parameters: {'max_depth': 10, 'min_child_weight': 4, 'gamma': 3.1390018271775994e-06, 'subsample': 0.5968310322220329, 'colsample_bytree': 0.9628618101017435, 'lambda': 1.3396421798212212e-07, 'alpha': 1.8015793034978864e-06, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:25:47,567]\u001b[0m Trial 188 pruned. Trial was pruned at iteration 313.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:26:20,682]\u001b[0m Trial 189 pruned. Trial was pruned at iteration 435.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:26:53,082]\u001b[0m Trial 190 pruned. Trial was pruned at iteration 505.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:27:35,174]\u001b[0m Trial 191 pruned. Trial was pruned at iteration 776.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:28:19,179]\u001b[0m Trial 192 finished with value: 2.906966 and parameters: {'max_depth': 10, 'min_child_weight': 4, 'gamma': 0.15849407769969695, 'subsample': 0.582573324822038, 'colsample_bytree': 0.9523934693668173, 'lambda': 7.380740226765972e-08, 'alpha': 1.8833624285139545e-06, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:28:21,605]\u001b[0m Trial 193 pruned. Trial was pruned at iteration 22.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:28:22,924]\u001b[0m Trial 194 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:28:25,592]\u001b[0m Trial 195 pruned. Trial was pruned at iteration 25.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:28:48,577]\u001b[0m Trial 196 pruned. Trial was pruned at iteration 300.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:29:23,185]\u001b[0m Trial 197 finished with value: 2.9200907999999997 and parameters: {'max_depth': 9, 'min_child_weight': 4, 'gamma': 0.08580825603265073, 'subsample': 0.5827411795015086, 'colsample_bytree': 0.9549111565375976, 'lambda': 7.479057409527016e-07, 'alpha': 2.973900350649874e-06, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:29:45,640]\u001b[0m Trial 198 pruned. Trial was pruned at iteration 133.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:29:46,726]\u001b[0m Trial 199 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:30:07,196]\u001b[0m Trial 200 pruned. Trial was pruned at iteration 171.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:30:46,263]\u001b[0m Trial 201 finished with value: 2.9169723999999997 and parameters: {'max_depth': 10, 'min_child_weight': 4, 'gamma': 8.330447826427933e-06, 'subsample': 0.599107345225988, 'colsample_bytree': 0.9663258665192659, 'lambda': 1.1958542429291606e-07, 'alpha': 1.5997644922682374e-06, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:31:24,904]\u001b[0m Trial 202 finished with value: 2.904841 and parameters: {'max_depth': 10, 'min_child_weight': 4, 'gamma': 1.9860544710705414e-06, 'subsample': 0.589954801405989, 'colsample_bytree': 0.9609418511165969, 'lambda': 8.652384278832938e-08, 'alpha': 2.514840163427668e-06, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:31:49,068]\u001b[0m Trial 203 pruned. Trial was pruned at iteration 263.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:31:50,496]\u001b[0m Trial 204 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:31:52,473]\u001b[0m Trial 205 pruned. Trial was pruned at iteration 21.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:31:55,106]\u001b[0m Trial 206 pruned. Trial was pruned at iteration 25.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:32:22,936]\u001b[0m Trial 207 pruned. Trial was pruned at iteration 405.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:32:24,012]\u001b[0m Trial 208 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:32:26,653]\u001b[0m Trial 209 pruned. Trial was pruned at iteration 25.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:33:00,414]\u001b[0m Trial 210 pruned. Trial was pruned at iteration 423.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:33:32,591]\u001b[0m Trial 211 pruned. Trial was pruned at iteration 429.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:33:33,897]\u001b[0m Trial 212 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:34:04,476]\u001b[0m Trial 213 pruned. Trial was pruned at iteration 384.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:34:53,765]\u001b[0m Trial 214 finished with value: 2.8984656 and parameters: {'max_depth': 10, 'min_child_weight': 4, 'gamma': 4.961000950584077e-07, 'subsample': 0.5895195307404126, 'colsample_bytree': 0.9311211738033331, 'lambda': 1.3734244667566983e-07, 'alpha': 1.1851306642925286e-07, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:34:54,856]\u001b[0m Trial 215 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:34:56,404]\u001b[0m Trial 216 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:34:57,431]\u001b[0m Trial 217 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:35:11,104]\u001b[0m Trial 218 pruned. Trial was pruned at iteration 168.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:35:22,161]\u001b[0m Trial 219 pruned. Trial was pruned at iteration 115.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:35:23,000]\u001b[0m Trial 220 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:35:24,153]\u001b[0m Trial 221 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:35:59,977]\u001b[0m Trial 222 pruned. Trial was pruned at iteration 549.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:36:30,006]\u001b[0m Trial 223 pruned. Trial was pruned at iteration 398.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:37:00,475]\u001b[0m Trial 224 pruned. Trial was pruned at iteration 363.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:37:01,412]\u001b[0m Trial 225 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:37:28,422]\u001b[0m Trial 226 pruned. Trial was pruned at iteration 166.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:37:29,543]\u001b[0m Trial 227 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:37:29,880]\u001b[0m Trial 228 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:37:56,536]\u001b[0m Trial 229 pruned. Trial was pruned at iteration 398.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:37:57,624]\u001b[0m Trial 230 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:37:58,193]\u001b[0m Trial 231 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:37:58,912]\u001b[0m Trial 232 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:37:59,814]\u001b[0m Trial 233 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:38:00,172]\u001b[0m Trial 234 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:38:36,488]\u001b[0m Trial 235 finished with value: 2.9069290000000003 and parameters: {'max_depth': 9, 'min_child_weight': 4, 'gamma': 0.030227789679211407, 'subsample': 0.5286744697815334, 'colsample_bytree': 0.9536152041751667, 'lambda': 3.441940938199717e-08, 'alpha': 4.529281407308674e-06, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:38:37,536]\u001b[0m Trial 236 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:38:38,593]\u001b[0m Trial 237 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:38:40,535]\u001b[0m Trial 238 pruned. Trial was pruned at iteration 21.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:39:16,941]\u001b[0m Trial 239 finished with value: 2.9081234 and parameters: {'max_depth': 9, 'min_child_weight': 4, 'gamma': 0.1356778127946714, 'subsample': 0.528616824824221, 'colsample_bytree': 0.9506981776174733, 'lambda': 3.492865049459723e-07, 'alpha': 6.464410454710883e-07, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:39:17,972]\u001b[0m Trial 240 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:39:40,394]\u001b[0m Trial 241 pruned. Trial was pruned at iteration 350.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:40:02,927]\u001b[0m Trial 242 pruned. Trial was pruned at iteration 329.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:40:22,990]\u001b[0m Trial 243 pruned. Trial was pruned at iteration 292.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:40:24,472]\u001b[0m Trial 244 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:40:25,471]\u001b[0m Trial 245 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:40:26,562]\u001b[0m Trial 246 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:40:28,147]\u001b[0m Trial 247 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:40:31,476]\u001b[0m Trial 248 pruned. Trial was pruned at iteration 38.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:41:14,563]\u001b[0m Trial 249 finished with value: 2.9162694 and parameters: {'max_depth': 9, 'min_child_weight': 3, 'gamma': 0.013883188859808394, 'subsample': 0.6205941354707902, 'colsample_bytree': 0.9494076874322275, 'lambda': 9.775827150271313e-08, 'alpha': 1.0209759816332964e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:41:15,551]\u001b[0m Trial 250 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:41:16,623]\u001b[0m Trial 251 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:41:49,577]\u001b[0m Trial 252 pruned. Trial was pruned at iteration 475.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:41:50,690]\u001b[0m Trial 253 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:41:54,053]\u001b[0m Trial 254 pruned. Trial was pruned at iteration 39.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:41:55,292]\u001b[0m Trial 255 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:42:00,913]\u001b[0m Trial 256 pruned. Trial was pruned at iteration 64.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:42:01,966]\u001b[0m Trial 257 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:42:03,270]\u001b[0m Trial 258 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:42:04,389]\u001b[0m Trial 259 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:42:33,486]\u001b[0m Trial 260 pruned. Trial was pruned at iteration 497.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:42:34,801]\u001b[0m Trial 261 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:42:35,848]\u001b[0m Trial 262 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:43:17,053]\u001b[0m Trial 263 finished with value: 2.9059947999999998 and parameters: {'max_depth': 9, 'min_child_weight': 4, 'gamma': 0.07802945808051809, 'subsample': 0.640067418723077, 'colsample_bytree': 0.9111289550144579, 'lambda': 4.905093381177412e-05, 'alpha': 1.311539500412296e-06, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:43:38,987]\u001b[0m Trial 264 pruned. Trial was pruned at iteration 302.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:44:03,623]\u001b[0m Trial 265 pruned. Trial was pruned at iteration 338.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:44:04,654]\u001b[0m Trial 266 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:44:06,018]\u001b[0m Trial 267 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:44:32,537]\u001b[0m Trial 268 pruned. Trial was pruned at iteration 299.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:44:33,638]\u001b[0m Trial 269 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:44:34,641]\u001b[0m Trial 270 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:44:54,094]\u001b[0m Trial 271 pruned. Trial was pruned at iteration 252.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:44:54,975]\u001b[0m Trial 272 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:44:55,847]\u001b[0m Trial 273 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:44:56,636]\u001b[0m Trial 274 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:45:03,728]\u001b[0m Trial 275 pruned. Trial was pruned at iteration 86.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:45:04,788]\u001b[0m Trial 276 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:45:05,673]\u001b[0m Trial 277 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:45:06,760]\u001b[0m Trial 278 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:45:08,279]\u001b[0m Trial 279 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:45:09,193]\u001b[0m Trial 280 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:45:10,005]\u001b[0m Trial 281 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:45:10,916]\u001b[0m Trial 282 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:45:11,817]\u001b[0m Trial 283 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:45:15,610]\u001b[0m Trial 284 pruned. Trial was pruned at iteration 38.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:45:50,643]\u001b[0m Trial 285 pruned. Trial was pruned at iteration 526.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:46:26,243]\u001b[0m Trial 286 finished with value: 2.9147564 and parameters: {'max_depth': 9, 'min_child_weight': 4, 'gamma': 0.005295959043299497, 'subsample': 0.6149586793569427, 'colsample_bytree': 0.9130489357846819, 'lambda': 3.1750582708323284e-07, 'alpha': 1.2468831063406508e-06, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:46:52,930]\u001b[0m Trial 287 pruned. Trial was pruned at iteration 358.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:46:54,080]\u001b[0m Trial 288 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:47:05,567]\u001b[0m Trial 289 pruned. Trial was pruned at iteration 94.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:47:06,277]\u001b[0m Trial 290 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:47:07,265]\u001b[0m Trial 291 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:47:07,705]\u001b[0m Trial 292 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:47:08,601]\u001b[0m Trial 293 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:47:22,225]\u001b[0m Trial 294 pruned. Trial was pruned at iteration 171.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:48:09,128]\u001b[0m Trial 295 finished with value: 2.9117588000000003 and parameters: {'max_depth': 10, 'min_child_weight': 4, 'gamma': 0.035358992876761024, 'subsample': 0.5868775244576062, 'colsample_bytree': 0.9639543653529111, 'lambda': 4.7521447924303813e-07, 'alpha': 2.920061191157352e-06, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:48:38,481]\u001b[0m Trial 296 pruned. Trial was pruned at iteration 312.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:49:10,565]\u001b[0m Trial 297 pruned. Trial was pruned at iteration 191.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:49:51,228]\u001b[0m Trial 298 finished with value: 2.9113452000000004 and parameters: {'max_depth': 10, 'min_child_weight': 4, 'gamma': 0.054229153595651544, 'subsample': 0.5848813941965469, 'colsample_bytree': 0.9753073993151063, 'lambda': 3.1847822170328567e-07, 'alpha': 1.8887386822442317e-06, 'grow_policy': 'lossguide'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:50:24,086]\u001b[0m Trial 299 pruned. Trial was pruned at iteration 462.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:50:59,397]\u001b[0m Trial 300 pruned. Trial was pruned at iteration 465.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:51:00,719]\u001b[0m Trial 301 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:51:32,227]\u001b[0m Trial 302 pruned. Trial was pruned at iteration 404.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:52:04,873]\u001b[0m Trial 303 pruned. Trial was pruned at iteration 407.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:52:06,108]\u001b[0m Trial 304 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:52:50,743]\u001b[0m Trial 305 finished with value: 2.9103882 and parameters: {'max_depth': 10, 'min_child_weight': 4, 'gamma': 0.19813291785856108, 'subsample': 0.5945610609508145, 'colsample_bytree': 0.9643257373724848, 'lambda': 1.4401842065915305e-07, 'alpha': 9.724386955366175e-07, 'grow_policy': 'lossguide'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:52:51,851]\u001b[0m Trial 306 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:53:16,084]\u001b[0m Trial 307 pruned. Trial was pruned at iteration 265.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:53:55,344]\u001b[0m Trial 308 finished with value: 2.9159423999999996 and parameters: {'max_depth': 10, 'min_child_weight': 4, 'gamma': 0.12647334485662873, 'subsample': 0.5952485145886819, 'colsample_bytree': 0.9943380407055674, 'lambda': 0.0002316191693044029, 'alpha': 2.4762918903315608e-08, 'grow_policy': 'lossguide'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:54:12,764]\u001b[0m Trial 309 pruned. Trial was pruned at iteration 282.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:54:34,224]\u001b[0m Trial 310 pruned. Trial was pruned at iteration 134.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:54:35,499]\u001b[0m Trial 311 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:54:37,036]\u001b[0m Trial 312 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:54:42,005]\u001b[0m Trial 313 pruned. Trial was pruned at iteration 48.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:54:42,636]\u001b[0m Trial 314 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:54:43,616]\u001b[0m Trial 315 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:54:44,339]\u001b[0m Trial 316 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:54:45,154]\u001b[0m Trial 317 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:54:47,189]\u001b[0m Trial 318 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:54:48,157]\u001b[0m Trial 319 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:54:49,902]\u001b[0m Trial 320 pruned. Trial was pruned at iteration 19.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:54:50,990]\u001b[0m Trial 321 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:55:37,753]\u001b[0m Trial 322 finished with value: 2.9185578000000003 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 0.16275279707450074, 'subsample': 0.6163480923690786, 'colsample_bytree': 0.9794361790891922, 'lambda': 7.454365202483901e-08, 'alpha': 0.003448965969461748, 'grow_policy': 'lossguide'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:55:38,774]\u001b[0m Trial 323 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:55:39,945]\u001b[0m Trial 324 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:55:40,460]\u001b[0m Trial 325 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:55:41,696]\u001b[0m Trial 326 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:55:42,692]\u001b[0m Trial 327 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:55:43,732]\u001b[0m Trial 328 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:56:10,883]\u001b[0m Trial 329 pruned. Trial was pruned at iteration 301.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:56:12,067]\u001b[0m Trial 330 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:56:12,962]\u001b[0m Trial 331 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:56:13,825]\u001b[0m Trial 332 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:56:14,755]\u001b[0m Trial 333 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:56:43,329]\u001b[0m Trial 334 pruned. Trial was pruned at iteration 171.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:57:07,250]\u001b[0m Trial 335 pruned. Trial was pruned at iteration 279.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:57:08,548]\u001b[0m Trial 336 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:57:09,616]\u001b[0m Trial 337 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:57:10,869]\u001b[0m Trial 338 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:57:11,940]\u001b[0m Trial 339 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:57:13,420]\u001b[0m Trial 340 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:57:14,707]\u001b[0m Trial 341 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:57:15,422]\u001b[0m Trial 342 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:57:17,539]\u001b[0m Trial 343 pruned. Trial was pruned at iteration 23.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:57:46,421]\u001b[0m Trial 344 pruned. Trial was pruned at iteration 314.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:57:47,047]\u001b[0m Trial 345 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:57:51,967]\u001b[0m Trial 346 pruned. Trial was pruned at iteration 48.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:58:22,122]\u001b[0m Trial 347 pruned. Trial was pruned at iteration 337.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:59:03,454]\u001b[0m Trial 348 finished with value: 2.9114934000000003 and parameters: {'max_depth': 9, 'min_child_weight': 4, 'gamma': 0.15454737511748026, 'subsample': 0.6487728505835884, 'colsample_bytree': 0.9113778517501688, 'lambda': 5.09900644724987e-05, 'alpha': 4.718633629440769e-06, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:59:05,143]\u001b[0m Trial 349 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:59:28,867]\u001b[0m Trial 350 pruned. Trial was pruned at iteration 264.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 18:59:43,136]\u001b[0m Trial 351 pruned. Trial was pruned at iteration 226.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:00:11,207]\u001b[0m Trial 352 pruned. Trial was pruned at iteration 440.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:00:12,145]\u001b[0m Trial 353 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:00:33,209]\u001b[0m Trial 354 pruned. Trial was pruned at iteration 184.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:00:56,510]\u001b[0m Trial 355 pruned. Trial was pruned at iteration 311.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:01:22,904]\u001b[0m Trial 356 pruned. Trial was pruned at iteration 149.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:01:31,695]\u001b[0m Trial 357 pruned. Trial was pruned at iteration 105.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:02:02,687]\u001b[0m Trial 358 pruned. Trial was pruned at iteration 361.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:02:03,702]\u001b[0m Trial 359 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:02:04,627]\u001b[0m Trial 360 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:02:05,451]\u001b[0m Trial 361 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:02:06,518]\u001b[0m Trial 362 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:02:07,517]\u001b[0m Trial 363 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:02:47,501]\u001b[0m Trial 364 finished with value: 2.9201013999999996 and parameters: {'max_depth': 10, 'min_child_weight': 4, 'gamma': 0.09103329736544348, 'subsample': 0.6158984782139214, 'colsample_bytree': 0.9659384820806017, 'lambda': 3.0647754858628685e-07, 'alpha': 3.213513831391037e-07, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:02:48,951]\u001b[0m Trial 365 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:02:49,523]\u001b[0m Trial 366 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:02:50,251]\u001b[0m Trial 367 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:03:17,814]\u001b[0m Trial 368 pruned. Trial was pruned at iteration 308.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:03:18,219]\u001b[0m Trial 369 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:03:19,338]\u001b[0m Trial 370 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:03:51,523]\u001b[0m Trial 371 pruned. Trial was pruned at iteration 535.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:03:52,961]\u001b[0m Trial 372 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:03:53,816]\u001b[0m Trial 373 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:03:55,041]\u001b[0m Trial 374 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:04:03,594]\u001b[0m Trial 375 pruned. Trial was pruned at iteration 71.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:04:38,504]\u001b[0m Trial 376 pruned. Trial was pruned at iteration 523.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:04:39,456]\u001b[0m Trial 377 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:05:16,661]\u001b[0m Trial 378 finished with value: 2.9102705999999996 and parameters: {'max_depth': 9, 'min_child_weight': 3, 'gamma': 0.1848052762768447, 'subsample': 0.6283665697024274, 'colsample_bytree': 0.9358933342194771, 'lambda': 1.0839103698191785e-07, 'alpha': 2.5420654774501926e-05, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:05:40,158]\u001b[0m Trial 379 pruned. Trial was pruned at iteration 279.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:06:06,728]\u001b[0m Trial 380 pruned. Trial was pruned at iteration 270.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:06:34,665]\u001b[0m Trial 381 pruned. Trial was pruned at iteration 378.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:06:49,057]\u001b[0m Trial 382 pruned. Trial was pruned at iteration 121.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:07:33,905]\u001b[0m Trial 383 finished with value: 2.896025 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 0.1416924543251953, 'subsample': 0.5121513319300404, 'colsample_bytree': 0.9452678899731238, 'lambda': 8.074062785694717e-08, 'alpha': 8.176395843604013e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:07:35,027]\u001b[0m Trial 384 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:07:35,784]\u001b[0m Trial 385 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:07:36,664]\u001b[0m Trial 386 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:07:39,393]\u001b[0m Trial 387 pruned. Trial was pruned at iteration 24.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:07:40,353]\u001b[0m Trial 388 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:08:09,292]\u001b[0m Trial 389 pruned. Trial was pruned at iteration 316.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:08:11,906]\u001b[0m Trial 390 pruned. Trial was pruned at iteration 28.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:08:34,105]\u001b[0m Trial 391 pruned. Trial was pruned at iteration 253.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:08:42,824]\u001b[0m Trial 392 pruned. Trial was pruned at iteration 81.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:09:22,002]\u001b[0m Trial 393 finished with value: 2.9129398 and parameters: {'max_depth': 9, 'min_child_weight': 3, 'gamma': 3.912271498347173e-06, 'subsample': 0.5170832344174765, 'colsample_bytree': 0.9791480030758661, 'lambda': 2.1237009664837934e-07, 'alpha': 1.7706625728100146e-05, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:09:24,042]\u001b[0m Trial 394 pruned. Trial was pruned at iteration 24.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:09:25,170]\u001b[0m Trial 395 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:09:26,463]\u001b[0m Trial 396 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:10:00,799]\u001b[0m Trial 397 pruned. Trial was pruned at iteration 406.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:10:04,253]\u001b[0m Trial 398 pruned. Trial was pruned at iteration 38.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:10:05,341]\u001b[0m Trial 399 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:10:07,162]\u001b[0m Trial 400 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:10:32,574]\u001b[0m Trial 401 pruned. Trial was pruned at iteration 288.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:11:01,151]\u001b[0m Trial 402 pruned. Trial was pruned at iteration 380.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:11:02,229]\u001b[0m Trial 403 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:11:03,255]\u001b[0m Trial 404 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:11:04,141]\u001b[0m Trial 405 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:11:05,480]\u001b[0m Trial 406 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:11:06,678]\u001b[0m Trial 407 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:11:07,409]\u001b[0m Trial 408 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:11:08,831]\u001b[0m Trial 409 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:11:09,418]\u001b[0m Trial 410 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:11:39,696]\u001b[0m Trial 411 pruned. Trial was pruned at iteration 363.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:12:08,515]\u001b[0m Trial 412 finished with value: 2.9153072 and parameters: {'max_depth': 8, 'min_child_weight': 4, 'gamma': 0.003937052193230313, 'subsample': 0.6165030637705131, 'colsample_bytree': 0.9989016572606786, 'lambda': 2.2549475557095355e-07, 'alpha': 5.837786756559959e-05, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:12:09,723]\u001b[0m Trial 413 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:12:36,505]\u001b[0m Trial 414 pruned. Trial was pruned at iteration 237.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:12:37,497]\u001b[0m Trial 415 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:12:38,575]\u001b[0m Trial 416 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:12:39,974]\u001b[0m Trial 417 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:13:06,286]\u001b[0m Trial 418 pruned. Trial was pruned at iteration 158.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:13:07,264]\u001b[0m Trial 419 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:13:08,194]\u001b[0m Trial 420 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:13:25,872]\u001b[0m Trial 421 pruned. Trial was pruned at iteration 181.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:13:27,135]\u001b[0m Trial 422 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:13:28,172]\u001b[0m Trial 423 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:13:28,795]\u001b[0m Trial 424 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:14:07,938]\u001b[0m Trial 425 finished with value: 2.9106622000000004 and parameters: {'max_depth': 10, 'min_child_weight': 4, 'gamma': 2.5240842090900654e-07, 'subsample': 0.6049940659685535, 'colsample_bytree': 0.9184928137561109, 'lambda': 4.564853967047626e-07, 'alpha': 5.818198624917164e-07, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:14:40,609]\u001b[0m Trial 426 pruned. Trial was pruned at iteration 432.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:15:08,974]\u001b[0m Trial 427 pruned. Trial was pruned at iteration 355.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:15:45,544]\u001b[0m Trial 428 pruned. Trial was pruned at iteration 436.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:16:31,108]\u001b[0m Trial 429 finished with value: 2.9129574000000003 and parameters: {'max_depth': 10, 'min_child_weight': 4, 'gamma': 1.3430783800980322e-07, 'subsample': 0.605281322637953, 'colsample_bytree': 0.9248194877185515, 'lambda': 1.5776875600016235e-06, 'alpha': 1.0345881361549725e-06, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:16:40,036]\u001b[0m Trial 430 pruned. Trial was pruned at iteration 51.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:16:41,289]\u001b[0m Trial 431 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:16:41,927]\u001b[0m Trial 432 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:17:31,763]\u001b[0m Trial 433 finished with value: 2.9081248 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 2.0385604473982433e-07, 'subsample': 0.5801481292311563, 'colsample_bytree': 0.9398046307486992, 'lambda': 3.569143368140582e-07, 'alpha': 1.5161627218272288e-07, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:17:51,773]\u001b[0m Trial 434 pruned. Trial was pruned at iteration 205.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:18:36,124]\u001b[0m Trial 435 finished with value: 2.8865082 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 2.974332023174872e-07, 'subsample': 0.4812451869354192, 'colsample_bytree': 0.9440398144108936, 'lambda': 3.644136599727975e-08, 'alpha': 1.4960961711612815e-07, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:19:20,856]\u001b[0m Trial 436 finished with value: 2.8944368 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 2.5492287234362e-07, 'subsample': 0.4874616610822125, 'colsample_bytree': 0.944184749899949, 'lambda': 1.6636522234476632e-08, 'alpha': 1.8299969429840713e-07, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:19:22,178]\u001b[0m Trial 437 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:20:06,567]\u001b[0m Trial 438 finished with value: 2.8920445999999997 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 4.3641787065371106e-07, 'subsample': 0.48057636291093064, 'colsample_bytree': 0.94233481298947, 'lambda': 1.6906879872297774e-08, 'alpha': 2.1745093997032394e-07, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:20:07,082]\u001b[0m Trial 439 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:20:08,397]\u001b[0m Trial 440 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:20:11,302]\u001b[0m Trial 441 pruned. Trial was pruned at iteration 25.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:20:12,623]\u001b[0m Trial 442 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:20:15,319]\u001b[0m Trial 443 pruned. Trial was pruned at iteration 24.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:20:18,021]\u001b[0m Trial 444 pruned. Trial was pruned at iteration 24.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:20:19,293]\u001b[0m Trial 445 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:20:20,605]\u001b[0m Trial 446 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:20:21,745]\u001b[0m Trial 447 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:20:24,498]\u001b[0m Trial 448 pruned. Trial was pruned at iteration 24.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:20:25,234]\u001b[0m Trial 449 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:20:26,544]\u001b[0m Trial 450 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:20:27,437]\u001b[0m Trial 451 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:20:28,477]\u001b[0m Trial 452 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:21:11,692]\u001b[0m Trial 453 finished with value: 2.8938938000000003 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 4.2813196658942486e-07, 'subsample': 0.4695817321289244, 'colsample_bytree': 0.9578078047315268, 'lambda': 2.1646229781509497e-08, 'alpha': 1.220786529293099e-07, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:21:55,130]\u001b[0m Trial 454 finished with value: 2.9025818 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 4.2751335059328255e-07, 'subsample': 0.46394788615555393, 'colsample_bytree': 0.9647670247875041, 'lambda': 2.677432300906672e-08, 'alpha': 1.1418848288435856e-07, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:22:28,203]\u001b[0m Trial 455 pruned. Trial was pruned at iteration 513.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:22:28,648]\u001b[0m Trial 456 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:23:11,779]\u001b[0m Trial 457 finished with value: 2.9024434 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 5.336964630301873e-07, 'subsample': 0.4689793079452965, 'colsample_bytree': 0.9560915792913107, 'lambda': 2.402252496481211e-08, 'alpha': 5.1291414803801576e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:23:13,055]\u001b[0m Trial 458 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:23:56,609]\u001b[0m Trial 459 finished with value: 2.8981520000000005 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 4.884482180442636e-07, 'subsample': 0.46818285811300914, 'colsample_bytree': 0.9599608629257331, 'lambda': 1.2231665993878247e-08, 'alpha': 1.536428982275364e-07, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:23:57,928]\u001b[0m Trial 460 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:24:41,317]\u001b[0m Trial 461 finished with value: 2.9040703999999997 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 5.036165028546895e-07, 'subsample': 0.4662976691053435, 'colsample_bytree': 0.9725040183786244, 'lambda': 1.0956375535466118e-08, 'alpha': 4.518321865399803e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:25:15,977]\u001b[0m Trial 462 pruned. Trial was pruned at iteration 534.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:25:59,933]\u001b[0m Trial 463 finished with value: 2.904762 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 7.759705996988206e-07, 'subsample': 0.46793336771028154, 'colsample_bytree': 0.9789065554397589, 'lambda': 1.0139041189050454e-08, 'alpha': 4.842668031597862e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:26:01,189]\u001b[0m Trial 464 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:26:02,511]\u001b[0m Trial 465 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:26:03,844]\u001b[0m Trial 466 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:26:36,710]\u001b[0m Trial 467 pruned. Trial was pruned at iteration 480.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:27:20,303]\u001b[0m Trial 468 finished with value: 2.8879346 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 4.492775141254039e-07, 'subsample': 0.4770113468533898, 'colsample_bytree': 0.9612981586085009, 'lambda': 2.0659613583397116e-08, 'alpha': 1.043924612158003e-07, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:28:01,242]\u001b[0m Trial 469 finished with value: 2.9062930000000002 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 4.6020167064516353e-07, 'subsample': 0.46737846766046, 'colsample_bytree': 0.9991333849095667, 'lambda': 2.064312587786504e-08, 'alpha': 8.861959780001243e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:28:35,213]\u001b[0m Trial 470 pruned. Trial was pruned at iteration 514.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:29:19,822]\u001b[0m Trial 471 finished with value: 2.90781 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 8.012064588539861e-07, 'subsample': 0.47404072391003566, 'colsample_bytree': 0.9816669223206238, 'lambda': 1.7494163443156554e-08, 'alpha': 7.944640246822038e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:29:21,132]\u001b[0m Trial 472 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:29:22,461]\u001b[0m Trial 473 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:30:04,051]\u001b[0m Trial 474 finished with value: 2.90229 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 3.8957947993536857e-07, 'subsample': 0.4788418722147228, 'colsample_bytree': 0.9999220172463702, 'lambda': 1.4017435415832226e-08, 'alpha': 6.696351345762036e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:30:44,831]\u001b[0m Trial 475 finished with value: 2.9007456 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 4.4500519104410904e-07, 'subsample': 0.47684334406732903, 'colsample_bytree': 0.9988685546486226, 'lambda': 1.4058947625352183e-08, 'alpha': 6.010619115661652e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:31:25,680]\u001b[0m Trial 476 finished with value: 2.8976128 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 4.361654517396329e-07, 'subsample': 0.47729598001536194, 'colsample_bytree': 0.9935567037085508, 'lambda': 1.1238250115549324e-08, 'alpha': 5.375152588389456e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:32:11,312]\u001b[0m Trial 477 finished with value: 2.897967 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 3.986595482315418e-07, 'subsample': 0.4781395085641316, 'colsample_bytree': 0.995192441888853, 'lambda': 1.0500081301188276e-08, 'alpha': 3.561043426150882e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:32:55,491]\u001b[0m Trial 478 finished with value: 2.890645 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 4.5871091077816486e-07, 'subsample': 0.4802078514318867, 'colsample_bytree': 0.9947002159921284, 'lambda': 1.38354164342489e-08, 'alpha': 5.391948699720006e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:33:37,388]\u001b[0m Trial 479 finished with value: 2.9061502 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 9.410052641748916e-07, 'subsample': 0.487554040158969, 'colsample_bytree': 0.9978512512251037, 'lambda': 1.081352211271476e-08, 'alpha': 3.409232740231944e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:34:21,959]\u001b[0m Trial 480 finished with value: 2.9084939999999997 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 6.022582676169284e-07, 'subsample': 0.4747073749380266, 'colsample_bytree': 0.9989513988357794, 'lambda': 1.4270933003906983e-08, 'alpha': 2.1355474620742815e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:35:02,414]\u001b[0m Trial 481 finished with value: 2.8975822 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 3.7194493547205823e-07, 'subsample': 0.4778758391958019, 'colsample_bytree': 0.984830242096324, 'lambda': 1.0786899915172372e-08, 'alpha': 3.0094068840072004e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:35:44,220]\u001b[0m Trial 482 finished with value: 2.8869478 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 2.909968041440668e-07, 'subsample': 0.48031595304902214, 'colsample_bytree': 0.9984829761724583, 'lambda': 1.0524689066485203e-08, 'alpha': 3.009468786804245e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:36:26,013]\u001b[0m Trial 483 finished with value: 2.8905266 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 3.218660435134544e-07, 'subsample': 0.48038789674899907, 'colsample_bytree': 0.9981441694315434, 'lambda': 1.0438954146985288e-08, 'alpha': 2.9295000435867215e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:37:07,150]\u001b[0m Trial 484 finished with value: 2.898677 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 2.92917136664965e-07, 'subsample': 0.4802597429929059, 'colsample_bytree': 0.9974424667212394, 'lambda': 1.0273045296509782e-08, 'alpha': 3.1022635473457336e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:37:51,905]\u001b[0m Trial 485 finished with value: 2.8916106 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 2.924007469572416e-07, 'subsample': 0.4855125038796338, 'colsample_bytree': 0.9965948008146626, 'lambda': 1.511722016954638e-08, 'alpha': 2.291358512022214e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:38:36,069]\u001b[0m Trial 486 finished with value: 2.8863798000000003 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 2.2773728090609378e-07, 'subsample': 0.48371295107755213, 'colsample_bytree': 0.9991821762697125, 'lambda': 1.4224652100950574e-08, 'alpha': 2.5527022505789487e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:38:38,819]\u001b[0m Trial 487 pruned. Trial was pruned at iteration 23.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:39:21,063]\u001b[0m Trial 488 finished with value: 2.891933 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 2.2964232245551046e-07, 'subsample': 0.48389688164727646, 'colsample_bytree': 0.9984642485170394, 'lambda': 1.5211637481367984e-08, 'alpha': 1.7124543034117127e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:39:23,797]\u001b[0m Trial 489 pruned. Trial was pruned at iteration 23.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:39:25,134]\u001b[0m Trial 490 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:39:27,261]\u001b[0m Trial 491 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:40:11,405]\u001b[0m Trial 492 finished with value: 2.8932826 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 1.9138386829661854e-07, 'subsample': 0.4827295075926781, 'colsample_bytree': 0.9878316618926077, 'lambda': 1.2963509622890007e-08, 'alpha': 1.035553964446233e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:40:46,382]\u001b[0m Trial 493 pruned. Trial was pruned at iteration 503.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:40:47,718]\u001b[0m Trial 494 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:41:29,953]\u001b[0m Trial 495 finished with value: 2.8900753999999997 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 8.211130747020927e-08, 'subsample': 0.4887264752411879, 'colsample_bytree': 0.9979071290792496, 'lambda': 1.0552169500896037e-08, 'alpha': 1.0867713381305468e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:42:12,087]\u001b[0m Trial 496 finished with value: 2.8939459999999997 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 1.8760450171903482e-07, 'subsample': 0.48693898355823595, 'colsample_bytree': 0.985545712505475, 'lambda': 1.0463733860670773e-08, 'alpha': 1.0473983766416172e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:42:58,273]\u001b[0m Trial 497 finished with value: 2.9079712 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 1.1672655761132547e-07, 'subsample': 0.5004311128816805, 'colsample_bytree': 0.9988611418176943, 'lambda': 1.8203546091098903e-08, 'alpha': 1.430141985968641e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:43:00,998]\u001b[0m Trial 498 pruned. Trial was pruned at iteration 23.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:43:02,337]\u001b[0m Trial 499 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:43:32,430]\u001b[0m Trial 500 pruned. Trial was pruned at iteration 350.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:43:33,772]\u001b[0m Trial 501 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:44:15,461]\u001b[0m Trial 502 finished with value: 2.9070397999999997 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 1.0927210610703549e-07, 'subsample': 0.4808248978333111, 'colsample_bytree': 0.9995092817718892, 'lambda': 2.087476181271853e-08, 'alpha': 2.3035253214932313e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:44:50,963]\u001b[0m Trial 503 pruned. Trial was pruned at iteration 514.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:44:52,253]\u001b[0m Trial 504 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:45:36,828]\u001b[0m Trial 505 finished with value: 2.9008051999999998 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 1.623350633447871e-07, 'subsample': 0.4853186425201409, 'colsample_bytree': 0.9840388207924375, 'lambda': 1.033341786605409e-08, 'alpha': 1.5587848035606696e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:46:20,569]\u001b[0m Trial 506 finished with value: 2.9111193999999996 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 3.15714198993493e-07, 'subsample': 0.46758535304467735, 'colsample_bytree': 0.9755039624883504, 'lambda': 2.258675549191991e-08, 'alpha': 2.5705873381004838e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:46:21,889]\u001b[0m Trial 507 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:46:26,144]\u001b[0m Trial 508 pruned. Trial was pruned at iteration 38.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:46:27,457]\u001b[0m Trial 509 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:46:28,320]\u001b[0m Trial 510 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:46:31,654]\u001b[0m Trial 511 pruned. Trial was pruned at iteration 29.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:47:17,800]\u001b[0m Trial 512 finished with value: 2.9045344 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 2.1482827035182236e-07, 'subsample': 0.5087091232250229, 'colsample_bytree': 0.9993132521029275, 'lambda': 2.162182239553222e-08, 'alpha': 3.845442287100297e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:47:19,117]\u001b[0m Trial 513 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:47:53,475]\u001b[0m Trial 514 pruned. Trial was pruned at iteration 505.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:47:56,679]\u001b[0m Trial 515 pruned. Trial was pruned at iteration 28.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:47:59,794]\u001b[0m Trial 516 pruned. Trial was pruned at iteration 26.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:48:01,099]\u001b[0m Trial 517 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:48:02,459]\u001b[0m Trial 518 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:48:03,487]\u001b[0m Trial 519 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:48:07,806]\u001b[0m Trial 520 pruned. Trial was pruned at iteration 39.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:48:10,939]\u001b[0m Trial 521 pruned. Trial was pruned at iteration 26.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:48:52,036]\u001b[0m Trial 522 finished with value: 2.8966006 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 1.979953559897373e-08, 'subsample': 0.48516713986343424, 'colsample_bytree': 0.9997615562869578, 'lambda': 1.020640256274968e-08, 'alpha': 5.850379852826206e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:48:54,767]\u001b[0m Trial 523 pruned. Trial was pruned at iteration 23.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:48:56,098]\u001b[0m Trial 524 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:49:37,291]\u001b[0m Trial 525 finished with value: 2.9036306 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 1.3082120899595025e-08, 'subsample': 0.47742714492838734, 'colsample_bytree': 0.9845171474978843, 'lambda': 1.0937058049775983e-08, 'alpha': 3.550982434586807e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:50:23,096]\u001b[0m Trial 526 finished with value: 2.8978468 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 1.521267152088213e-08, 'subsample': 0.5103783837144252, 'colsample_bytree': 0.9996524112562571, 'lambda': 2.0876875193043377e-08, 'alpha': 6.460173963197775e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:50:24,332]\u001b[0m Trial 527 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:50:28,725]\u001b[0m Trial 528 pruned. Trial was pruned at iteration 38.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:50:30,173]\u001b[0m Trial 529 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:50:30,935]\u001b[0m Trial 530 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:51:15,735]\u001b[0m Trial 531 finished with value: 2.8856682 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 4.4494995748761254e-08, 'subsample': 0.48340438715421946, 'colsample_bytree': 0.9986394960529427, 'lambda': 1.8438702730843888e-08, 'alpha': 5.7215635187459516e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:51:17,743]\u001b[0m Trial 532 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:51:19,087]\u001b[0m Trial 533 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:51:20,362]\u001b[0m Trial 534 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:51:23,370]\u001b[0m Trial 535 pruned. Trial was pruned at iteration 25.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:51:24,679]\u001b[0m Trial 536 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:52:08,343]\u001b[0m Trial 537 finished with value: 2.8877926 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 1.980890209715848e-08, 'subsample': 0.4844707468814441, 'colsample_bytree': 0.9620735173416545, 'lambda': 2.3160215767273515e-08, 'alpha': 2.770090951839797e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:52:12,627]\u001b[0m Trial 538 pruned. Trial was pruned at iteration 39.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:52:13,669]\u001b[0m Trial 539 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:52:59,087]\u001b[0m Trial 540 finished with value: 2.8959064 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 5.1259619425881295e-08, 'subsample': 0.4850551221632321, 'colsample_bytree': 0.9628034136423966, 'lambda': 1.5409392615222084e-08, 'alpha': 1.449995396847444e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:53:43,998]\u001b[0m Trial 541 finished with value: 2.9051114 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 4.049002055849603e-08, 'subsample': 0.4877024236231667, 'colsample_bytree': 0.9686333400939077, 'lambda': 1.4907635802984815e-08, 'alpha': 1.3239630275925028e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:54:27,274]\u001b[0m Trial 542 finished with value: 2.8917493999999992 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 2.7248051384409866e-08, 'subsample': 0.46976005573854446, 'colsample_bytree': 0.9578887215747811, 'lambda': 1.0041230898095474e-08, 'alpha': 1.6090126782341604e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:54:28,601]\u001b[0m Trial 543 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:54:29,950]\u001b[0m Trial 544 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:54:30,851]\u001b[0m Trial 545 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:55:12,637]\u001b[0m Trial 546 finished with value: 2.9050754 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 1.761076138204867e-08, 'subsample': 0.46807784397005314, 'colsample_bytree': 0.9562099527368514, 'lambda': 2.2841846507623832e-08, 'alpha': 2.511705168778364e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:55:13,959]\u001b[0m Trial 547 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:55:15,766]\u001b[0m Trial 548 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:55:17,056]\u001b[0m Trial 549 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:55:18,198]\u001b[0m Trial 550 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:56:02,946]\u001b[0m Trial 551 finished with value: 2.9044234 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 8.826082055378317e-08, 'subsample': 0.473503868434231, 'colsample_bytree': 0.9808259198767844, 'lambda': 1.0271590997038342e-08, 'alpha': 3.2903397367765e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:56:04,011]\u001b[0m Trial 552 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:56:05,840]\u001b[0m Trial 553 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:56:08,359]\u001b[0m Trial 554 pruned. Trial was pruned at iteration 21.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:56:09,783]\u001b[0m Trial 555 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:56:10,930]\u001b[0m Trial 556 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:56:13,079]\u001b[0m Trial 557 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:56:14,445]\u001b[0m Trial 558 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:56:15,813]\u001b[0m Trial 559 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:56:19,841]\u001b[0m Trial 560 pruned. Trial was pruned at iteration 36.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:56:22,837]\u001b[0m Trial 561 pruned. Trial was pruned at iteration 25.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:56:27,121]\u001b[0m Trial 562 pruned. Trial was pruned at iteration 38.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:56:27,516]\u001b[0m Trial 563 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:56:28,852]\u001b[0m Trial 564 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:56:30,035]\u001b[0m Trial 565 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:57:05,636]\u001b[0m Trial 566 pruned. Trial was pruned at iteration 526.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:57:07,696]\u001b[0m Trial 567 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:57:09,834]\u001b[0m Trial 568 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:57:11,166]\u001b[0m Trial 569 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:57:15,394]\u001b[0m Trial 570 pruned. Trial was pruned at iteration 38.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:57:16,010]\u001b[0m Trial 571 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:57:17,340]\u001b[0m Trial 572 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:57:18,456]\u001b[0m Trial 573 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:57:52,218]\u001b[0m Trial 574 pruned. Trial was pruned at iteration 503.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:57:54,512]\u001b[0m Trial 575 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:58:39,841]\u001b[0m Trial 576 finished with value: 2.8947112 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 2.418139936103811e-07, 'subsample': 0.4845263802930071, 'colsample_bytree': 0.9999416414312948, 'lambda': 2.614195001010909e-08, 'alpha': 1.9150561241929143e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:58:40,996]\u001b[0m Trial 577 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:58:41,711]\u001b[0m Trial 578 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:58:44,474]\u001b[0m Trial 579 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:58:45,691]\u001b[0m Trial 580 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:58:47,072]\u001b[0m Trial 581 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:58:48,891]\u001b[0m Trial 582 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:58:50,203]\u001b[0m Trial 583 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:58:51,035]\u001b[0m Trial 584 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:58:51,813]\u001b[0m Trial 585 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:58:54,526]\u001b[0m Trial 586 pruned. Trial was pruned at iteration 22.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:59:10,138]\u001b[0m Trial 587 pruned. Trial was pruned at iteration 97.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:59:11,959]\u001b[0m Trial 588 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:59:13,292]\u001b[0m Trial 589 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:59:48,529]\u001b[0m Trial 590 pruned. Trial was pruned at iteration 528.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:59:52,677]\u001b[0m Trial 591 pruned. Trial was pruned at iteration 36.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:59:54,061]\u001b[0m Trial 592 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 19:59:58,334]\u001b[0m Trial 593 pruned. Trial was pruned at iteration 38.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:00:00,109]\u001b[0m Trial 594 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:00:02,570]\u001b[0m Trial 595 pruned. Trial was pruned at iteration 20.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:00:04,561]\u001b[0m Trial 596 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:00:05,324]\u001b[0m Trial 597 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:00:26,666]\u001b[0m Trial 598 pruned. Trial was pruned at iteration 132.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:00:28,553]\u001b[0m Trial 599 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:00:29,462]\u001b[0m Trial 600 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:00:34,404]\u001b[0m Trial 601 pruned. Trial was pruned at iteration 37.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:00:36,401]\u001b[0m Trial 602 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:00:37,746]\u001b[0m Trial 603 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:00:39,062]\u001b[0m Trial 604 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:00:41,228]\u001b[0m Trial 605 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:00:41,995]\u001b[0m Trial 606 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:00:43,617]\u001b[0m Trial 607 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:00:44,942]\u001b[0m Trial 608 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:00:46,356]\u001b[0m Trial 609 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:00:47,430]\u001b[0m Trial 610 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:00:48,790]\u001b[0m Trial 611 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:00:49,988]\u001b[0m Trial 612 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:00:50,499]\u001b[0m Trial 613 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:01:35,311]\u001b[0m Trial 614 finished with value: 2.8959263999999996 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 2.124317726520198e-07, 'subsample': 0.48167304438553493, 'colsample_bytree': 0.9827063802325628, 'lambda': 3.1081626382507605e-08, 'alpha': 1.9486963721197576e-08, 'grow_policy': 'depthwise'}. Best is trial 77 with value: 2.8791281999999994.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:01:36,528]\u001b[0m Trial 615 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:02:20,918]\u001b[0m Trial 616 finished with value: 2.8765868000000006 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 1.1273311837112433e-07, 'subsample': 0.48167905375660824, 'colsample_bytree': 0.9626653908113837, 'lambda': 3.4544441383016645e-08, 'alpha': 4.241571364142641e-08, 'grow_policy': 'depthwise'}. Best is trial 616 with value: 2.8765868000000006.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:03:05,453]\u001b[0m Trial 617 finished with value: 2.892597 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 9.577408288184866e-08, 'subsample': 0.47184576630998476, 'colsample_bytree': 0.959703374801588, 'lambda': 5.206711957261423e-08, 'alpha': 2.347332372948101e-08, 'grow_policy': 'depthwise'}. Best is trial 616 with value: 2.8765868000000006.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:03:06,797]\u001b[0m Trial 618 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:03:08,183]\u001b[0m Trial 619 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:03:09,528]\u001b[0m Trial 620 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:03:12,988]\u001b[0m Trial 621 pruned. Trial was pruned at iteration 30.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:03:14,360]\u001b[0m Trial 622 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:03:15,717]\u001b[0m Trial 623 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:03:50,476]\u001b[0m Trial 624 pruned. Trial was pruned at iteration 514.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:03:51,819]\u001b[0m Trial 625 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:03:54,465]\u001b[0m Trial 626 pruned. Trial was pruned at iteration 22.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:03:55,790]\u001b[0m Trial 627 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:03:59,925]\u001b[0m Trial 628 pruned. Trial was pruned at iteration 36.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:04:01,282]\u001b[0m Trial 629 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:04:02,798]\u001b[0m Trial 630 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:04:44,840]\u001b[0m Trial 631 finished with value: 2.8835984000000003 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 1.5510252947546693e-07, 'subsample': 0.48340614134599275, 'colsample_bytree': 0.9996730024699092, 'lambda': 3.9009317268110095e-08, 'alpha': 4.4845200391172454e-08, 'grow_policy': 'depthwise'}. Best is trial 616 with value: 2.8765868000000006.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:04:46,184]\u001b[0m Trial 632 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:04:47,565]\u001b[0m Trial 633 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:04:49,605]\u001b[0m Trial 634 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:04:50,975]\u001b[0m Trial 635 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:04:53,934]\u001b[0m Trial 636 pruned. Trial was pruned at iteration 25.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:04:55,306]\u001b[0m Trial 637 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:04:56,727]\u001b[0m Trial 638 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:05:38,301]\u001b[0m Trial 639 finished with value: 2.9035296 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 8.868527253699296e-08, 'subsample': 0.48511777149155483, 'colsample_bytree': 0.9996464470642474, 'lambda': 3.838713445182565e-08, 'alpha': 2.540784814984744e-08, 'grow_policy': 'depthwise'}. Best is trial 616 with value: 2.8765868000000006.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:05:38,757]\u001b[0m Trial 640 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:05:40,106]\u001b[0m Trial 641 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:06:02,870]\u001b[0m Trial 642 pruned. Trial was pruned at iteration 196.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:06:06,317]\u001b[0m Trial 643 pruned. Trial was pruned at iteration 30.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:06:07,737]\u001b[0m Trial 644 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:06:09,079]\u001b[0m Trial 645 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:06:10,860]\u001b[0m Trial 646 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:06:14,709]\u001b[0m Trial 647 pruned. Trial was pruned at iteration 33.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:06:15,139]\u001b[0m Trial 648 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:06:17,598]\u001b[0m Trial 649 pruned. Trial was pruned at iteration 20.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:06:37,186]\u001b[0m Trial 650 pruned. Trial was pruned at iteration 186.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:06:38,471]\u001b[0m Trial 651 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:06:39,828]\u001b[0m Trial 652 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:06:41,675]\u001b[0m Trial 653 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:06:43,162]\u001b[0m Trial 654 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:06:54,866]\u001b[0m Trial 655 pruned. Trial was pruned at iteration 82.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:06:56,194]\u001b[0m Trial 656 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:06:57,516]\u001b[0m Trial 657 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:07:00,040]\u001b[0m Trial 658 pruned. Trial was pruned at iteration 21.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:07:02,307]\u001b[0m Trial 659 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:07:04,466]\u001b[0m Trial 660 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:07:05,845]\u001b[0m Trial 661 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:07:07,271]\u001b[0m Trial 662 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:07:08,583]\u001b[0m Trial 663 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:07:31,708]\u001b[0m Trial 664 pruned. Trial was pruned at iteration 197.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:07:33,033]\u001b[0m Trial 665 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:07:34,426]\u001b[0m Trial 666 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:07:38,497]\u001b[0m Trial 667 pruned. Trial was pruned at iteration 36.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:07:42,838]\u001b[0m Trial 668 pruned. Trial was pruned at iteration 38.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:07:45,462]\u001b[0m Trial 669 pruned. Trial was pruned at iteration 22.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:07:46,823]\u001b[0m Trial 670 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:07:48,189]\u001b[0m Trial 671 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:07:49,625]\u001b[0m Trial 672 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:07:51,719]\u001b[0m Trial 673 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:07:53,077]\u001b[0m Trial 674 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:07:54,885]\u001b[0m Trial 675 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:07:56,210]\u001b[0m Trial 676 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:07:58,738]\u001b[0m Trial 677 pruned. Trial was pruned at iteration 21.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:08:32,068]\u001b[0m Trial 678 pruned. Trial was pruned at iteration 439.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:08:33,471]\u001b[0m Trial 679 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:08:35,641]\u001b[0m Trial 680 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:08:52,095]\u001b[0m Trial 681 pruned. Trial was pruned at iteration 150.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:08:54,785]\u001b[0m Trial 682 pruned. Trial was pruned at iteration 22.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:08:57,038]\u001b[0m Trial 683 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:08:58,368]\u001b[0m Trial 684 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:08:59,749]\u001b[0m Trial 685 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:09:42,175]\u001b[0m Trial 686 finished with value: 2.8921957999999997 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 2.5208152419609055e-07, 'subsample': 0.4807400584853143, 'colsample_bytree': 0.9997022454479204, 'lambda': 1.3641370732789873e-08, 'alpha': 2.8524847650585734e-08, 'grow_policy': 'depthwise'}. Best is trial 616 with value: 2.8765868000000006.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:10:23,885]\u001b[0m Trial 687 finished with value: 2.8992266 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 2.598897099142142e-07, 'subsample': 0.47177688517164906, 'colsample_bytree': 0.9998305604418068, 'lambda': 2.1934568594869395e-08, 'alpha': 4.1641989805638324e-08, 'grow_policy': 'depthwise'}. Best is trial 616 with value: 2.8765868000000006.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:10:52,264]\u001b[0m Trial 688 pruned. Trial was pruned at iteration 242.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:10:53,567]\u001b[0m Trial 689 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:10:54,928]\u001b[0m Trial 690 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:10:55,999]\u001b[0m Trial 691 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:11:00,382]\u001b[0m Trial 692 pruned. Trial was pruned at iteration 39.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:11:01,710]\u001b[0m Trial 693 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:11:07,006]\u001b[0m Trial 694 pruned. Trial was pruned at iteration 46.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:11:11,241]\u001b[0m Trial 695 pruned. Trial was pruned at iteration 37.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:11:14,259]\u001b[0m Trial 696 pruned. Trial was pruned at iteration 26.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:11:15,645]\u001b[0m Trial 697 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:11:17,044]\u001b[0m Trial 698 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:11:19,076]\u001b[0m Trial 699 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:11:45,809]\u001b[0m Trial 700 pruned. Trial was pruned at iteration 314.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:11:47,131]\u001b[0m Trial 701 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:11:47,519]\u001b[0m Trial 702 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:11:48,868]\u001b[0m Trial 703 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:11:50,332]\u001b[0m Trial 704 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:11:53,713]\u001b[0m Trial 705 pruned. Trial was pruned at iteration 29.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:11:57,002]\u001b[0m Trial 706 pruned. Trial was pruned at iteration 27.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:11:58,342]\u001b[0m Trial 707 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:11:59,721]\u001b[0m Trial 708 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:12:01,464]\u001b[0m Trial 709 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:12:05,476]\u001b[0m Trial 710 pruned. Trial was pruned at iteration 29.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:12:07,733]\u001b[0m Trial 711 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:12:09,131]\u001b[0m Trial 712 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:12:10,616]\u001b[0m Trial 713 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:12:12,008]\u001b[0m Trial 714 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:12:13,363]\u001b[0m Trial 715 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:12:14,702]\u001b[0m Trial 716 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:12:17,746]\u001b[0m Trial 717 pruned. Trial was pruned at iteration 25.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:12:20,123]\u001b[0m Trial 718 pruned. Trial was pruned at iteration 20.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:12:23,926]\u001b[0m Trial 719 pruned. Trial was pruned at iteration 33.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:12:25,283]\u001b[0m Trial 720 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:12:28,234]\u001b[0m Trial 721 pruned. Trial was pruned at iteration 24.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:12:29,600]\u001b[0m Trial 722 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:12:32,947]\u001b[0m Trial 723 pruned. Trial was pruned at iteration 28.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:13:01,101]\u001b[0m Trial 724 pruned. Trial was pruned at iteration 336.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:13:02,480]\u001b[0m Trial 725 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:13:04,496]\u001b[0m Trial 726 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:13:05,885]\u001b[0m Trial 727 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:13:47,782]\u001b[0m Trial 728 finished with value: 2.8945068000000003 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 1.445436145594489e-07, 'subsample': 0.4847270632134273, 'colsample_bytree': 0.9709342280047268, 'lambda': 1.0009183672000818e-08, 'alpha': 1.044608205900777e-08, 'grow_policy': 'depthwise'}. Best is trial 616 with value: 2.8765868000000006.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:14:32,569]\u001b[0m Trial 729 finished with value: 2.9055244 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 1.3568913226751087e-07, 'subsample': 0.4855074131006602, 'colsample_bytree': 0.9719950895837998, 'lambda': 1.3522774793919118e-08, 'alpha': 1.1941871986889498e-08, 'grow_policy': 'depthwise'}. Best is trial 616 with value: 2.8765868000000006.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:14:33,199]\u001b[0m Trial 730 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:14:33,727]\u001b[0m Trial 731 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:14:36,895]\u001b[0m Trial 732 pruned. Trial was pruned at iteration 26.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:14:37,342]\u001b[0m Trial 733 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:14:40,646]\u001b[0m Trial 734 pruned. Trial was pruned at iteration 28.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:14:42,071]\u001b[0m Trial 735 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:14:43,438]\u001b[0m Trial 736 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:14:44,116]\u001b[0m Trial 737 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:14:45,466]\u001b[0m Trial 738 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:14:47,511]\u001b[0m Trial 739 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:14:49,715]\u001b[0m Trial 740 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:14:51,120]\u001b[0m Trial 741 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:14:52,519]\u001b[0m Trial 742 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:14:52,919]\u001b[0m Trial 743 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:14:54,340]\u001b[0m Trial 744 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:15:05,311]\u001b[0m Trial 745 pruned. Trial was pruned at iteration 65.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:15:09,759]\u001b[0m Trial 746 pruned. Trial was pruned at iteration 39.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:15:11,099]\u001b[0m Trial 747 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:15:11,748]\u001b[0m Trial 748 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:15:13,274]\u001b[0m Trial 749 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:15:15,287]\u001b[0m Trial 750 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:15:16,675]\u001b[0m Trial 751 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:15:18,730]\u001b[0m Trial 752 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:15:20,118]\u001b[0m Trial 753 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:15:25,527]\u001b[0m Trial 754 pruned. Trial was pruned at iteration 46.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:15:26,984]\u001b[0m Trial 755 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:15:28,357]\u001b[0m Trial 756 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:15:30,588]\u001b[0m Trial 757 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:15:31,906]\u001b[0m Trial 758 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:15:33,981]\u001b[0m Trial 759 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:15:35,450]\u001b[0m Trial 760 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:15:37,305]\u001b[0m Trial 761 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:15:40,989]\u001b[0m Trial 762 pruned. Trial was pruned at iteration 20.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:15:42,411]\u001b[0m Trial 763 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:16:24,068]\u001b[0m Trial 764 finished with value: 2.9051048 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 3.398793515051426e-07, 'subsample': 0.46705579958057347, 'colsample_bytree': 0.967065658499976, 'lambda': 2.4885620206773124e-08, 'alpha': 3.52692416584776e-08, 'grow_policy': 'depthwise'}. Best is trial 616 with value: 2.8765868000000006.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:16:25,713]\u001b[0m Trial 765 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:16:28,712]\u001b[0m Trial 766 pruned. Trial was pruned at iteration 24.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:16:30,059]\u001b[0m Trial 767 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:16:31,480]\u001b[0m Trial 768 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:16:34,480]\u001b[0m Trial 769 pruned. Trial was pruned at iteration 25.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:16:36,362]\u001b[0m Trial 770 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:16:37,744]\u001b[0m Trial 771 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:16:39,917]\u001b[0m Trial 772 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:17:23,526]\u001b[0m Trial 773 finished with value: 2.8888244 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 8.087546970140524e-07, 'subsample': 0.4700153204441914, 'colsample_bytree': 0.9569200731851211, 'lambda': 1.787554973370682e-08, 'alpha': 1.2432523762372445e-07, 'grow_policy': 'depthwise'}. Best is trial 616 with value: 2.8765868000000006.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:17:24,833]\u001b[0m Trial 774 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:17:27,794]\u001b[0m Trial 775 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:17:30,053]\u001b[0m Trial 776 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:17:31,137]\u001b[0m Trial 777 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:17:31,758]\u001b[0m Trial 778 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:17:33,098]\u001b[0m Trial 779 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:17:35,618]\u001b[0m Trial 780 pruned. Trial was pruned at iteration 21.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:17:36,944]\u001b[0m Trial 781 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:17:38,348]\u001b[0m Trial 782 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:17:41,605]\u001b[0m Trial 783 pruned. Trial was pruned at iteration 28.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:17:42,956]\u001b[0m Trial 784 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:17:44,634]\u001b[0m Trial 785 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:17:47,702]\u001b[0m Trial 786 pruned. Trial was pruned at iteration 26.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:17:49,098]\u001b[0m Trial 787 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:17:50,457]\u001b[0m Trial 788 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:17:50,992]\u001b[0m Trial 789 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:17:54,100]\u001b[0m Trial 790 pruned. Trial was pruned at iteration 25.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:17:55,707]\u001b[0m Trial 791 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:17:57,054]\u001b[0m Trial 792 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:17:58,497]\u001b[0m Trial 793 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:18:00,987]\u001b[0m Trial 794 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:18:02,587]\u001b[0m Trial 795 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:18:03,939]\u001b[0m Trial 796 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:18:05,330]\u001b[0m Trial 797 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:18:20,367]\u001b[0m Trial 798 pruned. Trial was pruned at iteration 91.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:18:21,791]\u001b[0m Trial 799 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:18:23,166]\u001b[0m Trial 800 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:18:28,559]\u001b[0m Trial 801 pruned. Trial was pruned at iteration 46.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:18:29,899]\u001b[0m Trial 802 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:18:32,441]\u001b[0m Trial 803 pruned. Trial was pruned at iteration 21.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:18:33,829]\u001b[0m Trial 804 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:18:36,114]\u001b[0m Trial 805 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:19:10,781]\u001b[0m Trial 806 pruned. Trial was pruned at iteration 507.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:19:12,162]\u001b[0m Trial 807 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:19:13,526]\u001b[0m Trial 808 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:19:16,651]\u001b[0m Trial 809 pruned. Trial was pruned at iteration 26.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:19:18,005]\u001b[0m Trial 810 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:19:19,314]\u001b[0m Trial 811 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:19:20,671]\u001b[0m Trial 812 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:19:23,126]\u001b[0m Trial 813 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:19:24,568]\u001b[0m Trial 814 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:20:06,819]\u001b[0m Trial 815 finished with value: 2.9057974 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 4.197907578199249e-07, 'subsample': 0.48581762693530184, 'colsample_bytree': 0.9985664039322931, 'lambda': 1.0166439202434038e-08, 'alpha': 7.074898311635511e-08, 'grow_policy': 'depthwise'}. Best is trial 616 with value: 2.8765868000000006.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:20:08,199]\u001b[0m Trial 816 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:20:09,565]\u001b[0m Trial 817 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:20:11,386]\u001b[0m Trial 818 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:20:14,138]\u001b[0m Trial 819 pruned. Trial was pruned at iteration 23.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:20:15,475]\u001b[0m Trial 820 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:20:42,541]\u001b[0m Trial 821 pruned. Trial was pruned at iteration 229.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:20:43,710]\u001b[0m Trial 822 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:20:45,053]\u001b[0m Trial 823 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:21:29,799]\u001b[0m Trial 824 finished with value: 2.8933726 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 0.0001225059406520933, 'subsample': 0.47824479865666064, 'colsample_bytree': 0.9988092596064095, 'lambda': 2.832549292307496e-08, 'alpha': 3.263244972177115e-08, 'grow_policy': 'depthwise'}. Best is trial 616 with value: 2.8765868000000006.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:21:31,148]\u001b[0m Trial 825 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:21:34,636]\u001b[0m Trial 826 pruned. Trial was pruned at iteration 30.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:22:04,706]\u001b[0m Trial 827 pruned. Trial was pruned at iteration 354.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:22:06,127]\u001b[0m Trial 828 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:22:10,426]\u001b[0m Trial 829 pruned. Trial was pruned at iteration 35.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:22:11,775]\u001b[0m Trial 830 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:22:58,112]\u001b[0m Trial 831 finished with value: 2.9000102 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 0.0012016682621593727, 'subsample': 0.478146461535241, 'colsample_bytree': 0.9999445466777794, 'lambda': 3.56392915768474e-08, 'alpha': 5.99270454980338e-08, 'grow_policy': 'depthwise'}. Best is trial 616 with value: 2.8765868000000006.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:22:59,488]\u001b[0m Trial 832 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:23:00,904]\u001b[0m Trial 833 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:23:02,438]\u001b[0m Trial 834 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:23:02,991]\u001b[0m Trial 835 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:23:06,019]\u001b[0m Trial 836 pruned. Trial was pruned at iteration 25.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:23:07,395]\u001b[0m Trial 837 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:23:12,210]\u001b[0m Trial 838 pruned. Trial was pruned at iteration 35.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:23:14,085]\u001b[0m Trial 839 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:23:15,084]\u001b[0m Trial 840 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:23:24,960]\u001b[0m Trial 841 pruned. Trial was pruned at iteration 65.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:23:26,316]\u001b[0m Trial 842 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:23:27,710]\u001b[0m Trial 843 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:23:29,604]\u001b[0m Trial 844 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:23:31,019]\u001b[0m Trial 845 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:23:36,355]\u001b[0m Trial 846 pruned. Trial was pruned at iteration 46.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:23:36,990]\u001b[0m Trial 847 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:23:37,770]\u001b[0m Trial 848 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:23:39,158]\u001b[0m Trial 849 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:23:42,489]\u001b[0m Trial 850 pruned. Trial was pruned at iteration 29.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:23:43,856]\u001b[0m Trial 851 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:23:44,958]\u001b[0m Trial 852 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:23:46,370]\u001b[0m Trial 853 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:23:48,373]\u001b[0m Trial 854 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:23:52,439]\u001b[0m Trial 855 pruned. Trial was pruned at iteration 35.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:23:53,133]\u001b[0m Trial 856 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:24:26,172]\u001b[0m Trial 857 pruned. Trial was pruned at iteration 473.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:24:28,261]\u001b[0m Trial 858 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:24:29,736]\u001b[0m Trial 859 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:24:31,164]\u001b[0m Trial 860 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:24:32,567]\u001b[0m Trial 861 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:24:33,937]\u001b[0m Trial 862 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:24:35,799]\u001b[0m Trial 863 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:24:37,216]\u001b[0m Trial 864 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:24:38,561]\u001b[0m Trial 865 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:24:39,965]\u001b[0m Trial 866 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:24:43,704]\u001b[0m Trial 867 pruned. Trial was pruned at iteration 32.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:24:47,299]\u001b[0m Trial 868 pruned. Trial was pruned at iteration 25.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:24:48,692]\u001b[0m Trial 869 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:24:51,656]\u001b[0m Trial 870 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:24:53,095]\u001b[0m Trial 871 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:24:54,416]\u001b[0m Trial 872 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:24:58,377]\u001b[0m Trial 873 pruned. Trial was pruned at iteration 37.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:24:59,645]\u001b[0m Trial 874 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:25:01,714]\u001b[0m Trial 875 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:25:03,100]\u001b[0m Trial 876 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:25:03,916]\u001b[0m Trial 877 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:25:08,061]\u001b[0m Trial 878 pruned. Trial was pruned at iteration 35.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:25:10,320]\u001b[0m Trial 879 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:25:11,353]\u001b[0m Trial 880 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:25:13,252]\u001b[0m Trial 881 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:25:15,950]\u001b[0m Trial 882 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:25:17,569]\u001b[0m Trial 883 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:25:18,973]\u001b[0m Trial 884 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:25:23,359]\u001b[0m Trial 885 pruned. Trial was pruned at iteration 39.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:25:24,805]\u001b[0m Trial 886 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:25:25,819]\u001b[0m Trial 887 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:25:27,237]\u001b[0m Trial 888 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:25:28,589]\u001b[0m Trial 889 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:25:29,968]\u001b[0m Trial 890 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:25:31,383]\u001b[0m Trial 891 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:25:33,511]\u001b[0m Trial 892 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:26:02,198]\u001b[0m Trial 893 pruned. Trial was pruned at iteration 331.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:26:03,576]\u001b[0m Trial 894 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:26:05,927]\u001b[0m Trial 895 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:26:07,628]\u001b[0m Trial 896 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:26:09,036]\u001b[0m Trial 897 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:26:10,475]\u001b[0m Trial 898 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:26:11,829]\u001b[0m Trial 899 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:26:28,079]\u001b[0m Trial 900 pruned. Trial was pruned at iteration 98.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:26:29,471]\u001b[0m Trial 901 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:26:33,955]\u001b[0m Trial 902 pruned. Trial was pruned at iteration 40.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:26:35,297]\u001b[0m Trial 903 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:26:36,743]\u001b[0m Trial 904 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:26:38,120]\u001b[0m Trial 905 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:26:39,287]\u001b[0m Trial 906 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:26:40,620]\u001b[0m Trial 907 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:27:03,919]\u001b[0m Trial 908 pruned. Trial was pruned at iteration 201.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:27:07,465]\u001b[0m Trial 909 pruned. Trial was pruned at iteration 31.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:27:12,771]\u001b[0m Trial 910 pruned. Trial was pruned at iteration 45.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:27:14,176]\u001b[0m Trial 911 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:27:14,830]\u001b[0m Trial 912 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:27:15,318]\u001b[0m Trial 913 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:27:17,461]\u001b[0m Trial 914 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:27:18,910]\u001b[0m Trial 915 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:27:20,831]\u001b[0m Trial 916 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:27:21,928]\u001b[0m Trial 917 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:27:23,359]\u001b[0m Trial 918 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:27:35,182]\u001b[0m Trial 919 pruned. Trial was pruned at iteration 73.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:27:36,612]\u001b[0m Trial 920 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:27:37,407]\u001b[0m Trial 921 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:27:38,793]\u001b[0m Trial 922 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:27:40,301]\u001b[0m Trial 923 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:27:42,751]\u001b[0m Trial 924 pruned. Trial was pruned at iteration 25.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:28:02,581]\u001b[0m Trial 925 pruned. Trial was pruned at iteration 188.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:28:03,957]\u001b[0m Trial 926 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:28:05,264]\u001b[0m Trial 927 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:28:35,032]\u001b[0m Trial 928 pruned. Trial was pruned at iteration 350.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:28:37,808]\u001b[0m Trial 929 pruned. Trial was pruned at iteration 23.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:28:39,266]\u001b[0m Trial 930 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:28:40,601]\u001b[0m Trial 931 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:28:41,567]\u001b[0m Trial 932 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:28:42,731]\u001b[0m Trial 933 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:28:44,960]\u001b[0m Trial 934 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:29:11,053]\u001b[0m Trial 935 pruned. Trial was pruned at iteration 228.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:29:12,454]\u001b[0m Trial 936 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:29:13,812]\u001b[0m Trial 937 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:29:15,184]\u001b[0m Trial 938 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:29:16,603]\u001b[0m Trial 939 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:29:20,126]\u001b[0m Trial 940 pruned. Trial was pruned at iteration 31.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:29:21,474]\u001b[0m Trial 941 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:29:29,777]\u001b[0m Trial 942 pruned. Trial was pruned at iteration 69.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:29:33,100]\u001b[0m Trial 943 pruned. Trial was pruned at iteration 27.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:29:36,071]\u001b[0m Trial 944 pruned. Trial was pruned at iteration 25.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:29:37,428]\u001b[0m Trial 945 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:29:38,846]\u001b[0m Trial 946 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:29:40,228]\u001b[0m Trial 947 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:29:41,564]\u001b[0m Trial 948 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:29:43,228]\u001b[0m Trial 949 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:29:46,292]\u001b[0m Trial 950 pruned. Trial was pruned at iteration 25.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:29:47,638]\u001b[0m Trial 951 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:29:48,416]\u001b[0m Trial 952 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:29:48,809]\u001b[0m Trial 953 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:29:50,201]\u001b[0m Trial 954 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:29:52,041]\u001b[0m Trial 955 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:29:55,133]\u001b[0m Trial 956 pruned. Trial was pruned at iteration 26.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:29:56,471]\u001b[0m Trial 957 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:29:57,820]\u001b[0m Trial 958 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:29:59,511]\u001b[0m Trial 959 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:30:00,914]\u001b[0m Trial 960 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:30:02,614]\u001b[0m Trial 961 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:30:03,995]\u001b[0m Trial 962 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:30:39,625]\u001b[0m Trial 963 finished with value: 2.8962954 and parameters: {'max_depth': 9, 'min_child_weight': 3, 'gamma': 7.253587420968739e-07, 'subsample': 0.4856995331690786, 'colsample_bytree': 0.9987002594024956, 'lambda': 3.129305629517356e-08, 'alpha': 1.1104122094028873e-07, 'grow_policy': 'lossguide'}. Best is trial 616 with value: 2.8765868000000006.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:31:24,903]\u001b[0m Trial 964 finished with value: 2.8928053999999994 and parameters: {'max_depth': 10, 'min_child_weight': 3, 'gamma': 2.3691556826478713e-07, 'subsample': 0.478149011697273, 'colsample_bytree': 0.9996547567596168, 'lambda': 1.3960784498830409e-08, 'alpha': 3.6594788325772236e-08, 'grow_policy': 'depthwise'}. Best is trial 616 with value: 2.8765868000000006.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:31:26,893]\u001b[0m Trial 965 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:31:28,889]\u001b[0m Trial 966 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:31:31,537]\u001b[0m Trial 967 pruned. Trial was pruned at iteration 22.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:31:32,923]\u001b[0m Trial 968 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:31:34,978]\u001b[0m Trial 969 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:31:36,110]\u001b[0m Trial 970 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:31:36,649]\u001b[0m Trial 971 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:31:38,092]\u001b[0m Trial 972 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:31:42,351]\u001b[0m Trial 973 pruned. Trial was pruned at iteration 38.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:32:10,516]\u001b[0m Trial 974 pruned. Trial was pruned at iteration 321.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:32:11,890]\u001b[0m Trial 975 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:32:13,217]\u001b[0m Trial 976 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:32:14,674]\u001b[0m Trial 977 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:32:16,018]\u001b[0m Trial 978 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:32:17,797]\u001b[0m Trial 979 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:32:18,234]\u001b[0m Trial 980 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:32:19,207]\u001b[0m Trial 981 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:32:20,633]\u001b[0m Trial 982 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:32:22,451]\u001b[0m Trial 983 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:32:23,822]\u001b[0m Trial 984 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:32:25,937]\u001b[0m Trial 985 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:32:27,313]\u001b[0m Trial 986 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:32:28,270]\u001b[0m Trial 987 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:32:31,072]\u001b[0m Trial 988 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:32:32,227]\u001b[0m Trial 989 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:32:33,378]\u001b[0m Trial 990 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:32:34,886]\u001b[0m Trial 991 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:32:36,113]\u001b[0m Trial 992 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:32:38,344]\u001b[0m Trial 993 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:32:41,550]\u001b[0m Trial 994 pruned. Trial was pruned at iteration 23.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:32:43,961]\u001b[0m Trial 995 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:32:45,804]\u001b[0m Trial 996 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:32:47,149]\u001b[0m Trial 997 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:32:49,589]\u001b[0m Trial 998 pruned. Trial was pruned at iteration 25.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:32:50,925]\u001b[0m Trial 999 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 1000\n",
      "Best trial:\n",
      "  Value: 2.8765868000000006\n",
      "  Params: \n",
      "    max_depth: 10\n",
      "    min_child_weight: 3\n",
      "    gamma: 1.1273311837112433e-07\n",
      "    subsample: 0.48167905375660824\n",
      "    colsample_bytree: 0.9626653908113837\n",
      "    lambda: 3.4544441383016645e-08\n",
      "    alpha: 4.241571364142641e-08\n",
      "    grow_policy: depthwise\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "    param = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'tree_method': 'hist',\n",
    "        'learning_rate': 0.01,\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 10),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 6),\n",
    "        'gamma': trial.suggest_loguniform(\"gamma\", 1e-8, 1.0),\n",
    "        'subsample':trial.suggest_uniform('subsample', 0.1, 1),\n",
    "        'colsample_bytree':trial.suggest_uniform('colsample_bytree', 0.1, 1),\n",
    "        \"lambda\": trial.suggest_loguniform(\"lambda\", 1e-8, 1.0),\n",
    "        \"alpha\": trial.suggest_loguniform(\"alpha\", 1e-8, 1.0),\n",
    "        \"grow_policy\": trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
    "    }\n",
    "\n",
    "    pruning_callback = optuna.integration.XGBoostPruningCallback(trial, \"test-rmse\")\n",
    "\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    history = xgb.cv(param, dtrain, num_boost_round=2000, \n",
    "                     early_stopping_rounds=100,\n",
    "                     callbacks=[pruning_callback],\n",
    "                     metrics='rmse', \n",
    "                     folds=cv)\n",
    "\n",
    "    mean_score = history[\"test-rmse-mean\"].values[-1]\n",
    "    return mean_score\n",
    "\n",
    "pruner = optuna.pruners.MedianPruner(n_warmup_steps=10)\n",
    "study = optuna.create_study(pruner=pruner, direction='minimize')\n",
    "study.optimize(objective, n_trials=1000)\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ggqbIf3UNqYX",
    "outputId": "329a109b-d05c-4499-e932-454e68d31aea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 4.241571364142641e-08,\n",
       " 'colsample_bytree': 0.9626653908113837,\n",
       " 'gamma': 1.1273311837112433e-07,\n",
       " 'grow_policy': 'depthwise',\n",
       " 'lambda': 3.4544441383016645e-08,\n",
       " 'learning_rate': 0.01,\n",
       " 'max_depth': 10,\n",
       " 'min_child_weight': 3,\n",
       " 'objective': 'reg:squarederror',\n",
       " 'subsample': 0.48167905375660824,\n",
       " 'tree_method': 'hist'}"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get best params then add to param_2\n",
    "study_2_params = study.best_params\n",
    "param_2 = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'tree_method': 'hist',\n",
    "    'learning_rate': 0.01,\n",
    "}\n",
    "param_2.update(study_2_params)\n",
    "param_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C1CGZcryWz4x",
    "outputId": "25d50256-fd90-4b29-99c5-043e041573bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "737"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "cv = KFold(\n",
    "    n_splits=5, \n",
    "    shuffle=True, \n",
    "    random_state=0\n",
    ")\n",
    "history = xgb.cv(\n",
    "    param_2, dtrain, \n",
    "    num_boost_round=2000, \n",
    "    early_stopping_rounds=100,\n",
    "    metrics='rmse',\n",
    "    folds=cv\n",
    ")\n",
    "n_estimators_2 = history.shape[0]\n",
    "n_estimators_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46Vnrg0cjRio"
   },
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OLFchLJDXSSE",
    "outputId": "052d7cff-1925-462b-8d1a-b5ec8e103965"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train R2</th>\n",
       "      <th>CV R2</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Train RMSE</th>\n",
       "      <th>CV RMSE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Train MAE</th>\n",
       "      <th>CV MAE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9872</td>\n",
       "      <td>0.9272</td>\n",
       "      <td>0.9143</td>\n",
       "      <td>1.2411</td>\n",
       "      <td>2.9078</td>\n",
       "      <td>3.4386</td>\n",
       "      <td>0.5346</td>\n",
       "      <td>1.1063</td>\n",
       "      <td>1.2659</td>\n",
       "      <td>XGBRegressor (737)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9883</td>\n",
       "      <td>0.9215</td>\n",
       "      <td>0.9129</td>\n",
       "      <td>1.1862</td>\n",
       "      <td>3.0241</td>\n",
       "      <td>3.4659</td>\n",
       "      <td>0.5356</td>\n",
       "      <td>1.1452</td>\n",
       "      <td>1.3158</td>\n",
       "      <td>XGBRegressor (73)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train R2   CV R2  Test R2  ...  CV MAE  Test MAE               Model\n",
       "1    0.9872  0.9272   0.9143  ...  1.1063    1.2659  XGBRegressor (737)\n",
       "0    0.9883  0.9215   0.9129  ...  1.1452    1.3158   XGBRegressor (73)\n",
       "\n",
       "[2 rows x 10 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_study_1 = XGBRegressor(**param_1, n_estimators=n_estimators_1)\n",
    "xgb_study_2 = XGBRegressor(**param_2, n_estimators=n_estimators_2)\n",
    "\n",
    "models = {\n",
    "    f'XGBRegressor ({n_estimators_1})': xgb_study_1,\n",
    "    f'XGBRegressor ({n_estimators_2})': xgb_study_2\n",
    "}\n",
    "evaluate_model(models, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0SoMHIJlYBFk"
   },
   "source": [
    "#### Study 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a2gYuFxmYBF4",
    "outputId": "99d7eaf5-c779-40e4-f4ee-d0580294452a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-10-29 20:34:16,981]\u001b[0m A new study created in memory with name: no-name-f670fbf7-3cd4-4d89-b24c-df8a96bd10cb\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:35:21,142]\u001b[0m Trial 0 finished with value: 2.8993066 and parameters: {'learning_rate': 0.006717476196364012}. Best is trial 0 with value: 2.8993066.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:37:04,821]\u001b[0m Trial 1 finished with value: 2.8944406000000003 and parameters: {'learning_rate': 0.004528649551108013}. Best is trial 1 with value: 2.8944406000000003.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:39:02,243]\u001b[0m Trial 2 finished with value: 2.9068328 and parameters: {'learning_rate': 0.0034886000818777083}. Best is trial 1 with value: 2.8944406000000003.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:41:25,756]\u001b[0m Trial 3 finished with value: 2.9089868 and parameters: {'learning_rate': 0.0024890236114943794}. Best is trial 1 with value: 2.8944406000000003.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:43:33,843]\u001b[0m Trial 4 finished with value: 2.8996508 and parameters: {'learning_rate': 0.0030767161347567415}. Best is trial 1 with value: 2.8944406000000003.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:44:21,022]\u001b[0m Trial 5 finished with value: 2.8812598 and parameters: {'learning_rate': 0.009878060378654456}. Best is trial 5 with value: 2.8812598.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:44:22,402]\u001b[0m Trial 6 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:45:09,610]\u001b[0m Trial 7 finished with value: 2.8868492000000003 and parameters: {'learning_rate': 0.009843666296668403}. Best is trial 5 with value: 2.8812598.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:46:19,640]\u001b[0m Trial 8 finished with value: 2.8940058 and parameters: {'learning_rate': 0.005720603323032747}. Best is trial 5 with value: 2.8812598.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:47:35,098]\u001b[0m Trial 9 finished with value: 2.8869648000000003 and parameters: {'learning_rate': 0.005153764401900382}. Best is trial 5 with value: 2.8812598.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:48:22,424]\u001b[0m Trial 10 finished with value: 2.8939065999999998 and parameters: {'learning_rate': 0.009753568352287028}. Best is trial 5 with value: 2.8812598.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:49:05,508]\u001b[0m Trial 11 finished with value: 2.8784686 and parameters: {'learning_rate': 0.009980474012867925}. Best is trial 11 with value: 2.8784686.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:49:56,178]\u001b[0m Trial 12 pruned. Trial was pruned at iteration 803.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:50:46,728]\u001b[0m Trial 13 finished with value: 2.9029827999999998 and parameters: {'learning_rate': 0.008485838850613056}. Best is trial 11 with value: 2.8784686.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:51:38,209]\u001b[0m Trial 14 finished with value: 2.9007278 and parameters: {'learning_rate': 0.008435695076909543}. Best is trial 11 with value: 2.8784686.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:52:25,665]\u001b[0m Trial 15 finished with value: 2.8840936 and parameters: {'learning_rate': 0.0098540100631142}. Best is trial 11 with value: 2.8784686.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:52:27,066]\u001b[0m Trial 16 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:53:16,334]\u001b[0m Trial 17 pruned. Trial was pruned at iteration 825.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:53:17,729]\u001b[0m Trial 18 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:54:00,815]\u001b[0m Trial 19 finished with value: 2.8858696000000004 and parameters: {'learning_rate': 0.009973940206772614}. Best is trial 11 with value: 2.8784686.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:54:42,627]\u001b[0m Trial 20 pruned. Trial was pruned at iteration 600.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:55:30,543]\u001b[0m Trial 21 finished with value: 2.8835314 and parameters: {'learning_rate': 0.009817956964680113}. Best is trial 11 with value: 2.8784686.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:56:11,119]\u001b[0m Trial 22 pruned. Trial was pruned at iteration 560.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:56:12,545]\u001b[0m Trial 23 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:56:13,969]\u001b[0m Trial 24 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:56:51,663]\u001b[0m Trial 25 pruned. Trial was pruned at iteration 500.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:56:53,088]\u001b[0m Trial 26 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:57:41,902]\u001b[0m Trial 27 finished with value: 2.8745316 and parameters: {'learning_rate': 0.009956302543313311}. Best is trial 27 with value: 2.8745316.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:58:14,590]\u001b[0m Trial 28 pruned. Trial was pruned at iteration 361.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:58:58,883]\u001b[0m Trial 29 pruned. Trial was pruned at iteration 701.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:59:00,296]\u001b[0m Trial 30 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 20:59:47,995]\u001b[0m Trial 31 finished with value: 2.8777776 and parameters: {'learning_rate': 0.009935095730265173}. Best is trial 27 with value: 2.8745316.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:00:35,141]\u001b[0m Trial 32 finished with value: 2.8775569999999995 and parameters: {'learning_rate': 0.009932135081493734}. Best is trial 27 with value: 2.8745316.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:00:36,564]\u001b[0m Trial 33 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:01:20,605]\u001b[0m Trial 34 finished with value: 2.8757222000000002 and parameters: {'learning_rate': 0.009991468558320867}. Best is trial 27 with value: 2.8745316.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:01:22,025]\u001b[0m Trial 35 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:01:23,444]\u001b[0m Trial 36 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:01:24,851]\u001b[0m Trial 37 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:01:26,269]\u001b[0m Trial 38 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:01:27,696]\u001b[0m Trial 39 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:01:29,117]\u001b[0m Trial 40 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:02:16,170]\u001b[0m Trial 41 finished with value: 2.8835668 and parameters: {'learning_rate': 0.00992281433352613}. Best is trial 27 with value: 2.8745316.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:02:17,559]\u001b[0m Trial 42 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:03:05,348]\u001b[0m Trial 43 finished with value: 2.8786274 and parameters: {'learning_rate': 0.009979359686325505}. Best is trial 27 with value: 2.8745316.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:03:52,183]\u001b[0m Trial 44 finished with value: 2.873105 and parameters: {'learning_rate': 0.009987800417601897}. Best is trial 44 with value: 2.873105.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:03:53,581]\u001b[0m Trial 45 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:03:54,981]\u001b[0m Trial 46 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:03:56,377]\u001b[0m Trial 47 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:03:57,776]\u001b[0m Trial 48 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:04:45,909]\u001b[0m Trial 49 finished with value: 2.8803774 and parameters: {'learning_rate': 0.009962935095094867}. Best is trial 44 with value: 2.873105.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:04:47,298]\u001b[0m Trial 50 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:05:35,444]\u001b[0m Trial 51 finished with value: 2.8688364 and parameters: {'learning_rate': 0.009996079810126374}. Best is trial 51 with value: 2.8688364.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:05:36,868]\u001b[0m Trial 52 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:06:20,226]\u001b[0m Trial 53 finished with value: 2.8791422 and parameters: {'learning_rate': 0.009980105091749167}. Best is trial 51 with value: 2.8688364.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:06:21,621]\u001b[0m Trial 54 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:06:23,029]\u001b[0m Trial 55 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:06:24,442]\u001b[0m Trial 56 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:06:25,847]\u001b[0m Trial 57 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:06:27,257]\u001b[0m Trial 58 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:06:28,667]\u001b[0m Trial 59 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:06:30,080]\u001b[0m Trial 60 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:07:17,562]\u001b[0m Trial 61 finished with value: 2.8741418 and parameters: {'learning_rate': 0.009972979822606675}. Best is trial 51 with value: 2.8688364.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:08:04,494]\u001b[0m Trial 62 finished with value: 2.875522 and parameters: {'learning_rate': 0.00999864917513998}. Best is trial 51 with value: 2.8688364.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:08:05,937]\u001b[0m Trial 63 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:08:07,356]\u001b[0m Trial 64 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:08:08,787]\u001b[0m Trial 65 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:08:56,825]\u001b[0m Trial 66 finished with value: 2.8792516000000004 and parameters: {'learning_rate': 0.009978083005080103}. Best is trial 51 with value: 2.8688364.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:08:58,225]\u001b[0m Trial 67 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:08:59,637]\u001b[0m Trial 68 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:09:01,080]\u001b[0m Trial 69 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:09:02,484]\u001b[0m Trial 70 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:09:03,900]\u001b[0m Trial 71 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:09:05,309]\u001b[0m Trial 72 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:09:52,830]\u001b[0m Trial 73 finished with value: 2.8747664000000004 and parameters: {'learning_rate': 0.009943514828926045}. Best is trial 51 with value: 2.8688364.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:09:54,223]\u001b[0m Trial 74 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:10:42,367]\u001b[0m Trial 75 finished with value: 2.8770446 and parameters: {'learning_rate': 0.009979059622167679}. Best is trial 51 with value: 2.8688364.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:10:43,807]\u001b[0m Trial 76 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:11:31,731]\u001b[0m Trial 77 finished with value: 2.8741952 and parameters: {'learning_rate': 0.009993275044200675}. Best is trial 51 with value: 2.8688364.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:11:33,127]\u001b[0m Trial 78 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:11:34,534]\u001b[0m Trial 79 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:11:35,930]\u001b[0m Trial 80 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:12:23,678]\u001b[0m Trial 81 finished with value: 2.8773234000000003 and parameters: {'learning_rate': 0.009978489381490617}. Best is trial 51 with value: 2.8688364.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:12:25,068]\u001b[0m Trial 82 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:13:13,223]\u001b[0m Trial 83 finished with value: 2.8760470000000002 and parameters: {'learning_rate': 0.009992460567122306}. Best is trial 51 with value: 2.8688364.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:13:14,640]\u001b[0m Trial 84 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:13:16,055]\u001b[0m Trial 85 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:13:17,457]\u001b[0m Trial 86 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:13:18,850]\u001b[0m Trial 87 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:13:20,259]\u001b[0m Trial 88 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:13:21,663]\u001b[0m Trial 89 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:13:23,056]\u001b[0m Trial 90 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:14:10,766]\u001b[0m Trial 91 finished with value: 2.8746554000000004 and parameters: {'learning_rate': 0.009984016180764622}. Best is trial 51 with value: 2.8688364.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:14:40,455]\u001b[0m Trial 92 pruned. Trial was pruned at iteration 341.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:14:41,846]\u001b[0m Trial 93 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:14:43,235]\u001b[0m Trial 94 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:14:44,629]\u001b[0m Trial 95 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:15:32,246]\u001b[0m Trial 96 finished with value: 2.877101 and parameters: {'learning_rate': 0.00999380802568534}. Best is trial 51 with value: 2.8688364.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:15:33,638]\u001b[0m Trial 97 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:15:35,040]\u001b[0m Trial 98 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:15:36,450]\u001b[0m Trial 99 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:15:37,867]\u001b[0m Trial 100 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:16:21,627]\u001b[0m Trial 101 finished with value: 2.8775226000000003 and parameters: {'learning_rate': 0.009967378599779649}. Best is trial 51 with value: 2.8688364.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:17:08,199]\u001b[0m Trial 102 finished with value: 2.8724421999999996 and parameters: {'learning_rate': 0.009990612921575694}. Best is trial 51 with value: 2.8688364.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:17:09,591]\u001b[0m Trial 103 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:17:10,996]\u001b[0m Trial 104 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:17:12,394]\u001b[0m Trial 105 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:17:13,792]\u001b[0m Trial 106 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:17:15,192]\u001b[0m Trial 107 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:18:03,005]\u001b[0m Trial 108 finished with value: 2.8749873999999997 and parameters: {'learning_rate': 0.009988258515607086}. Best is trial 51 with value: 2.8688364.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:18:04,410]\u001b[0m Trial 109 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:18:05,813]\u001b[0m Trial 110 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:18:53,663]\u001b[0m Trial 111 finished with value: 2.875489 and parameters: {'learning_rate': 0.009988096613211246}. Best is trial 51 with value: 2.8688364.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:18:55,042]\u001b[0m Trial 112 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:18:56,416]\u001b[0m Trial 113 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:18:57,799]\u001b[0m Trial 114 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:18:59,193]\u001b[0m Trial 115 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:19:00,582]\u001b[0m Trial 116 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:19:19,966]\u001b[0m Trial 117 pruned. Trial was pruned at iteration 190.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:19:21,343]\u001b[0m Trial 118 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:20:08,576]\u001b[0m Trial 119 finished with value: 2.8686952 and parameters: {'learning_rate': 0.009989509504706885}. Best is trial 119 with value: 2.8686952.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:20:56,083]\u001b[0m Trial 120 finished with value: 2.8762864 and parameters: {'learning_rate': 0.009998880472804115}. Best is trial 119 with value: 2.8686952.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:20:57,476]\u001b[0m Trial 121 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:21:46,116]\u001b[0m Trial 122 finished with value: 2.8676008 and parameters: {'learning_rate': 0.009989495071134816}. Best is trial 122 with value: 2.8676008.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:22:33,011]\u001b[0m Trial 123 finished with value: 2.874718 and parameters: {'learning_rate': 0.009998182049696595}. Best is trial 122 with value: 2.8676008.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:22:34,396]\u001b[0m Trial 124 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:23:21,636]\u001b[0m Trial 125 finished with value: 2.8675288000000005 and parameters: {'learning_rate': 0.009996273911841104}. Best is trial 125 with value: 2.8675288000000005.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:23:23,020]\u001b[0m Trial 126 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:23:24,395]\u001b[0m Trial 127 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:23:25,769]\u001b[0m Trial 128 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:23:27,149]\u001b[0m Trial 129 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:23:28,525]\u001b[0m Trial 130 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:23:29,908]\u001b[0m Trial 131 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:23:31,323]\u001b[0m Trial 132 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:24:00,409]\u001b[0m Trial 133 pruned. Trial was pruned at iteration 335.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:24:01,794]\u001b[0m Trial 134 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:24:30,075]\u001b[0m Trial 135 pruned. Trial was pruned at iteration 308.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:24:31,471]\u001b[0m Trial 136 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:25:04,817]\u001b[0m Trial 137 pruned. Trial was pruned at iteration 435.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:25:06,205]\u001b[0m Trial 138 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:25:07,578]\u001b[0m Trial 139 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:25:08,971]\u001b[0m Trial 140 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:25:55,351]\u001b[0m Trial 141 finished with value: 2.8673888 and parameters: {'learning_rate': 0.009995591219202522}. Best is trial 141 with value: 2.8673888.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:25:56,725]\u001b[0m Trial 142 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:25:58,105]\u001b[0m Trial 143 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:26:44,798]\u001b[0m Trial 144 finished with value: 2.8642984 and parameters: {'learning_rate': 0.00999013716708745}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:26:46,185]\u001b[0m Trial 145 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:26:47,565]\u001b[0m Trial 146 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:27:34,488]\u001b[0m Trial 147 finished with value: 2.8719708 and parameters: {'learning_rate': 0.009992816715908908}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:27:35,872]\u001b[0m Trial 148 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:27:37,249]\u001b[0m Trial 149 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:27:38,644]\u001b[0m Trial 150 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:27:40,021]\u001b[0m Trial 151 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:27:41,395]\u001b[0m Trial 152 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:27:42,771]\u001b[0m Trial 153 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:28:12,085]\u001b[0m Trial 154 pruned. Trial was pruned at iteration 338.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:28:13,465]\u001b[0m Trial 155 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:28:14,845]\u001b[0m Trial 156 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:28:16,219]\u001b[0m Trial 157 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:28:17,597]\u001b[0m Trial 158 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:28:18,978]\u001b[0m Trial 159 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:28:20,357]\u001b[0m Trial 160 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:29:07,668]\u001b[0m Trial 161 finished with value: 2.8723932 and parameters: {'learning_rate': 0.009996598827027263}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:29:09,048]\u001b[0m Trial 162 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:29:56,285]\u001b[0m Trial 163 finished with value: 2.8732332 and parameters: {'learning_rate': 0.009989051156087718}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:29:57,658]\u001b[0m Trial 164 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:30:24,443]\u001b[0m Trial 165 pruned. Trial was pruned at iteration 287.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:30:25,814]\u001b[0m Trial 166 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:30:27,206]\u001b[0m Trial 167 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:31:10,131]\u001b[0m Trial 168 finished with value: 2.8751614 and parameters: {'learning_rate': 0.009994718724070314}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:31:38,255]\u001b[0m Trial 169 pruned. Trial was pruned at iteration 314.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:31:39,631]\u001b[0m Trial 170 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:32:16,649]\u001b[0m Trial 171 pruned. Trial was pruned at iteration 543.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:32:18,031]\u001b[0m Trial 172 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:32:19,419]\u001b[0m Trial 173 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:33:02,367]\u001b[0m Trial 174 finished with value: 2.8779468 and parameters: {'learning_rate': 0.009994340645607114}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:33:03,759]\u001b[0m Trial 175 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:33:05,145]\u001b[0m Trial 176 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:33:33,720]\u001b[0m Trial 177 pruned. Trial was pruned at iteration 318.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:33:35,097]\u001b[0m Trial 178 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:34:22,284]\u001b[0m Trial 179 finished with value: 2.8681492000000004 and parameters: {'learning_rate': 0.009996506995920086}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:34:23,660]\u001b[0m Trial 180 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:34:25,046]\u001b[0m Trial 181 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:34:54,412]\u001b[0m Trial 182 pruned. Trial was pruned at iteration 337.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:34:55,799]\u001b[0m Trial 183 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:35:42,268]\u001b[0m Trial 184 finished with value: 2.8680436 and parameters: {'learning_rate': 0.009997040222511442}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:35:43,641]\u001b[0m Trial 185 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:35:45,015]\u001b[0m Trial 186 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:35:46,404]\u001b[0m Trial 187 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:36:33,356]\u001b[0m Trial 188 finished with value: 2.8695136000000003 and parameters: {'learning_rate': 0.009994383320463767}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:37:19,809]\u001b[0m Trial 189 finished with value: 2.8710338 and parameters: {'learning_rate': 0.00999545197515047}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:38:06,295]\u001b[0m Trial 190 finished with value: 2.8719780000000004 and parameters: {'learning_rate': 0.009998037993157393}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:38:34,356]\u001b[0m Trial 191 pruned. Trial was pruned at iteration 314.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:38:35,736]\u001b[0m Trial 192 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:39:23,469]\u001b[0m Trial 193 finished with value: 2.866708 and parameters: {'learning_rate': 0.009995968446104059}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:39:24,877]\u001b[0m Trial 194 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:39:26,257]\u001b[0m Trial 195 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:39:56,409]\u001b[0m Trial 196 pruned. Trial was pruned at iteration 356.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:40:18,327]\u001b[0m Trial 197 pruned. Trial was pruned at iteration 223.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:40:19,708]\u001b[0m Trial 198 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:40:21,085]\u001b[0m Trial 199 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:40:45,179]\u001b[0m Trial 200 pruned. Trial was pruned at iteration 251.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:40:46,566]\u001b[0m Trial 201 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:41:33,109]\u001b[0m Trial 202 finished with value: 2.8673818 and parameters: {'learning_rate': 0.009990621026851925}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:42:11,457]\u001b[0m Trial 203 pruned. Trial was pruned at iteration 567.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:42:12,840]\u001b[0m Trial 204 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:42:14,230]\u001b[0m Trial 205 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:42:15,609]\u001b[0m Trial 206 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:42:16,986]\u001b[0m Trial 207 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:42:18,367]\u001b[0m Trial 208 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:42:19,747]\u001b[0m Trial 209 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:42:21,136]\u001b[0m Trial 210 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:43:08,576]\u001b[0m Trial 211 finished with value: 2.8713514000000004 and parameters: {'learning_rate': 0.009991933844252917}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:43:09,951]\u001b[0m Trial 212 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:43:11,330]\u001b[0m Trial 213 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:43:12,710]\u001b[0m Trial 214 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:43:55,898]\u001b[0m Trial 215 pruned. Trial was pruned at iteration 735.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:44:26,221]\u001b[0m Trial 216 pruned. Trial was pruned at iteration 358.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:44:27,602]\u001b[0m Trial 217 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:44:28,990]\u001b[0m Trial 218 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:45:12,436]\u001b[0m Trial 219 finished with value: 2.8746744 and parameters: {'learning_rate': 0.009991535954065671}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:45:13,835]\u001b[0m Trial 220 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:45:15,226]\u001b[0m Trial 221 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:45:47,566]\u001b[0m Trial 222 pruned. Trial was pruned at iteration 406.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:46:08,913]\u001b[0m Trial 223 pruned. Trial was pruned at iteration 215.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:46:10,291]\u001b[0m Trial 224 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:46:11,669]\u001b[0m Trial 225 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:46:32,023]\u001b[0m Trial 226 pruned. Trial was pruned at iteration 203.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:46:33,405]\u001b[0m Trial 227 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:46:34,789]\u001b[0m Trial 228 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:46:36,169]\u001b[0m Trial 229 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:46:37,544]\u001b[0m Trial 230 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:46:38,922]\u001b[0m Trial 231 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:46:40,305]\u001b[0m Trial 232 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:46:41,677]\u001b[0m Trial 233 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:47:28,397]\u001b[0m Trial 234 finished with value: 2.8696206 and parameters: {'learning_rate': 0.009996355928161504}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:47:29,789]\u001b[0m Trial 235 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:48:01,182]\u001b[0m Trial 236 pruned. Trial was pruned at iteration 369.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:48:26,167]\u001b[0m Trial 237 pruned. Trial was pruned at iteration 264.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:48:27,545]\u001b[0m Trial 238 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:48:28,926]\u001b[0m Trial 239 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:49:12,000]\u001b[0m Trial 240 pruned. Trial was pruned at iteration 727.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:49:59,433]\u001b[0m Trial 241 finished with value: 2.8715970000000004 and parameters: {'learning_rate': 0.009989324020955731}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:50:14,959]\u001b[0m Trial 242 pruned. Trial was pruned at iteration 148.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:50:16,342]\u001b[0m Trial 243 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:50:53,444]\u001b[0m Trial 244 pruned. Trial was pruned at iteration 526.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:50:54,820]\u001b[0m Trial 245 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:51:37,997]\u001b[0m Trial 246 finished with value: 2.8699528 and parameters: {'learning_rate': 0.009992048025004812}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:52:07,441]\u001b[0m Trial 247 pruned. Trial was pruned at iteration 335.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:52:08,843]\u001b[0m Trial 248 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:52:10,228]\u001b[0m Trial 249 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:52:53,558]\u001b[0m Trial 250 finished with value: 2.874068 and parameters: {'learning_rate': 0.009991336425360089}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:52:54,945]\u001b[0m Trial 251 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:53:42,600]\u001b[0m Trial 252 finished with value: 2.8680820000000002 and parameters: {'learning_rate': 0.009989830892201972}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:54:10,979]\u001b[0m Trial 253 pruned. Trial was pruned at iteration 310.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:54:12,358]\u001b[0m Trial 254 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:54:59,865]\u001b[0m Trial 255 finished with value: 2.8659018000000005 and parameters: {'learning_rate': 0.009996053900182034}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:55:01,259]\u001b[0m Trial 256 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:55:31,682]\u001b[0m Trial 257 pruned. Trial was pruned at iteration 358.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:55:33,064]\u001b[0m Trial 258 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:56:20,205]\u001b[0m Trial 259 finished with value: 2.8750303999999995 and parameters: {'learning_rate': 0.009994366972407208}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:56:21,585]\u001b[0m Trial 260 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:56:22,974]\u001b[0m Trial 261 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:56:24,358]\u001b[0m Trial 262 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:56:25,738]\u001b[0m Trial 263 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:56:27,132]\u001b[0m Trial 264 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:56:28,526]\u001b[0m Trial 265 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:56:41,980]\u001b[0m Trial 266 pruned. Trial was pruned at iteration 126.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:56:43,363]\u001b[0m Trial 267 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:57:13,445]\u001b[0m Trial 268 pruned. Trial was pruned at iteration 338.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:57:14,862]\u001b[0m Trial 269 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:57:44,193]\u001b[0m Trial 270 pruned. Trial was pruned at iteration 334.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:57:45,581]\u001b[0m Trial 271 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:57:46,967]\u001b[0m Trial 272 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:58:02,944]\u001b[0m Trial 273 pruned. Trial was pruned at iteration 152.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:58:04,344]\u001b[0m Trial 274 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:58:05,753]\u001b[0m Trial 275 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:58:52,431]\u001b[0m Trial 276 finished with value: 2.8692970000000004 and parameters: {'learning_rate': 0.009991852596775957}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:58:53,823]\u001b[0m Trial 277 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:58:55,199]\u001b[0m Trial 278 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:59:23,621]\u001b[0m Trial 279 pruned. Trial was pruned at iteration 318.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:59:25,002]\u001b[0m Trial 280 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:59:54,725]\u001b[0m Trial 281 pruned. Trial was pruned at iteration 338.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:59:56,105]\u001b[0m Trial 282 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 21:59:57,500]\u001b[0m Trial 283 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:00:26,856]\u001b[0m Trial 284 pruned. Trial was pruned at iteration 337.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:00:28,260]\u001b[0m Trial 285 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:00:29,640]\u001b[0m Trial 286 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:00:31,036]\u001b[0m Trial 287 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:00:32,431]\u001b[0m Trial 288 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:00:33,816]\u001b[0m Trial 289 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:00:35,202]\u001b[0m Trial 290 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:00:36,595]\u001b[0m Trial 291 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:01:10,978]\u001b[0m Trial 292 pruned. Trial was pruned at iteration 453.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:01:12,370]\u001b[0m Trial 293 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:01:13,746]\u001b[0m Trial 294 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:02:01,215]\u001b[0m Trial 295 finished with value: 2.8721317999999996 and parameters: {'learning_rate': 0.009994037395489914}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:02:02,601]\u001b[0m Trial 296 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:02:03,994]\u001b[0m Trial 297 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:02:34,358]\u001b[0m Trial 298 pruned. Trial was pruned at iteration 351.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:03:22,399]\u001b[0m Trial 299 finished with value: 2.870578 and parameters: {'learning_rate': 0.00999802223889138}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:03:23,772]\u001b[0m Trial 300 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:04:11,335]\u001b[0m Trial 301 finished with value: 2.8677992 and parameters: {'learning_rate': 0.009996559506431853}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:04:12,713]\u001b[0m Trial 302 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:04:32,842]\u001b[0m Trial 303 pruned. Trial was pruned at iteration 200.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:04:34,224]\u001b[0m Trial 304 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:04:35,613]\u001b[0m Trial 305 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:04:36,996]\u001b[0m Trial 306 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:04:38,388]\u001b[0m Trial 307 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:04:39,771]\u001b[0m Trial 308 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:04:41,152]\u001b[0m Trial 309 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:04:42,541]\u001b[0m Trial 310 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:04:43,927]\u001b[0m Trial 311 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:04:45,310]\u001b[0m Trial 312 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:04:46,701]\u001b[0m Trial 313 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:04:48,089]\u001b[0m Trial 314 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:04:49,470]\u001b[0m Trial 315 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:04:50,859]\u001b[0m Trial 316 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:04:52,284]\u001b[0m Trial 317 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:05:16,858]\u001b[0m Trial 318 pruned. Trial was pruned at iteration 257.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:05:37,534]\u001b[0m Trial 319 pruned. Trial was pruned at iteration 205.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:05:38,923]\u001b[0m Trial 320 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:05:40,303]\u001b[0m Trial 321 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:05:41,690]\u001b[0m Trial 322 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:05:43,066]\u001b[0m Trial 323 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:05:44,446]\u001b[0m Trial 324 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:06:06,411]\u001b[0m Trial 325 pruned. Trial was pruned at iteration 218.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:06:32,822]\u001b[0m Trial 326 pruned. Trial was pruned at iteration 285.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:06:34,209]\u001b[0m Trial 327 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:06:35,601]\u001b[0m Trial 328 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:06:36,981]\u001b[0m Trial 329 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:07:06,213]\u001b[0m Trial 330 pruned. Trial was pruned at iteration 334.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:07:07,595]\u001b[0m Trial 331 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:07:08,993]\u001b[0m Trial 332 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:07:10,379]\u001b[0m Trial 333 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:07:53,648]\u001b[0m Trial 334 finished with value: 2.8751612 and parameters: {'learning_rate': 0.009994719986152242}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:07:55,034]\u001b[0m Trial 335 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:07:56,409]\u001b[0m Trial 336 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:08:45,068]\u001b[0m Trial 337 finished with value: 2.8667088000000005 and parameters: {'learning_rate': 0.00999090475391495}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:08:46,460]\u001b[0m Trial 338 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:08:47,856]\u001b[0m Trial 339 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:09:22,378]\u001b[0m Trial 340 pruned. Trial was pruned at iteration 445.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:09:45,655]\u001b[0m Trial 341 pruned. Trial was pruned at iteration 240.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:09:47,044]\u001b[0m Trial 342 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:10:30,297]\u001b[0m Trial 343 finished with value: 2.8713194 and parameters: {'learning_rate': 0.009991349589226813}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:10:31,684]\u001b[0m Trial 344 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:10:51,095]\u001b[0m Trial 345 pruned. Trial was pruned at iteration 190.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:10:52,485]\u001b[0m Trial 346 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:10:53,879]\u001b[0m Trial 347 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:11:17,680]\u001b[0m Trial 348 pruned. Trial was pruned at iteration 245.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:11:19,068]\u001b[0m Trial 349 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:11:36,521]\u001b[0m Trial 350 pruned. Trial was pruned at iteration 169.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:11:37,903]\u001b[0m Trial 351 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:11:39,284]\u001b[0m Trial 352 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:11:40,663]\u001b[0m Trial 353 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:11:42,040]\u001b[0m Trial 354 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:12:29,883]\u001b[0m Trial 355 finished with value: 2.8683944 and parameters: {'learning_rate': 0.009996522967577746}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:12:31,276]\u001b[0m Trial 356 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:12:32,665]\u001b[0m Trial 357 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:12:53,148]\u001b[0m Trial 358 pruned. Trial was pruned at iteration 200.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:12:54,547]\u001b[0m Trial 359 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:12:55,939]\u001b[0m Trial 360 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:13:22,558]\u001b[0m Trial 361 pruned. Trial was pruned at iteration 289.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:13:23,943]\u001b[0m Trial 362 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:13:25,338]\u001b[0m Trial 363 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:13:26,718]\u001b[0m Trial 364 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:13:28,109]\u001b[0m Trial 365 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:13:56,400]\u001b[0m Trial 366 pruned. Trial was pruned at iteration 315.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:13:57,786]\u001b[0m Trial 367 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:14:18,383]\u001b[0m Trial 368 pruned. Trial was pruned at iteration 204.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:14:19,766]\u001b[0m Trial 369 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:14:21,141]\u001b[0m Trial 370 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:14:22,520]\u001b[0m Trial 371 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:14:23,898]\u001b[0m Trial 372 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:14:41,534]\u001b[0m Trial 373 pruned. Trial was pruned at iteration 171.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:14:42,916]\u001b[0m Trial 374 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:15:03,115]\u001b[0m Trial 375 pruned. Trial was pruned at iteration 200.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:15:22,738]\u001b[0m Trial 376 pruned. Trial was pruned at iteration 188.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:15:24,126]\u001b[0m Trial 377 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:15:25,517]\u001b[0m Trial 378 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:15:26,904]\u001b[0m Trial 379 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:15:28,294]\u001b[0m Trial 380 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:15:29,682]\u001b[0m Trial 381 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:15:31,078]\u001b[0m Trial 382 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:15:32,463]\u001b[0m Trial 383 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:15:33,851]\u001b[0m Trial 384 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:15:35,236]\u001b[0m Trial 385 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:15:36,630]\u001b[0m Trial 386 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:15:38,023]\u001b[0m Trial 387 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:16:05,847]\u001b[0m Trial 388 pruned. Trial was pruned at iteration 307.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:16:07,236]\u001b[0m Trial 389 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:16:23,030]\u001b[0m Trial 390 pruned. Trial was pruned at iteration 150.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:16:45,298]\u001b[0m Trial 391 pruned. Trial was pruned at iteration 224.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:16:46,704]\u001b[0m Trial 392 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:16:48,097]\u001b[0m Trial 393 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:16:49,495]\u001b[0m Trial 394 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:16:50,896]\u001b[0m Trial 395 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:16:52,295]\u001b[0m Trial 396 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:16:53,693]\u001b[0m Trial 397 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:16:55,082]\u001b[0m Trial 398 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:16:56,466]\u001b[0m Trial 399 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:17:33,519]\u001b[0m Trial 400 pruned. Trial was pruned at iteration 523.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:18:03,015]\u001b[0m Trial 401 pruned. Trial was pruned at iteration 335.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:18:04,420]\u001b[0m Trial 402 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:18:30,328]\u001b[0m Trial 403 pruned. Trial was pruned at iteration 270.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:18:31,739]\u001b[0m Trial 404 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:18:33,126]\u001b[0m Trial 405 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:18:34,526]\u001b[0m Trial 406 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:18:35,961]\u001b[0m Trial 407 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:18:53,836]\u001b[0m Trial 408 pruned. Trial was pruned at iteration 171.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:18:55,223]\u001b[0m Trial 409 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:18:56,604]\u001b[0m Trial 410 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:18:57,989]\u001b[0m Trial 411 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:18:59,384]\u001b[0m Trial 412 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:19:14,648]\u001b[0m Trial 413 pruned. Trial was pruned at iteration 144.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:19:16,038]\u001b[0m Trial 414 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:19:17,440]\u001b[0m Trial 415 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:19:18,819]\u001b[0m Trial 416 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:19:31,489]\u001b[0m Trial 417 pruned. Trial was pruned at iteration 118.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:19:32,885]\u001b[0m Trial 418 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:20:00,289]\u001b[0m Trial 419 pruned. Trial was pruned at iteration 301.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:20:01,703]\u001b[0m Trial 420 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:20:03,110]\u001b[0m Trial 421 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:20:04,525]\u001b[0m Trial 422 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:20:05,923]\u001b[0m Trial 423 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:20:07,309]\u001b[0m Trial 424 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:20:08,693]\u001b[0m Trial 425 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:20:10,086]\u001b[0m Trial 426 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:20:11,480]\u001b[0m Trial 427 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:20:12,872]\u001b[0m Trial 428 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:20:42,187]\u001b[0m Trial 429 pruned. Trial was pruned at iteration 335.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:20:43,584]\u001b[0m Trial 430 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:21:20,441]\u001b[0m Trial 431 pruned. Trial was pruned at iteration 527.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:21:21,847]\u001b[0m Trial 432 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:21:23,237]\u001b[0m Trial 433 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:21:50,819]\u001b[0m Trial 434 pruned. Trial was pruned at iteration 295.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:22:15,606]\u001b[0m Trial 435 pruned. Trial was pruned at iteration 258.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:22:17,009]\u001b[0m Trial 436 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:22:18,405]\u001b[0m Trial 437 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:22:19,801]\u001b[0m Trial 438 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:22:21,193]\u001b[0m Trial 439 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:22:43,377]\u001b[0m Trial 440 pruned. Trial was pruned at iteration 224.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:22:44,768]\u001b[0m Trial 441 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:22:46,178]\u001b[0m Trial 442 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:22:47,580]\u001b[0m Trial 443 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:23:03,577]\u001b[0m Trial 444 pruned. Trial was pruned at iteration 151.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:23:04,989]\u001b[0m Trial 445 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:23:34,521]\u001b[0m Trial 446 pruned. Trial was pruned at iteration 332.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:23:35,914]\u001b[0m Trial 447 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:24:02,546]\u001b[0m Trial 448 pruned. Trial was pruned at iteration 286.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:24:03,936]\u001b[0m Trial 449 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:24:05,345]\u001b[0m Trial 450 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:24:06,730]\u001b[0m Trial 451 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:24:08,116]\u001b[0m Trial 452 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:24:09,513]\u001b[0m Trial 453 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:24:25,301]\u001b[0m Trial 454 pruned. Trial was pruned at iteration 150.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:24:26,700]\u001b[0m Trial 455 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:24:28,089]\u001b[0m Trial 456 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:24:29,479]\u001b[0m Trial 457 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:24:44,087]\u001b[0m Trial 458 pruned. Trial was pruned at iteration 135.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:24:59,319]\u001b[0m Trial 459 pruned. Trial was pruned at iteration 144.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:25:00,706]\u001b[0m Trial 460 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:25:02,116]\u001b[0m Trial 461 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:25:03,527]\u001b[0m Trial 462 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:25:20,990]\u001b[0m Trial 463 pruned. Trial was pruned at iteration 168.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:26:08,584]\u001b[0m Trial 464 finished with value: 2.8676576000000003 and parameters: {'learning_rate': 0.009996306021826148}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:26:09,962]\u001b[0m Trial 465 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:26:36,055]\u001b[0m Trial 466 pruned. Trial was pruned at iteration 279.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:26:51,959]\u001b[0m Trial 467 pruned. Trial was pruned at iteration 151.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:26:53,366]\u001b[0m Trial 468 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:26:54,759]\u001b[0m Trial 469 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:27:20,325]\u001b[0m Trial 470 pruned. Trial was pruned at iteration 270.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:27:21,725]\u001b[0m Trial 471 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:27:54,500]\u001b[0m Trial 472 pruned. Trial was pruned at iteration 402.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:27:55,887]\u001b[0m Trial 473 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:27:57,267]\u001b[0m Trial 474 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:27:58,659]\u001b[0m Trial 475 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:28:00,043]\u001b[0m Trial 476 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:28:01,443]\u001b[0m Trial 477 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:28:02,868]\u001b[0m Trial 478 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:28:04,274]\u001b[0m Trial 479 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:28:05,686]\u001b[0m Trial 480 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:28:07,078]\u001b[0m Trial 481 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:28:08,471]\u001b[0m Trial 482 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:28:31,999]\u001b[0m Trial 483 pruned. Trial was pruned at iteration 240.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:28:33,409]\u001b[0m Trial 484 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:28:34,813]\u001b[0m Trial 485 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:28:36,218]\u001b[0m Trial 486 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:28:37,616]\u001b[0m Trial 487 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:28:39,008]\u001b[0m Trial 488 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:29:01,122]\u001b[0m Trial 489 pruned. Trial was pruned at iteration 220.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:29:02,557]\u001b[0m Trial 490 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:29:03,979]\u001b[0m Trial 491 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:29:33,312]\u001b[0m Trial 492 pruned. Trial was pruned at iteration 330.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:29:34,705]\u001b[0m Trial 493 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:30:21,882]\u001b[0m Trial 494 finished with value: 2.8708704000000003 and parameters: {'learning_rate': 0.0099964493281645}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:30:23,279]\u001b[0m Trial 495 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:30:24,664]\u001b[0m Trial 496 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:30:26,054]\u001b[0m Trial 497 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:30:27,452]\u001b[0m Trial 498 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:30:28,847]\u001b[0m Trial 499 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:30:58,930]\u001b[0m Trial 500 pruned. Trial was pruned at iteration 338.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:31:25,563]\u001b[0m Trial 501 pruned. Trial was pruned at iteration 287.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:31:26,958]\u001b[0m Trial 502 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:31:48,428]\u001b[0m Trial 503 pruned. Trial was pruned at iteration 216.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:31:49,823]\u001b[0m Trial 504 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:32:17,520]\u001b[0m Trial 505 pruned. Trial was pruned at iteration 304.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:33:05,452]\u001b[0m Trial 506 finished with value: 2.8731186 and parameters: {'learning_rate': 0.009996261793404444}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:33:06,850]\u001b[0m Trial 507 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:33:08,244]\u001b[0m Trial 508 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:33:09,626]\u001b[0m Trial 509 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:33:40,300]\u001b[0m Trial 510 pruned. Trial was pruned at iteration 360.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:33:41,688]\u001b[0m Trial 511 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:33:43,071]\u001b[0m Trial 512 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:33:58,925]\u001b[0m Trial 513 pruned. Trial was pruned at iteration 150.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:34:00,371]\u001b[0m Trial 514 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:34:16,468]\u001b[0m Trial 515 pruned. Trial was pruned at iteration 146.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:34:17,858]\u001b[0m Trial 516 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:34:19,256]\u001b[0m Trial 517 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:34:48,027]\u001b[0m Trial 518 pruned. Trial was pruned at iteration 324.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:35:35,769]\u001b[0m Trial 519 finished with value: 2.8693218 and parameters: {'learning_rate': 0.009998935733001495}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:35:37,168]\u001b[0m Trial 520 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:35:38,573]\u001b[0m Trial 521 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:36:05,379]\u001b[0m Trial 522 pruned. Trial was pruned at iteration 289.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:36:06,773]\u001b[0m Trial 523 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:36:54,480]\u001b[0m Trial 524 finished with value: 2.869536 and parameters: {'learning_rate': 0.00999700824386731}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:36:55,881]\u001b[0m Trial 525 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:36:57,264]\u001b[0m Trial 526 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:36:58,664]\u001b[0m Trial 527 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:37:26,620]\u001b[0m Trial 528 pruned. Trial was pruned at iteration 302.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:37:28,007]\u001b[0m Trial 529 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:37:29,420]\u001b[0m Trial 530 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:37:49,605]\u001b[0m Trial 531 pruned. Trial was pruned at iteration 200.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:37:50,995]\u001b[0m Trial 532 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:38:19,970]\u001b[0m Trial 533 pruned. Trial was pruned at iteration 328.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:39:07,940]\u001b[0m Trial 534 finished with value: 2.8695254 and parameters: {'learning_rate': 0.009996971168581219}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:39:09,325]\u001b[0m Trial 535 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:39:10,706]\u001b[0m Trial 536 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:39:12,096]\u001b[0m Trial 537 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:39:13,499]\u001b[0m Trial 538 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:39:14,925]\u001b[0m Trial 539 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:39:41,633]\u001b[0m Trial 540 pruned. Trial was pruned at iteration 289.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:39:43,027]\u001b[0m Trial 541 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:39:44,414]\u001b[0m Trial 542 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:40:05,341]\u001b[0m Trial 543 pruned. Trial was pruned at iteration 209.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:40:06,727]\u001b[0m Trial 544 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:40:30,012]\u001b[0m Trial 545 pruned. Trial was pruned at iteration 233.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:40:31,406]\u001b[0m Trial 546 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:40:56,776]\u001b[0m Trial 547 pruned. Trial was pruned at iteration 267.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:40:58,161]\u001b[0m Trial 548 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:40:59,551]\u001b[0m Trial 549 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:41:26,415]\u001b[0m Trial 550 pruned. Trial was pruned at iteration 290.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:41:27,805]\u001b[0m Trial 551 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:41:55,571]\u001b[0m Trial 552 pruned. Trial was pruned at iteration 306.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:41:56,963]\u001b[0m Trial 553 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:41:58,350]\u001b[0m Trial 554 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:41:59,735]\u001b[0m Trial 555 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:42:01,127]\u001b[0m Trial 556 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:42:02,525]\u001b[0m Trial 557 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:42:03,928]\u001b[0m Trial 558 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:42:24,653]\u001b[0m Trial 559 pruned. Trial was pruned at iteration 206.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:43:08,142]\u001b[0m Trial 560 finished with value: 2.8744249999999996 and parameters: {'learning_rate': 0.009996058589279917}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:43:45,081]\u001b[0m Trial 561 pruned. Trial was pruned at iteration 516.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:43:46,490]\u001b[0m Trial 562 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:43:47,896]\u001b[0m Trial 563 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:43:49,331]\u001b[0m Trial 564 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:43:50,753]\u001b[0m Trial 565 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:44:11,164]\u001b[0m Trial 566 pruned. Trial was pruned at iteration 198.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:44:12,596]\u001b[0m Trial 567 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:44:14,007]\u001b[0m Trial 568 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:44:15,413]\u001b[0m Trial 569 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:44:31,055]\u001b[0m Trial 570 pruned. Trial was pruned at iteration 148.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:44:32,463]\u001b[0m Trial 571 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:44:47,601]\u001b[0m Trial 572 pruned. Trial was pruned at iteration 142.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:45:07,002]\u001b[0m Trial 573 pruned. Trial was pruned at iteration 188.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:45:30,512]\u001b[0m Trial 574 pruned. Trial was pruned at iteration 241.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:45:31,902]\u001b[0m Trial 575 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:45:33,302]\u001b[0m Trial 576 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:45:34,699]\u001b[0m Trial 577 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:45:36,098]\u001b[0m Trial 578 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:45:37,488]\u001b[0m Trial 579 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:45:57,595]\u001b[0m Trial 580 pruned. Trial was pruned at iteration 198.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:45:59,003]\u001b[0m Trial 581 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:46:00,392]\u001b[0m Trial 582 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:46:01,784]\u001b[0m Trial 583 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:46:28,575]\u001b[0m Trial 584 pruned. Trial was pruned at iteration 289.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:46:29,975]\u001b[0m Trial 585 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:46:31,370]\u001b[0m Trial 586 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:46:51,517]\u001b[0m Trial 587 pruned. Trial was pruned at iteration 198.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:47:17,471]\u001b[0m Trial 588 pruned. Trial was pruned at iteration 267.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:47:43,954]\u001b[0m Trial 589 pruned. Trial was pruned at iteration 286.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:47:45,355]\u001b[0m Trial 590 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:47:46,755]\u001b[0m Trial 591 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:47:48,146]\u001b[0m Trial 592 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:48:15,387]\u001b[0m Trial 593 pruned. Trial was pruned at iteration 297.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:48:16,780]\u001b[0m Trial 594 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:48:18,164]\u001b[0m Trial 595 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:48:19,571]\u001b[0m Trial 596 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:48:20,957]\u001b[0m Trial 597 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:48:22,346]\u001b[0m Trial 598 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:48:23,744]\u001b[0m Trial 599 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:48:25,127]\u001b[0m Trial 600 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:48:51,946]\u001b[0m Trial 601 pruned. Trial was pruned at iteration 290.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:49:19,102]\u001b[0m Trial 602 pruned. Trial was pruned at iteration 290.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:49:20,527]\u001b[0m Trial 603 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:49:50,856]\u001b[0m Trial 604 pruned. Trial was pruned at iteration 354.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:49:52,264]\u001b[0m Trial 605 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:49:53,661]\u001b[0m Trial 606 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:50:16,705]\u001b[0m Trial 607 pruned. Trial was pruned at iteration 235.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:50:18,104]\u001b[0m Trial 608 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:50:47,205]\u001b[0m Trial 609 pruned. Trial was pruned at iteration 324.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:50:48,617]\u001b[0m Trial 610 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:50:50,012]\u001b[0m Trial 611 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:50:51,419]\u001b[0m Trial 612 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:50:52,821]\u001b[0m Trial 613 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:50:54,226]\u001b[0m Trial 614 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:50:55,615]\u001b[0m Trial 615 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:50:57,006]\u001b[0m Trial 616 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:50:58,399]\u001b[0m Trial 617 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:51:25,963]\u001b[0m Trial 618 pruned. Trial was pruned at iteration 302.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:51:27,353]\u001b[0m Trial 619 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:51:59,677]\u001b[0m Trial 620 pruned. Trial was pruned at iteration 401.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:52:01,071]\u001b[0m Trial 621 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:52:16,544]\u001b[0m Trial 622 pruned. Trial was pruned at iteration 146.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:52:17,940]\u001b[0m Trial 623 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:52:19,330]\u001b[0m Trial 624 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:52:44,950]\u001b[0m Trial 625 pruned. Trial was pruned at iteration 271.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:53:07,724]\u001b[0m Trial 626 pruned. Trial was pruned at iteration 232.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:53:31,232]\u001b[0m Trial 627 pruned. Trial was pruned at iteration 241.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:53:32,627]\u001b[0m Trial 628 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:53:34,021]\u001b[0m Trial 629 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:53:35,419]\u001b[0m Trial 630 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:53:36,832]\u001b[0m Trial 631 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:53:38,244]\u001b[0m Trial 632 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:53:39,716]\u001b[0m Trial 633 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:53:41,607]\u001b[0m Trial 634 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:54:05,215]\u001b[0m Trial 635 pruned. Trial was pruned at iteration 243.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:54:52,284]\u001b[0m Trial 636 finished with value: 2.8686118 and parameters: {'learning_rate': 0.009996281465059164}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:54:53,683]\u001b[0m Trial 637 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:54:55,076]\u001b[0m Trial 638 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:54:56,472]\u001b[0m Trial 639 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:54:57,862]\u001b[0m Trial 640 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:55:12,945]\u001b[0m Trial 641 pruned. Trial was pruned at iteration 142.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:55:14,349]\u001b[0m Trial 642 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:55:15,748]\u001b[0m Trial 643 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:55:17,133]\u001b[0m Trial 644 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:55:18,541]\u001b[0m Trial 645 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:55:19,937]\u001b[0m Trial 646 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:55:21,337]\u001b[0m Trial 647 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:55:49,143]\u001b[0m Trial 648 pruned. Trial was pruned at iteration 307.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:55:50,547]\u001b[0m Trial 649 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:55:51,951]\u001b[0m Trial 650 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:55:53,357]\u001b[0m Trial 651 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:56:08,825]\u001b[0m Trial 652 pruned. Trial was pruned at iteration 146.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:56:10,224]\u001b[0m Trial 653 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:56:11,624]\u001b[0m Trial 654 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:56:13,018]\u001b[0m Trial 655 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:56:14,416]\u001b[0m Trial 656 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:56:15,812]\u001b[0m Trial 657 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:56:17,200]\u001b[0m Trial 658 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:56:18,591]\u001b[0m Trial 659 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:57:06,751]\u001b[0m Trial 660 finished with value: 2.8706364 and parameters: {'learning_rate': 0.009995931161314042}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:57:08,150]\u001b[0m Trial 661 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:57:35,475]\u001b[0m Trial 662 pruned. Trial was pruned at iteration 299.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:57:54,730]\u001b[0m Trial 663 pruned. Trial was pruned at iteration 188.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:58:10,204]\u001b[0m Trial 664 pruned. Trial was pruned at iteration 146.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:58:25,667]\u001b[0m Trial 665 pruned. Trial was pruned at iteration 146.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:58:45,915]\u001b[0m Trial 666 pruned. Trial was pruned at iteration 200.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:58:47,314]\u001b[0m Trial 667 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:58:48,712]\u001b[0m Trial 668 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:58:50,108]\u001b[0m Trial 669 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:59:15,439]\u001b[0m Trial 670 pruned. Trial was pruned at iteration 265.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:59:16,843]\u001b[0m Trial 671 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:59:18,239]\u001b[0m Trial 672 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:59:19,647]\u001b[0m Trial 673 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:59:21,042]\u001b[0m Trial 674 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:59:22,459]\u001b[0m Trial 675 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:59:23,870]\u001b[0m Trial 676 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:59:25,285]\u001b[0m Trial 677 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:59:26,690]\u001b[0m Trial 678 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:59:44,986]\u001b[0m Trial 679 pruned. Trial was pruned at iteration 175.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:59:46,383]\u001b[0m Trial 680 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:59:47,790]\u001b[0m Trial 681 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 22:59:49,181]\u001b[0m Trial 682 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:00:16,302]\u001b[0m Trial 683 pruned. Trial was pruned at iteration 289.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:00:17,691]\u001b[0m Trial 684 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:00:19,091]\u001b[0m Trial 685 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:00:20,481]\u001b[0m Trial 686 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:00:21,903]\u001b[0m Trial 687 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:00:23,311]\u001b[0m Trial 688 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:00:24,714]\u001b[0m Trial 689 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:00:26,124]\u001b[0m Trial 690 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:00:27,544]\u001b[0m Trial 691 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:00:29,611]\u001b[0m Trial 692 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:00:31,013]\u001b[0m Trial 693 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:00:32,418]\u001b[0m Trial 694 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:00:33,808]\u001b[0m Trial 695 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:00:35,210]\u001b[0m Trial 696 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:00:36,612]\u001b[0m Trial 697 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:00:38,010]\u001b[0m Trial 698 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:00:39,411]\u001b[0m Trial 699 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:01:04,776]\u001b[0m Trial 700 pruned. Trial was pruned at iteration 266.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:01:06,173]\u001b[0m Trial 701 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:01:07,584]\u001b[0m Trial 702 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:01:08,982]\u001b[0m Trial 703 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:01:24,480]\u001b[0m Trial 704 pruned. Trial was pruned at iteration 146.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:01:53,919]\u001b[0m Trial 705 pruned. Trial was pruned at iteration 331.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:02:17,354]\u001b[0m Trial 706 pruned. Trial was pruned at iteration 239.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:02:18,756]\u001b[0m Trial 707 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:02:20,161]\u001b[0m Trial 708 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:02:21,557]\u001b[0m Trial 709 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:02:22,952]\u001b[0m Trial 710 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:02:24,350]\u001b[0m Trial 711 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:02:39,862]\u001b[0m Trial 712 pruned. Trial was pruned at iteration 146.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:02:41,261]\u001b[0m Trial 713 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:02:42,668]\u001b[0m Trial 714 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:02:44,064]\u001b[0m Trial 715 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:02:45,468]\u001b[0m Trial 716 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:03:04,275]\u001b[0m Trial 717 pruned. Trial was pruned at iteration 182.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:03:19,404]\u001b[0m Trial 718 pruned. Trial was pruned at iteration 142.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:03:20,803]\u001b[0m Trial 719 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:03:41,466]\u001b[0m Trial 720 pruned. Trial was pruned at iteration 204.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:03:42,869]\u001b[0m Trial 721 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:04:09,475]\u001b[0m Trial 722 pruned. Trial was pruned at iteration 278.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:04:10,874]\u001b[0m Trial 723 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:04:12,278]\u001b[0m Trial 724 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:04:13,673]\u001b[0m Trial 725 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:04:15,072]\u001b[0m Trial 726 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:04:16,467]\u001b[0m Trial 727 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:04:47,788]\u001b[0m Trial 728 pruned. Trial was pruned at iteration 368.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:04:49,187]\u001b[0m Trial 729 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:04:50,585]\u001b[0m Trial 730 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:04:51,986]\u001b[0m Trial 731 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:05:35,761]\u001b[0m Trial 732 pruned. Trial was pruned at iteration 736.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:05:37,173]\u001b[0m Trial 733 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:05:52,315]\u001b[0m Trial 734 pruned. Trial was pruned at iteration 142.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:05:53,726]\u001b[0m Trial 735 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:06:30,332]\u001b[0m Trial 736 pruned. Trial was pruned at iteration 516.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:06:31,722]\u001b[0m Trial 737 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:07:18,617]\u001b[0m Trial 738 finished with value: 2.8706294 and parameters: {'learning_rate': 0.009993995027940229}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:07:57,696]\u001b[0m Trial 739 pruned. Trial was pruned at iteration 573.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:07:59,091]\u001b[0m Trial 740 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:08:00,475]\u001b[0m Trial 741 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:08:27,106]\u001b[0m Trial 742 pruned. Trial was pruned at iteration 287.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:08:28,514]\u001b[0m Trial 743 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:08:29,903]\u001b[0m Trial 744 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:08:31,299]\u001b[0m Trial 745 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:08:32,696]\u001b[0m Trial 746 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:08:34,084]\u001b[0m Trial 747 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:08:49,434]\u001b[0m Trial 748 pruned. Trial was pruned at iteration 144.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:08:50,835]\u001b[0m Trial 749 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:08:52,273]\u001b[0m Trial 750 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:08:53,744]\u001b[0m Trial 751 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:09:09,254]\u001b[0m Trial 752 pruned. Trial was pruned at iteration 146.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:09:10,645]\u001b[0m Trial 753 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:09:12,055]\u001b[0m Trial 754 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:09:13,451]\u001b[0m Trial 755 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:09:29,038]\u001b[0m Trial 756 pruned. Trial was pruned at iteration 147.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:09:30,441]\u001b[0m Trial 757 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:09:31,840]\u001b[0m Trial 758 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:09:33,247]\u001b[0m Trial 759 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:09:34,652]\u001b[0m Trial 760 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:09:36,048]\u001b[0m Trial 761 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:09:37,447]\u001b[0m Trial 762 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:09:38,855]\u001b[0m Trial 763 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:10:01,679]\u001b[0m Trial 764 pruned. Trial was pruned at iteration 228.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:10:22,110]\u001b[0m Trial 765 pruned. Trial was pruned at iteration 201.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:10:42,342]\u001b[0m Trial 766 pruned. Trial was pruned at iteration 200.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:10:43,743]\u001b[0m Trial 767 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:11:13,263]\u001b[0m Trial 768 pruned. Trial was pruned at iteration 325.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:11:14,674]\u001b[0m Trial 769 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:12:02,472]\u001b[0m Trial 770 finished with value: 2.8690728 and parameters: {'learning_rate': 0.009996019984141062}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:12:03,871]\u001b[0m Trial 771 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:12:05,276]\u001b[0m Trial 772 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:12:06,687]\u001b[0m Trial 773 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:12:08,084]\u001b[0m Trial 774 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:12:23,538]\u001b[0m Trial 775 pruned. Trial was pruned at iteration 146.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:12:24,943]\u001b[0m Trial 776 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:12:26,334]\u001b[0m Trial 777 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:12:27,730]\u001b[0m Trial 778 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:12:29,123]\u001b[0m Trial 779 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:12:30,521]\u001b[0m Trial 780 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:12:31,916]\u001b[0m Trial 781 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:12:33,321]\u001b[0m Trial 782 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:12:34,719]\u001b[0m Trial 783 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:13:01,711]\u001b[0m Trial 784 pruned. Trial was pruned at iteration 292.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:13:03,125]\u001b[0m Trial 785 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:13:04,532]\u001b[0m Trial 786 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:13:24,881]\u001b[0m Trial 787 pruned. Trial was pruned at iteration 201.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:13:26,276]\u001b[0m Trial 788 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:13:27,671]\u001b[0m Trial 789 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:13:46,892]\u001b[0m Trial 790 pruned. Trial was pruned at iteration 188.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:13:48,278]\u001b[0m Trial 791 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:13:49,669]\u001b[0m Trial 792 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:13:51,068]\u001b[0m Trial 793 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:14:19,528]\u001b[0m Trial 794 pruned. Trial was pruned at iteration 316.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:15:07,843]\u001b[0m Trial 795 finished with value: 2.8689816 and parameters: {'learning_rate': 0.009998794659240825}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:15:09,247]\u001b[0m Trial 796 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:15:28,561]\u001b[0m Trial 797 pruned. Trial was pruned at iteration 189.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:15:29,949]\u001b[0m Trial 798 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:15:31,349]\u001b[0m Trial 799 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:15:32,749]\u001b[0m Trial 800 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:15:51,793]\u001b[0m Trial 801 pruned. Trial was pruned at iteration 185.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:15:53,208]\u001b[0m Trial 802 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:15:54,600]\u001b[0m Trial 803 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:15:55,989]\u001b[0m Trial 804 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:15:57,385]\u001b[0m Trial 805 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:15:58,797]\u001b[0m Trial 806 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:16:14,082]\u001b[0m Trial 807 pruned. Trial was pruned at iteration 144.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:16:29,582]\u001b[0m Trial 808 pruned. Trial was pruned at iteration 146.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:16:48,814]\u001b[0m Trial 809 pruned. Trial was pruned at iteration 188.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:16:50,219]\u001b[0m Trial 810 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:16:51,623]\u001b[0m Trial 811 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:16:53,024]\u001b[0m Trial 812 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:16:54,423]\u001b[0m Trial 813 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:16:55,816]\u001b[0m Trial 814 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:16:57,206]\u001b[0m Trial 815 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:16:58,601]\u001b[0m Trial 816 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:17:23,898]\u001b[0m Trial 817 pruned. Trial was pruned at iteration 266.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:17:36,772]\u001b[0m Trial 818 pruned. Trial was pruned at iteration 120.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:17:38,159]\u001b[0m Trial 819 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:18:04,009]\u001b[0m Trial 820 pruned. Trial was pruned at iteration 273.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:18:05,435]\u001b[0m Trial 821 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:18:23,834]\u001b[0m Trial 822 pruned. Trial was pruned at iteration 171.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:18:25,239]\u001b[0m Trial 823 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:18:26,645]\u001b[0m Trial 824 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:18:28,035]\u001b[0m Trial 825 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:19:04,524]\u001b[0m Trial 826 pruned. Trial was pruned at iteration 515.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:19:05,931]\u001b[0m Trial 827 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:19:07,317]\u001b[0m Trial 828 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:19:08,710]\u001b[0m Trial 829 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:19:10,106]\u001b[0m Trial 830 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:19:11,505]\u001b[0m Trial 831 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:19:30,405]\u001b[0m Trial 832 pruned. Trial was pruned at iteration 185.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:19:31,803]\u001b[0m Trial 833 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:19:33,194]\u001b[0m Trial 834 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:19:34,580]\u001b[0m Trial 835 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:19:35,981]\u001b[0m Trial 836 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:19:37,365]\u001b[0m Trial 837 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:20:04,958]\u001b[0m Trial 838 pruned. Trial was pruned at iteration 301.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:20:06,353]\u001b[0m Trial 839 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:20:07,759]\u001b[0m Trial 840 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:20:31,523]\u001b[0m Trial 841 pruned. Trial was pruned at iteration 244.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:20:32,931]\u001b[0m Trial 842 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:20:34,316]\u001b[0m Trial 843 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:20:35,705]\u001b[0m Trial 844 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:20:37,096]\u001b[0m Trial 845 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:21:03,777]\u001b[0m Trial 846 pruned. Trial was pruned at iteration 289.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:21:05,183]\u001b[0m Trial 847 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:21:32,405]\u001b[0m Trial 848 pruned. Trial was pruned at iteration 297.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:21:33,794]\u001b[0m Trial 849 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:21:35,189]\u001b[0m Trial 850 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:22:23,560]\u001b[0m Trial 851 finished with value: 2.8681840000000003 and parameters: {'learning_rate': 0.009996304086760548}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:22:24,958]\u001b[0m Trial 852 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:22:52,667]\u001b[0m Trial 853 pruned. Trial was pruned at iteration 303.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:23:23,952]\u001b[0m Trial 854 pruned. Trial was pruned at iteration 370.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:23:25,372]\u001b[0m Trial 855 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:23:26,794]\u001b[0m Trial 856 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:23:28,213]\u001b[0m Trial 857 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:23:54,537]\u001b[0m Trial 858 pruned. Trial was pruned at iteration 280.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:24:39,113]\u001b[0m Trial 859 pruned. Trial was pruned at iteration 735.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:24:40,517]\u001b[0m Trial 860 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:24:41,942]\u001b[0m Trial 861 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:25:30,132]\u001b[0m Trial 862 finished with value: 2.8680228 and parameters: {'learning_rate': 0.009996533022331689}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:25:31,525]\u001b[0m Trial 863 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:25:47,137]\u001b[0m Trial 864 pruned. Trial was pruned at iteration 148.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:25:48,540]\u001b[0m Trial 865 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:25:49,934]\u001b[0m Trial 866 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:26:12,184]\u001b[0m Trial 867 pruned. Trial was pruned at iteration 216.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:26:13,612]\u001b[0m Trial 868 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:26:31,617]\u001b[0m Trial 869 pruned. Trial was pruned at iteration 171.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:26:33,041]\u001b[0m Trial 870 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:26:34,468]\u001b[0m Trial 871 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:27:01,382]\u001b[0m Trial 872 pruned. Trial was pruned at iteration 287.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:27:02,800]\u001b[0m Trial 873 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:27:04,218]\u001b[0m Trial 874 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:27:05,648]\u001b[0m Trial 875 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:27:07,059]\u001b[0m Trial 876 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:27:08,487]\u001b[0m Trial 877 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:27:29,045]\u001b[0m Trial 878 pruned. Trial was pruned at iteration 201.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:27:30,455]\u001b[0m Trial 879 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:27:31,859]\u001b[0m Trial 880 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:27:33,278]\u001b[0m Trial 881 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:27:34,692]\u001b[0m Trial 882 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:27:36,102]\u001b[0m Trial 883 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:27:56,644]\u001b[0m Trial 884 pruned. Trial was pruned at iteration 200.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:27:58,052]\u001b[0m Trial 885 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:28:18,866]\u001b[0m Trial 886 pruned. Trial was pruned at iteration 204.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:28:20,285]\u001b[0m Trial 887 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:28:41,959]\u001b[0m Trial 888 pruned. Trial was pruned at iteration 215.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:29:01,369]\u001b[0m Trial 889 pruned. Trial was pruned at iteration 188.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:29:02,789]\u001b[0m Trial 890 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:29:29,947]\u001b[0m Trial 891 pruned. Trial was pruned at iteration 292.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:29:31,350]\u001b[0m Trial 892 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:30:04,490]\u001b[0m Trial 893 pruned. Trial was pruned at iteration 408.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:30:05,910]\u001b[0m Trial 894 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:30:54,222]\u001b[0m Trial 895 finished with value: 2.8685283999999998 and parameters: {'learning_rate': 0.009996115385737664}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:30:55,629]\u001b[0m Trial 896 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:31:22,057]\u001b[0m Trial 897 pruned. Trial was pruned at iteration 280.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:31:23,477]\u001b[0m Trial 898 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:31:24,884]\u001b[0m Trial 899 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:31:26,299]\u001b[0m Trial 900 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:31:27,697]\u001b[0m Trial 901 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:31:29,114]\u001b[0m Trial 902 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:31:30,538]\u001b[0m Trial 903 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:31:31,953]\u001b[0m Trial 904 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:32:00,732]\u001b[0m Trial 905 pruned. Trial was pruned at iteration 319.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:32:02,147]\u001b[0m Trial 906 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:32:29,103]\u001b[0m Trial 907 pruned. Trial was pruned at iteration 289.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:33:17,200]\u001b[0m Trial 908 finished with value: 2.8691188 and parameters: {'learning_rate': 0.009996105364292289}. Best is trial 144 with value: 2.8642984.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:33:44,153]\u001b[0m Trial 909 pruned. Trial was pruned at iteration 290.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:33:45,780]\u001b[0m Trial 910 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:33:47,176]\u001b[0m Trial 911 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:33:48,571]\u001b[0m Trial 912 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:33:49,967]\u001b[0m Trial 913 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:34:09,270]\u001b[0m Trial 914 pruned. Trial was pruned at iteration 188.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:34:36,354]\u001b[0m Trial 915 pruned. Trial was pruned at iteration 290.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:34:37,761]\u001b[0m Trial 916 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:34:39,157]\u001b[0m Trial 917 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:34:40,567]\u001b[0m Trial 918 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:34:59,471]\u001b[0m Trial 919 pruned. Trial was pruned at iteration 182.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:35:00,886]\u001b[0m Trial 920 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:35:29,113]\u001b[0m Trial 921 pruned. Trial was pruned at iteration 306.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:35:30,538]\u001b[0m Trial 922 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:35:31,962]\u001b[0m Trial 923 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:35:33,366]\u001b[0m Trial 924 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:35:34,792]\u001b[0m Trial 925 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:36:00,348]\u001b[0m Trial 926 pruned. Trial was pruned at iteration 265.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:36:01,771]\u001b[0m Trial 927 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:36:17,344]\u001b[0m Trial 928 pruned. Trial was pruned at iteration 145.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:36:18,742]\u001b[0m Trial 929 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:36:44,590]\u001b[0m Trial 930 pruned. Trial was pruned at iteration 275.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:36:45,989]\u001b[0m Trial 931 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:37:16,762]\u001b[0m Trial 932 pruned. Trial was pruned at iteration 362.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:37:18,149]\u001b[0m Trial 933 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:37:19,548]\u001b[0m Trial 934 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:37:20,941]\u001b[0m Trial 935 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:37:22,343]\u001b[0m Trial 936 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:37:43,163]\u001b[0m Trial 937 pruned. Trial was pruned at iteration 200.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:37:44,551]\u001b[0m Trial 938 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:38:03,041]\u001b[0m Trial 939 pruned. Trial was pruned at iteration 180.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:38:30,642]\u001b[0m Trial 940 pruned. Trial was pruned at iteration 301.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:38:32,050]\u001b[0m Trial 941 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:38:33,449]\u001b[0m Trial 942 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:38:34,849]\u001b[0m Trial 943 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:38:36,234]\u001b[0m Trial 944 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:39:00,469]\u001b[0m Trial 945 pruned. Trial was pruned at iteration 252.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:39:27,304]\u001b[0m Trial 946 pruned. Trial was pruned at iteration 290.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:39:28,698]\u001b[0m Trial 947 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:39:46,400]\u001b[0m Trial 948 pruned. Trial was pruned at iteration 171.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:39:47,794]\u001b[0m Trial 949 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:39:49,188]\u001b[0m Trial 950 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:39:50,577]\u001b[0m Trial 951 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:40:30,784]\u001b[0m Trial 952 pruned. Trial was pruned at iteration 627.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:40:32,177]\u001b[0m Trial 953 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:40:33,572]\u001b[0m Trial 954 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:41:06,243]\u001b[0m Trial 955 pruned. Trial was pruned at iteration 406.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:41:21,548]\u001b[0m Trial 956 pruned. Trial was pruned at iteration 144.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:41:22,943]\u001b[0m Trial 957 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:41:24,337]\u001b[0m Trial 958 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:41:25,718]\u001b[0m Trial 959 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:41:27,108]\u001b[0m Trial 960 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:41:28,494]\u001b[0m Trial 961 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:41:29,901]\u001b[0m Trial 962 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:41:31,296]\u001b[0m Trial 963 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:41:32,699]\u001b[0m Trial 964 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:41:34,101]\u001b[0m Trial 965 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:42:02,526]\u001b[0m Trial 966 pruned. Trial was pruned at iteration 307.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:42:32,082]\u001b[0m Trial 967 pruned. Trial was pruned at iteration 338.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:42:33,479]\u001b[0m Trial 968 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2020-10-29 23:42:52,698]\u001b[0m Trial 969 pruned. Trial was pruned at iteration 188.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "    param = param_2\n",
    "    param[\"learning_rate\"] = trial.suggest_uniform('learning_rate', 0.001, 0.01)\n",
    "\n",
    "    pruning_callback = optuna.integration.XGBoostPruningCallback(trial, \"test-rmse\")\n",
    "\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    history = xgb.cv(param, dtrain, num_boost_round=2000, \n",
    "                     early_stopping_rounds=100,\n",
    "                     callbacks=[pruning_callback],\n",
    "                     metrics='rmse', \n",
    "                     folds=cv)\n",
    "\n",
    "    mean_score = history[\"test-rmse-mean\"].values[-1]\n",
    "    return mean_score\n",
    "\n",
    "pruner = optuna.pruners.MedianPruner(n_warmup_steps=10)\n",
    "study = optuna.create_study(pruner=pruner, direction='minimize')\n",
    "study.optimize(objective, n_trials=1000)\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dp9QnijQYBGD"
   },
   "outputs": [],
   "source": [
    "# Get best params then add to param_3\n",
    "param_3 = param_2.copy()\n",
    "param_3[\"learning_rate\"] = study.best_params[\"learning_rate\"]\n",
    "param_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H03n4RSjYBGH"
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "cv = KFold(\n",
    "    n_splits=5, \n",
    "    shuffle=True, \n",
    "    random_state=0\n",
    ")\n",
    "history = xgb.cv(\n",
    "    param_3, dtrain, \n",
    "    num_boost_round=2000, \n",
    "    early_stopping_rounds=100,\n",
    "    metrics='rmse',\n",
    "    folds=cv\n",
    ")\n",
    "n_estimators_3 = history.shape[0]\n",
    "n_estimators_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ty69r92GYXtx"
   },
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bQp80jXaYXuG"
   },
   "outputs": [],
   "source": [
    "xgb_study_1 = XGBRegressor(**param_1, n_estimators=n_estimators_1)\n",
    "xgb_study_2 = XGBRegressor(**param_2, n_estimators=n_estimators_2)\n",
    "xgb_study_3 = XGBRegressor(**param_3, n_estimators=n_estimators_3)\n",
    "\n",
    "models = {\n",
    "    f'XGBRegressor ({n_estimators_1}) {param_1}': xgb_study_1,\n",
    "    f'XGBRegressor ({n_estimators_2}) {param_2}': xgb_study_2,\n",
    "    f'XGBRegressor ({n_estimators_3}) {param_3}': xgb_study_3\n",
    "}\n",
    "result = evaluate_model(models, X_train, X_test, y_train, y_test)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SCciIDdwdDd8"
   },
   "outputs": [],
   "source": [
    "result.to_csv(\"tuning_dropna_all (XGB).csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cp5UE4lbMZf1"
   },
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMGLpL8nMZgJ"
   },
   "source": [
    "#### Study 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_DBuAfcmMZgK"
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 30),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"lambda_l1\": trial.suggest_loguniform(\"lambda_l1\", 1e-8, 1.0),\n",
    "        \"lambda_l2\": trial.suggest_loguniform(\"lambda_l2\", 1e-8, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 1),\n",
    "        \"feature_fraction\": trial.suggest_uniform(\"feature_fraction\", 0.1, 1),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "    }\n",
    "\n",
    "    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"rmse\")\n",
    "\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    scores = lgb.cv(params, dtrain, \n",
    "                    num_boost_round=2000, \n",
    "                    early_stopping_rounds=100,\n",
    "                    callbacks=[pruning_callback],\n",
    "                    metrics='rmse', \n",
    "                    folds=cv)\n",
    "\n",
    "    mean_score = scores['rmse-mean'][-1]\n",
    "    return mean_score\n",
    "\n",
    "pruner = optuna.pruners.MedianPruner(n_warmup_steps=10)\n",
    "study = optuna.create_study(pruner=pruner, direction='minimize')\n",
    "study.optimize(objective, n_trials=1000)\n",
    "\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w-RaxMEsMZgS"
   },
   "outputs": [],
   "source": [
    "# Get best params then add to param_1\n",
    "study_1_params = study.best_params\n",
    "param_1 = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"verbosity\": -1,\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"learning_rate\": 0.1,\n",
    "}\n",
    "param_1.update(study_1_params)\n",
    "param_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kY2PHvvqMZgW"
   },
   "outputs": [],
   "source": [
    "dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "cv = KFold(\n",
    "    n_splits=5, \n",
    "    shuffle=True, \n",
    "    random_state=0\n",
    ")\n",
    "history = lgb.cv(\n",
    "    param_1, dtrain, \n",
    "    num_boost_round=2000,\n",
    "    early_stopping_rounds=100,\n",
    "    metrics='rmse', \n",
    "    folds=cv\n",
    ")\n",
    "n_estimators_1 = pd.DataFrame(history).shape[0]\n",
    "n_estimators_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8m8NA4IEMZgZ"
   },
   "source": [
    "#### Study 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ofs6sGjMZgb"
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 30),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"lambda_l1\": trial.suggest_loguniform(\"lambda_l1\", 1e-8, 1.0),\n",
    "        \"lambda_l2\": trial.suggest_loguniform(\"lambda_l2\", 1e-8, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 1),\n",
    "        \"feature_fraction\": trial.suggest_uniform(\"feature_fraction\", 0.1, 1),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "    }\n",
    "\n",
    "    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"rmse\")\n",
    "\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    scores = lgb.cv(params, dtrain, \n",
    "                    num_boost_round=2000, \n",
    "                    early_stopping_rounds=100,\n",
    "                    callbacks=[pruning_callback],\n",
    "                    metrics='rmse', \n",
    "                    folds=cv)\n",
    "\n",
    "    mean_score = scores['rmse-mean'][-1]\n",
    "    return mean_score\n",
    "\n",
    "pruner = optuna.pruners.MedianPruner(n_warmup_steps=10)\n",
    "study = optuna.create_study(pruner=pruner, direction='minimize')\n",
    "study.optimize(objective, n_trials=1000)\n",
    "\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PEUnEOY2MZgf"
   },
   "outputs": [],
   "source": [
    "# Get best params then add to param_2\n",
    "study_2_params = study.best_params\n",
    "param_2 = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"verbosity\": -1,\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"learning_rate\": 0.1,\n",
    "}\n",
    "param_2.update(study_2_params)\n",
    "param_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "31_EVr9BMZgi"
   },
   "outputs": [],
   "source": [
    "dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "cv = KFold(\n",
    "    n_splits=5, \n",
    "    shuffle=True, \n",
    "    random_state=0\n",
    ")\n",
    "history = lgb.cv(\n",
    "    param_2, dtrain, \n",
    "    num_boost_round=2000,\n",
    "    early_stopping_rounds=100,\n",
    "    metrics='rmse', \n",
    "    folds=cv\n",
    ")\n",
    "n_estimators_2 = pd.DataFrame(history).shape[0]\n",
    "n_estimators_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kdnBKWshMZgl"
   },
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L323nvX2MZgm"
   },
   "outputs": [],
   "source": [
    "lgb_study_1 = LGBMRegressor(**param_1, n_estimators=n_estimators_1)\n",
    "lgb_study_2 = LGBMRegressor(**param_2, n_estimators=n_estimators_2)\n",
    "\n",
    "models = {\n",
    "    f'LGBMRegressor ({n_estimators_1}) {param_1}': lgb_study_1,\n",
    "    f'LGBMRegressor ({n_estimators_2}) {param_2}': lgb_study_2\n",
    "}\n",
    "result = evaluate_model(models, X_train, X_test, y_train, y_test)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMLdn24uMZgq"
   },
   "source": [
    "#### Study 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1yqpJRkqMZgr"
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "    param = param_2\n",
    "    param[\"learning_rate\"] = trial.suggest_uniform('learning_rate', 0.001, 0.01)\n",
    "\n",
    "    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"rmse\")\n",
    "\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    scores = lgb.cv(params, dtrain, \n",
    "                    num_boost_round=2000, \n",
    "                    early_stopping_rounds=100,\n",
    "                    callbacks=[pruning_callback],\n",
    "                    metrics='rmse', \n",
    "                    folds=cv)\n",
    "\n",
    "    mean_score = scores['rmse-mean'][-1]\n",
    "    return mean_score\n",
    "\n",
    "pruner = optuna.pruners.MedianPruner(n_warmup_steps=10)\n",
    "study = optuna.create_study(pruner=pruner, direction='minimize')\n",
    "study.optimize(objective, n_trials=1000)\n",
    "\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hRrJ92p_MZgu"
   },
   "outputs": [],
   "source": [
    "# Get best params then add to param_3\n",
    "param_3 = param_2.copy()\n",
    "param_3[\"learning_rate\"] = study.best_params[\"learning_rate\"]\n",
    "param_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kVNd4F6mMZgx"
   },
   "outputs": [],
   "source": [
    "dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "cv = KFold(\n",
    "    n_splits=5, \n",
    "    shuffle=True, \n",
    "    random_state=0\n",
    ")\n",
    "history = lgb.cv(\n",
    "    param_3, dtrain, \n",
    "    num_boost_round=2000,\n",
    "    early_stopping_rounds=100,\n",
    "    metrics='rmse', \n",
    "    folds=cv\n",
    ")\n",
    "n_estimators_3 = pd.DataFrame(history).shape[0]\n",
    "n_estimators_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gJqhWdzMZg0"
   },
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ita98N6JMZg1"
   },
   "outputs": [],
   "source": [
    "lgb_study_1 = LGBMRegressor(**param_1, n_estimators=n_estimators_1)\n",
    "lgb_study_2 = LGBMRegressor(**param_2, n_estimators=n_estimators_2)\n",
    "lgb_study_3 = LGBMRegressor(**param_3, n_estimators=n_estimators_3)\n",
    "\n",
    "models = {\n",
    "    f'LGBMRegressor ({n_estimators_1}) {param_1}': lgb_study_1,\n",
    "    f'LGBMRegressor ({n_estimators_2}) {param_2}': lgb_study_2,\n",
    "    f'LGBMRegressor ({n_estimators_3}) {param_3}': lgb_study_3\n",
    "}\n",
    "result = evaluate_model(models, X_train, X_test, y_train, y_test)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yALoggpxMZg4"
   },
   "outputs": [],
   "source": [
    "result.to_csv(\"tuning_dropna_all (LGB).csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QNQzROBsMZg7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tuning_dropna_all.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "7e6ba86d-f2b0-4a20-b936-811e696ed5ab",
  "jupytext": {
   "formats": "notebooks//ipynb,markdown//md,scripts//py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
